{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f269c5f",
   "metadata": {},
   "source": [
    "1. Extracting and forming the macro-economic indicators csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53bc0f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved macro indicators to: /Users/vvmohith/Desktop/PROJECT/phase-3(final)/macro_indicators_wb.csv\n",
      "  Fiscal_Year  GDP_Growth_Rate  Inflation_CPI  Exchange_Rate_USD  \\\n",
      "0       05-06         8.060733       5.796523          45.307008   \n",
      "1       06-07         7.660815       6.372881          41.348533   \n",
      "2       07-08         3.086698       8.349267          43.505183   \n",
      "3       08-09         7.861889      10.882353          48.405267   \n",
      "4       09-10         8.497585      11.989390          45.725812   \n",
      "\n",
      "   Current_Account_GDP  Global_GDP_Growth  Election_Year  High_Inflation  \\\n",
      "0            -0.988988           4.471221            0.0               0   \n",
      "1            -0.663718           4.385583            0.0               1   \n",
      "2            -2.583377           2.073953            0.0               1   \n",
      "3            -1.951462          -1.319598            0.0               1   \n",
      "4            -3.253484           4.527147            1.0               1   \n",
      "\n",
      "   GDP_Growth_Lag1  Inflation_Lag1  \n",
      "0              NaN             NaN  \n",
      "1         8.060733        5.796523  \n",
      "2         7.660815        6.372881  \n",
      "3         3.086698        8.349267  \n",
      "4         7.861889       10.882353  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT\")\n",
    "OUT = BASE / \"phase-3(final)\" / \"macro_indicators_wb.csv\"\n",
    "\n",
    "# World Bank indicator → output column name\n",
    "INDICATORS = {\n",
    "    \"NY.GDP.MKTP.KD.ZG\": \"GDP_Growth_Rate\",     # Real GDP growth (annual %)\n",
    "    \"FP.CPI.TOTL.ZG\": \"Inflation_CPI\",          # CPI inflation (annual %)\n",
    "    \"PA.NUS.FCRF\": \"Exchange_Rate_USD\",         # LCU per USD (avg)\n",
    "    \"BN.CAB.XOKA.GD.ZS\": \"Current_Account_GDP\", # Current account balance (% of GDP)\n",
    "}\n",
    "WB_CODES = list(INDICATORS.keys())\n",
    "\n",
    "def wb_fetch_series(country: str, indicator: str, start: int, end: int, retries: int = 3, sleep_s: float = 0.8) -> pd.DataFrame:\n",
    "    \"\"\"Fetch a single indicator as Calendar_Year/value using WB JSON API.\"\"\"\n",
    "    url = f\"https://api.worldbank.org/v2/country/{country}/indicator/{indicator}\"\n",
    "    params = {\"format\": \"json\", \"per_page\": 200, \"date\": f\"{start}:{end}\"}\n",
    "    last_err = None\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=20)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if not isinstance(data, list) or len(data) < 2:\n",
    "                raise ValueError(f\"Unexpected response for {country} {indicator}\")\n",
    "            rows = data[1] or []\n",
    "            recs = []\n",
    "            for row in rows:\n",
    "                year = row.get(\"date\")\n",
    "                val = row.get(\"value\")\n",
    "                if year is None:\n",
    "                    continue\n",
    "                try:\n",
    "                    year = int(year)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                # Keep numeric values only\n",
    "                if val is None or (isinstance(val, float) and (math.isnan(val))):\n",
    "                    continue\n",
    "                recs.append({\"Calendar_Year\": year, indicator: float(val)})\n",
    "            df = pd.DataFrame(recs).drop_duplicates(subset=[\"Calendar_Year\"])\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(sleep_s)\n",
    "    raise RuntimeError(f\"World Bank API fetch failed for {country} {indicator}: {last_err}\")\n",
    "\n",
    "def to_fy_label(cal_year: int) -> str:\n",
    "    y2 = cal_year % 100\n",
    "    y1 = (cal_year - 1) % 100\n",
    "    return f\"{y1:02d}-{y2:02d}\"\n",
    "\n",
    "def main():\n",
    "    start, end = 2005, 2025  # CY → will map to FY 05-06 … 24-25\n",
    "\n",
    "    # Fetch India indicators\n",
    "    df = None\n",
    "    for code in WB_CODES:\n",
    "        part = wb_fetch_series(\"IND\", code, start, end)\n",
    "        df = part if df is None else pd.merge(df, part, on=\"Calendar_Year\", how=\"outer\")\n",
    "\n",
    "    # Fetch Global GDP growth for control\n",
    "    wld = wb_fetch_series(\"WLD\", \"NY.GDP.MKTP.KD.ZG\", start, end)\n",
    "    wld = wld.rename(columns={\"NY.GDP.MKTP.KD.ZG\": \"Global_GDP_Growth\"})\n",
    "    df = pd.merge(df, wld, on=\"Calendar_Year\", how=\"left\")\n",
    "\n",
    "    # Rename indicator codes to friendly names\n",
    "    df = df.rename(columns=INDICATORS)\n",
    "\n",
    "    # Map Calendar Year → Fiscal Year label (uses end-year)\n",
    "    df[\"Fiscal_Year\"] = df[\"Calendar_Year\"].apply(to_fy_label)\n",
    "    df = df.drop(columns=[\"Calendar_Year\"])\n",
    "    # Ensure numeric\n",
    "    for c in [\"GDP_Growth_Rate\",\"Inflation_CPI\",\"Exchange_Rate_USD\",\"Current_Account_GDP\",\"Global_GDP_Growth\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # Election and inflation flags\n",
    "    elections = [2009, 2014, 2019, 2024]\n",
    "    election_fys = {f\"{e%100:02d}-{(e+1)%100:02d}\": 1 for e in elections}\n",
    "    df[\"Election_Year\"] = df[\"Fiscal_Year\"].map(election_fys).fillna(0).astype(int)\n",
    "    df[\"High_Inflation\"] = (df[\"Inflation_CPI\"] > 6).astype(\"Int64\")\n",
    "\n",
    "    # Reindex to full FY range and make lags\n",
    "    fy_keep = [to_fy_label(y) for y in range(2006, 2026)]  # 05-06 … 24-25\n",
    "    df = df.set_index(\"Fiscal_Year\").reindex(fy_keep)\n",
    "    df[\"GDP_Growth_Lag1\"] = pd.to_numeric(df[\"GDP_Growth_Rate\"], errors=\"coerce\").shift(1)\n",
    "    df[\"Inflation_Lag1\"] = pd.to_numeric(df[\"Inflation_CPI\"], errors=\"coerce\").shift(1)\n",
    "    df = df.reset_index().rename(columns={\"index\": \"Fiscal_Year\"})\n",
    "\n",
    "    # Sanity: warn if negative GDP growth before FY 19-20\n",
    "    pre_covid_bad = df[(df[\"Fiscal_Year\"] < \"19-20\") & (pd.to_numeric(df[\"GDP_Growth_Rate\"], errors=\"coerce\") < -3)]\n",
    "    if not pre_covid_bad.empty:\n",
    "        print(\"Warning: unexpected negative GDP growth before FY 19-20:\\n\", pre_covid_bad[[\"Fiscal_Year\",\"GDP_Growth_Rate\"]])\n",
    "\n",
    "    # Order columns\n",
    "    cols = [\n",
    "        \"Fiscal_Year\",\n",
    "        \"GDP_Growth_Rate\",\n",
    "        \"Inflation_CPI\",\n",
    "        \"Exchange_Rate_USD\",\n",
    "        \"Current_Account_GDP\",\n",
    "        \"Global_GDP_Growth\",\n",
    "        \"Election_Year\",\n",
    "        \"High_Inflation\",\n",
    "        \"GDP_Growth_Lag1\",\n",
    "        \"Inflation_Lag1\",\n",
    "    ]\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    df_out = df[cols].reset_index(drop=True)\n",
    "\n",
    "    OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_out.to_csv(OUT, index=False)\n",
    "    print(f\"Saved macro indicators to: {OUT}\")\n",
    "    print(df_out.head(5))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7fc07",
   "metadata": {},
   "source": [
    "2. this is where i have combined the columns of csv along with the macro-economic indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c1d9025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/cumulative_budget_macro.csv\n",
      "Rows: 1037, Ministries: 61, FY columns used: 17 [05-06, 06-07, 07-08, ..., 21-22, 22-23, 23-24]\n",
      "Filter: kept only ministries with values for all FY columns.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "BUDGETS = BASE / \"standardized_budget_time_series.csv\"\n",
    "MACROS = BASE.parent / \"phase-3(final)\" / \"macro_indicators_wb.csv\"\n",
    "OUT = BASE / \"cumulative_budget_macro.csv\"\n",
    "\n",
    "# Keep only ministries with a value in every FY column present in the budgets file\n",
    "FULL_COVERAGE_ONLY = True  # set False to keep all ministries (even with gaps)\n",
    "\n",
    "def main():\n",
    "    # Load budgets (wide)\n",
    "    dfb = pd.read_csv(BUDGETS, dtype={\"Base_Ministry\": \"string\"})\n",
    "    dfb[\"Base_Ministry\"] = (\n",
    "        dfb[\"Base_Ministry\"]\n",
    "        .str.strip()\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    )\n",
    "\n",
    "    # Identify FY columns like 05-06, 23-24, etc.\n",
    "    fy_cols = [c for c in dfb.columns if re.fullmatch(r\"\\d{2}-\\d{2}\", str(c))]\n",
    "    if not fy_cols:\n",
    "        raise RuntimeError(\"No fiscal-year columns found in standardized_budget_time_series.csv\")\n",
    "\n",
    "    # Coerce budget numbers to numeric\n",
    "    dfb[fy_cols] = (\n",
    "        dfb[fy_cols]\n",
    "        .replace(r\"[,\\s]\", \"\", regex=True)\n",
    "        .apply(pd.to_numeric, errors=\"coerce\")\n",
    "    )\n",
    "\n",
    "    # If duplicate ministry names exist, sum their values (min_count=1 keeps NaN if all NaN)\n",
    "    dfb = dfb.groupby(\"Base_Ministry\", as_index=False)[fy_cols].sum(min_count=1)\n",
    "\n",
    "    # Tidy to long format: one row per (Base_Ministry, Fiscal_Year)\n",
    "    long = dfb.melt(\n",
    "        id_vars=\"Base_Ministry\",\n",
    "        value_vars=fy_cols,\n",
    "        var_name=\"Fiscal_Year\",\n",
    "        value_name=\"Budget_Amount\"\n",
    "    )\n",
    "\n",
    "    # Optionally keep only ministries with complete coverage across all FY columns\n",
    "    if FULL_COVERAGE_ONLY:\n",
    "        coverage = long.groupby(\"Base_Ministry\")[\"Budget_Amount\"].apply(lambda s: s.notna().sum())\n",
    "        required = len(fy_cols)\n",
    "        keep_ministries = coverage[coverage == required].index\n",
    "        long = long[long[\"Base_Ministry\"].isin(keep_ministries)]\n",
    "\n",
    "    # Drop rows with no budget\n",
    "    long = long.dropna(subset=[\"Budget_Amount\"])\n",
    "\n",
    "    # Load macros and keep overlapping FYs only\n",
    "    macros = pd.read_csv(MACROS, dtype={\"Fiscal_Year\": \"string\"})\n",
    "    macros = macros[macros[\"Fiscal_Year\"].isin(fy_cols)].copy()\n",
    "\n",
    "    # Merge\n",
    "    merged = long.merge(macros, on=\"Fiscal_Year\", how=\"inner\")\n",
    "\n",
    "    # Sort for readability\n",
    "    # order FY by end-year\n",
    "    def fy_sort_key(s: pd.Series) -> pd.Series:\n",
    "        return s.str.split(\"-\", expand=True)[1].astype(int)\n",
    "    merged = merged.sort_values([\"Base_Ministry\", \"Fiscal_Year\"], key=lambda col: fy_sort_key(col) if col.name==\"Fiscal_Year\" else col)\n",
    "\n",
    "    # Save\n",
    "    OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "    merged.to_csv(OUT, index=False)\n",
    "\n",
    "    # Report\n",
    "    fy_span = \", \".join(fy_cols[:3] + ([\"...\"] if len(fy_cols) > 6 else []) + fy_cols[-3:])\n",
    "    print(f\"Saved: {OUT}\")\n",
    "    print(f\"Rows: {len(merged)}, Ministries: {merged['Base_Ministry'].nunique()}, FY columns used: {len(fy_cols)} [{fy_span}]\")\n",
    "    if FULL_COVERAGE_ONLY:\n",
    "        print(\"Filter: kept only ministries with values for all FY columns.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2301398",
   "metadata": {},
   "source": [
    "3. Per‑ministry single‑year modeling (FY 23‑24) + visualizations\n",
    "\n",
    "- Builds features (macro vars + Budget_Lag1) and trains per‑ministry models on data up to FY 22‑23.\n",
    "- Predicts FY 23‑24 for each ministry using: Linear, Ridge, Lasso, Random Forest, GBM.\n",
    "- Saves:\n",
    "  - ministry_macro_predictions.csv and macro_model_metrics.csv\n",
    "  - Plots in final_data/figs: metrics_*.png, preds_vs_actual_best.png, residuals_best.png, top_ministries_actual_vs_best.png, feature_importance_*.png.\n",
    "- Use these plots to assess accuracy, bias, and which features matter most (pooled importances)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "738e746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.069e+08, tolerance: 2.310e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.279e+03, tolerance: 1.295e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.279e+03, tolerance: 1.295e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.068e+05, tolerance: 1.676e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.068e+05, tolerance: 1.676e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions: /Users/vvmohith/Desktop/PROJECT/final_data/ministry_macro_predictions.csv\n",
      "Saved metrics:     /Users/vvmohith/Desktop/PROJECT/final_data/macro_model_metrics.csv\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/metrics_mae.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/metrics_rmse.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/metrics_mape_%.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/metrics_r2.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/metrics_rmse.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/metrics_mape_%.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/metrics_r2.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/preds_vs_actual_best.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/residuals_best.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/preds_vs_actual_best.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/residuals_best.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/top_ministries_actual_vs_best.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/top_ministries_actual_vs_best.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/feature_importance_rf.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/feature_importance_rf.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/feature_importance_gbm.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs/feature_importance_gbm.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "DATA = BASE / \"cumulative_budget_macro.csv\"\n",
    "OUT_PRED = BASE / \"ministry_macro_predictions.csv\"\n",
    "OUT_METRICS = BASE / \"macro_model_metrics.csv\"\n",
    "PLOTS_DIR = BASE / \"figs\"\n",
    "\n",
    "# Feature columns from macros + we add a per‑ministry budget lag\n",
    "MACRO_COLS = [\n",
    "    \"GDP_Growth_Rate\",\n",
    "    \"Inflation_CPI\",\n",
    "    \"Exchange_Rate_USD\",\n",
    "    \"Current_Account_GDP\",\n",
    "    \"Global_GDP_Growth\",\n",
    "    \"Election_Year\",\n",
    "    \"High_Inflation\",\n",
    "    \"GDP_Growth_Lag1\",\n",
    "    \"Inflation_Lag1\",\n",
    "]\n",
    "\n",
    "def fy_end_year(fy: str) -> int:\n",
    "    # '05-06' -> 2006\n",
    "    end = int(str(fy).split(\"-\")[1])\n",
    "    return 2000 + end\n",
    "\n",
    "def make_plots(preds: pd.DataFrame, metrics_df: pd.DataFrame, df_all: pd.DataFrame, feature_cols: list):\n",
    "    PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    if metrics_df.empty or preds.empty:\n",
    "        print(\"No metrics/predictions to plot.\")\n",
    "        return\n",
    "\n",
    "    # 1) Metrics bar charts (MAE and RMSE)\n",
    "    for metric in [\"MAE\", \"RMSE\", \"MAPE_%\", \"R2\"]:\n",
    "        if metric not in metrics_df.columns:\n",
    "            continue\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        order = metrics_df.sort_values(metric, ascending=(metric != \"R2\"))[\"Model\"]\n",
    "        sns.barplot(data=metrics_df, x=\"Model\", y=metric, order=order)\n",
    "        plt.title(f\"Model {metric}\")\n",
    "        plt.tight_layout()\n",
    "        out = PLOTS_DIR / f\"metrics_{metric.lower()}.png\"\n",
    "        plt.savefig(out, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"Saved: {out}\")\n",
    "\n",
    "    # Best model\n",
    "    best = metrics_df.iloc[0][\"Model\"]\n",
    "    col = f\"{best}_Prediction\"\n",
    "    valid = preds.dropna(subset=[col, \"Actual_Budget\"]).copy()\n",
    "    if valid.empty:\n",
    "        print(\"No valid rows for best-model plots.\")\n",
    "        return\n",
    "\n",
    "    # 2) Predictions vs Actual (scatter)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.scatterplot(x=valid[\"Actual_Budget\"], y=valid[col])\n",
    "    lim = [\n",
    "        0,\n",
    "        max(valid[\"Actual_Budget\"].max(), valid[col].max()) * 1.05\n",
    "    ]\n",
    "    plt.plot(lim, lim, \"r--\", linewidth=1)\n",
    "    plt.xlim(lim); plt.ylim(lim)\n",
    "    plt.xlabel(\"Actual 23-24\")\n",
    "    plt.ylabel(f\"{best} Prediction\")\n",
    "    plt.title(f\"Predictions vs Actuals ({best})\")\n",
    "    plt.tight_layout()\n",
    "    out = PLOTS_DIR / \"preds_vs_actual_best.png\"\n",
    "    plt.savefig(out, dpi=300); plt.close()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "    # 3) Residuals histogram\n",
    "    residuals = valid[col] - valid[\"Actual_Budget\"]\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(residuals, bins=20, alpha=0.8)\n",
    "    plt.axvline(residuals.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean {residuals.mean():.1f}\")\n",
    "    plt.title(f\"Residuals ({best})\")\n",
    "    plt.xlabel(\"Prediction - Actual\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    out = PLOTS_DIR / \"residuals_best.png\"\n",
    "    plt.savefig(out, dpi=300); plt.close()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "    # 4) Top ministries by actual spend (bar, side-by-side)\n",
    "    topn = valid.sort_values(\"Actual_Budget\", ascending=False).head(15).copy()\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    x = np.arange(len(topn))\n",
    "    width = 0.45\n",
    "    plt.bar(x - width/2, topn[\"Actual_Budget\"], width=width, label=\"Actual\")\n",
    "    plt.bar(x + width/2, topn[col], width=width, label=f\"{best}\")\n",
    "    plt.xticks(x, topn[\"Base_Ministry\"], rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Budget (crores)\")\n",
    "    plt.title(f\"Top 15 ministries: Actual vs {best}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    out = PLOTS_DIR / \"top_ministries_actual_vs_best.png\"\n",
    "    plt.savefig(out, dpi=300); plt.close()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "    # 5) Pooled feature importance (RF and GBM) trained on all train rows\n",
    "    train_all = df_all[(df_all[\"Year_End\"] <= 2023)].dropna(subset=[\"Budget_Amount\"] + feature_cols).copy()\n",
    "    if not train_all.empty:\n",
    "        X_all = train_all[feature_cols]\n",
    "        y_all = train_all[\"Budget_Amount\"]\n",
    "\n",
    "        rf = RandomForestRegressor(n_estimators=400, random_state=42)\n",
    "        rf.fit(X_all, y_all)\n",
    "        imp_rf = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=False).head(12)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=imp_rf.values, y=imp_rf.index)\n",
    "        plt.title(\"Random Forest feature importance (pooled)\")\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "        out = PLOTS_DIR / \"feature_importance_rf.png\"\n",
    "        plt.savefig(out, dpi=300); plt.close()\n",
    "        print(f\"Saved: {out}\")\n",
    "\n",
    "        gbm = GradientBoostingRegressor(n_estimators=400, random_state=42)\n",
    "        gbm.fit(X_all, y_all)\n",
    "        imp_gbm = pd.Series(gbm.feature_importances_, index=feature_cols).sort_values(ascending=False).head(12)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=imp_gbm.values, y=imp_gbm.index)\n",
    "        plt.title(\"GBM feature importance (pooled)\")\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "        out = PLOTS_DIR / \"feature_importance_gbm.png\"\n",
    "        plt.savefig(out, dpi=300); plt.close()\n",
    "        print(f\"Saved: {out}\")\n",
    "    else:\n",
    "        print(\"Skipped pooled feature importance (no training rows).\")\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(DATA, dtype={\"Base_Ministry\": \"string\", \"Fiscal_Year\": \"string\"})\n",
    "    # Ensure numerics\n",
    "    for c in [\"Budget_Amount\"] + MACRO_COLS:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # Sort and create time helper\n",
    "    df[\"Year_End\"] = df[\"Fiscal_Year\"].apply(fy_end_year)\n",
    "\n",
    "    # Add per‑ministry budget lag (strong predictor)\n",
    "    df = df.sort_values([\"Base_Ministry\", \"Year_End\"])\n",
    "    df[\"Budget_Lag1\"] = df.groupby(\"Base_Ministry\")[\"Budget_Amount\"].shift(1)\n",
    "\n",
    "    # Final feature set\n",
    "    feature_cols = [c for c in MACRO_COLS if c in df.columns] + [\"Budget_Lag1\"]\n",
    "\n",
    "    # Target test year (FY 23-24 -> end year 2024)\n",
    "    TEST_END_YEAR = 2024\n",
    "    TRAIN_MAX_END_YEAR = TEST_END_YEAR - 1\n",
    "\n",
    "    preds_rows = []\n",
    "\n",
    "    # Models\n",
    "    linear = Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"m\", LinearRegression())])\n",
    "    ridge = Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"m\", Ridge(alpha=10.0, random_state=42))])\n",
    "    lasso = Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"m\", Lasso(alpha=1.0, random_state=42))])\n",
    "    rf = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "    gbm = GradientBoostingRegressor(n_estimators=300, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"Linear\": linear,\n",
    "        \"Ridge\": ridge,\n",
    "        \"Lasso\": lasso,\n",
    "        \"RF\": rf,\n",
    "        \"GBM\": gbm,\n",
    "    }\n",
    "\n",
    "    # Train per ministry and predict 23-24\n",
    "    for ministry, g in df.groupby(\"Base_Ministry\", dropna=True):\n",
    "        g = g.copy().sort_values(\"Year_End\")\n",
    "\n",
    "        train = g[g[\"Year_End\"] <= TRAIN_MAX_END_YEAR].dropna(subset=[\"Budget_Amount\"] + feature_cols)\n",
    "        test = g[g[\"Year_End\"] == TEST_END_YEAR]\n",
    "\n",
    "        if train.empty or test.empty:\n",
    "            continue\n",
    "\n",
    "        X_train = train[feature_cols]\n",
    "        y_train = train[\"Budget_Amount\"]\n",
    "        X_test = test[feature_cols]\n",
    "        y_test = test[\"Budget_Amount\"]\n",
    "\n",
    "        row = {\"Base_Ministry\": ministry, \"Fiscal_Year\": \"23-24\", \"Actual_Budget\": float(y_test.iloc[0]) if not y_test.isna().all() else np.nan}\n",
    "\n",
    "        for name, model in models.items():\n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = float(model.predict(X_test)[0])\n",
    "                row[f\"{name}_Prediction\"] = y_pred\n",
    "            except Exception:\n",
    "                row[f\"{name}_Prediction\"] = np.nan\n",
    "\n",
    "        preds_rows.append(row)\n",
    "\n",
    "    preds = pd.DataFrame(preds_rows)\n",
    "\n",
    "    # Compute metrics across ministries (only where both pred and actual exist)\n",
    "    metrics = []\n",
    "    for name in models.keys():\n",
    "        col = f\"{name}_Prediction\"\n",
    "        valid = preds.dropna(subset=[col, \"Actual_Budget\"]).copy()\n",
    "        if valid.empty:\n",
    "            continue\n",
    "        y_true = valid[\"Actual_Budget\"].astype(float).values\n",
    "        y_pred = valid[col].astype(float).values\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mape = float(np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), 1e-12))) * 100.0)\n",
    "        metrics.append({\"Model\": name, \"Count\": len(valid), \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE_%\": mape})\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics).sort_values(\"MAE\")\n",
    "\n",
    "    # Save CSVs\n",
    "    OUT_PRED.parent.mkdir(parents=True, exist_ok=True)\n",
    "    preds.to_csv(OUT_PRED, index=False)\n",
    "    metrics_df.to_csv(OUT_METRICS, index=False)\n",
    "    print(f\"Saved predictions: {OUT_PRED}\")\n",
    "    print(f\"Saved metrics:     {OUT_METRICS}\")\n",
    "\n",
    "    # Plots\n",
    "    make_plots(preds, metrics_df, df, feature_cols)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9069a77",
   "metadata": {},
   "source": [
    "4. Rolling backtest with engineered features and extra models\n",
    "\n",
    "- Adds richer features: Budget_Lag1/Lag2, Budget_Growth_Lag1, Trend, Inflation×Election.\n",
    "- Evaluates models via forward‑chaining across multiple years (train < year, predict year).\n",
    "- Uses log1p target for stability (configurable).\n",
    "- Models: Linear, Ridge, Lasso, RF, GBM, HistGradientBoosting, and a small MLP.\n",
    "- Saves:\n",
    "  - ministry_macro_backtest_predictions.csv and macro_model_metrics_backtest.csv\n",
    "  - Plots in final_data/figs-2: backtest_mae/rmse/mape_%/r2.png, backtest_error_over_years.png.\n",
    "- Use these to judge out‑of‑sample performance and stability over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f2d2617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:19: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions: /Users/vvmohith/Desktop/PROJECT/final_data/ministry_macro_backtest_predictions.csv\n",
      "Saved metrics:     /Users/vvmohith/Desktop/PROJECT/final_data/macro_model_metrics_backtest.csv\n",
      " Model  Count          MAE         RMSE            R2       MAPE_%\n",
      "   GBM    549 1.085168e+04 3.434682e+04  5.502673e-01 1.273510e+02\n",
      "    RF    549 1.227256e+04 3.379402e+04  5.646273e-01 1.126442e+02\n",
      "   HGB    549 1.662989e+04 4.008722e+04  3.873767e-01 1.086272e+02\n",
      " Ridge    549 1.737282e+14 4.070558e+15 -6.316689e+21 2.840390e+11\n",
      "Linear    549 4.766114e+19 1.116735e+21 -4.754251e+32 1.500797e+18\n",
      "   MLP    549 2.878266e+22 6.743993e+23 -1.733867e+38 4.705406e+19\n",
      " Lasso    549 5.087235e+22 1.191977e+24 -5.416483e+38 8.316640e+19\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs-2/backtest_mae.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs-2/backtest_rmse.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs-2/backtest_mape_%.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs-2/backtest_r2.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs-2/backtest_mape_%.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs-2/backtest_r2.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs-2/backtest_error_over_years.png\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/figs-2/backtest_error_over_years.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "DATA = BASE / \"cumulative_budget_macro.csv\"\n",
    "OUT_PRED = BASE / \"ministry_macro_backtest_predictions.csv\"\n",
    "OUT_METRICS = BASE / \"macro_model_metrics_backtest.csv\"\n",
    "PLOTS = BASE / \"figs-2\"\n",
    "\n",
    "MACRO_COLS = [\n",
    "    \"GDP_Growth_Rate\",\n",
    "    \"Inflation_CPI\",\n",
    "    \"Exchange_Rate_USD\",\n",
    "    \"Current_Account_GDP\",\n",
    "    \"Global_GDP_Growth\",\n",
    "    \"Election_Year\",\n",
    "    \"High_Inflation\",\n",
    "    \"GDP_Growth_Lag1\",\n",
    "    \"Inflation_Lag1\",\n",
    "]\n",
    "\n",
    "USE_LOG_TARGET = True  # log1p target often stabilizes trends\n",
    "MIN_TRAIN_YEARS = 6    # require at least this many training rows per split\n",
    "\n",
    "def fy_end_year(fy: str) -> int:\n",
    "    end = int(str(fy).split(\"-\")[1])\n",
    "    return 2000 + end\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"Year_End\"] = df[\"Fiscal_Year\"].apply(fy_end_year)\n",
    "    df = df.sort_values([\"Base_Ministry\", \"Year_End\"])\n",
    "\n",
    "    # Per‑ministry lags and growth\n",
    "    df[\"Budget_Lag1\"] = df.groupby(\"Base_Ministry\")[\"Budget_Amount\"].shift(1)\n",
    "    df[\"Budget_Lag2\"] = df.groupby(\"Base_Ministry\")[\"Budget_Amount\"].shift(2)\n",
    "    df[\"Budget_Growth_Lag1\"] = (df[\"Budget_Amount\"] / df[\"Budget_Lag1\"] - 1).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Time trend (helps linear models)\n",
    "    df[\"Trend\"] = df.groupby(\"Base_Ministry\")[\"Year_End\"].transform(lambda s: s - s.min())\n",
    "\n",
    "    # Optional simple interaction\n",
    "    if \"Inflation_CPI\" in df.columns and \"Election_Year\" in df.columns:\n",
    "        df[\"Inflation_x_Election\"] = pd.to_numeric(df[\"Inflation_CPI\"], errors=\"coerce\") * pd.to_numeric(df[\"Election_Year\"], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"Inflation_x_Election\"] = np.nan\n",
    "\n",
    "    # Final feature list\n",
    "    feature_cols = [c for c in MACRO_COLS if c in df.columns] + [\n",
    "        \"Budget_Lag1\", \"Budget_Lag2\", \"Budget_Growth_Lag1\", \"Trend\", \"Inflation_x_Election\"\n",
    "    ]\n",
    "    return df, feature_cols\n",
    "\n",
    "def main():\n",
    "    PLOTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(DATA, dtype={\"Base_Ministry\": \"string\", \"Fiscal_Year\": \"string\"})\n",
    "    # Coerce numerics\n",
    "    df[\"Budget_Amount\"] = pd.to_numeric(df[\"Budget_Amount\"], errors=\"coerce\")\n",
    "    for c in MACRO_COLS:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df, feature_cols = build_features(df)\n",
    "\n",
    "    # Models to compare\n",
    "    models = {\n",
    "        \"Linear\": Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"m\", LinearRegression())]),\n",
    "        \"Ridge\":  Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"m\", Ridge(alpha=10.0, random_state=42))]),\n",
    "        \"Lasso\":  Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"m\", Lasso(alpha=1.0, random_state=42))]),\n",
    "        \"RF\":     RandomForestRegressor(n_estimators=400, random_state=42),\n",
    "        \"GBM\":    GradientBoostingRegressor(n_estimators=400, random_state=42),\n",
    "        \"HGB\":    HistGradientBoostingRegressor(max_depth=3, l2_regularization=0.1, random_state=42),\n",
    "        \"MLP\":    Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"m\", MLPRegressor(hidden_layer_sizes=(64, 32), alpha=1e-3, max_iter=2000, random_state=42))]),\n",
    "    }\n",
    "\n",
    "    # Rolling backtest across many years (predict end year t using data <= t-1)\n",
    "    # Choose a reasonable window given your data span\n",
    "    all_years = sorted(df[\"Year_End\"].dropna().unique())\n",
    "    start_eval = max(min(all_years) + 6, 2014)  # ensure enough train years\n",
    "    end_eval = max(all_years)                   # should include 2024\n",
    "    eval_years = [y for y in all_years if start_eval <= y <= end_eval]\n",
    "\n",
    "    preds_rows = []\n",
    "    for ministry, g in df.groupby(\"Base_Ministry\", dropna=True):\n",
    "        g = g.copy().sort_values(\"Year_End\")\n",
    "        for test_year in eval_years:\n",
    "            train = g[g[\"Year_End\"] < test_year].dropna(subset=[\"Budget_Amount\"] + feature_cols)\n",
    "            test = g[g[\"Year_End\"] == test_year]\n",
    "            if len(train) < MIN_TRAIN_YEARS or test.empty:\n",
    "                continue\n",
    "\n",
    "            X_train = train[feature_cols]\n",
    "            y_train = train[\"Budget_Amount\"].astype(float)\n",
    "            X_test = test[feature_cols]\n",
    "            y_test = test[\"Budget_Amount\"].astype(float)\n",
    "\n",
    "            row = {\"Base_Ministry\": ministry, \"Fiscal_Year\": test[\"Fiscal_Year\"].iloc[0], \"Year_End\": test_year,\n",
    "                   \"Actual_Budget\": float(y_test.iloc[0]) if not y_test.isna().all() else np.nan}\n",
    "\n",
    "            for name, model in models.items():\n",
    "                try:\n",
    "                    if USE_LOG_TARGET:\n",
    "                        y_tr = np.log1p(y_train)\n",
    "                        model.fit(X_train, y_tr)\n",
    "                        y_pred = float(np.expm1(model.predict(X_test))[0])\n",
    "                    else:\n",
    "                        model.fit(X_train, y_train)\n",
    "                        y_pred = float(model.predict(X_test)[0])\n",
    "                    row[f\"{name}_Prediction\"] = y_pred\n",
    "                except Exception:\n",
    "                    row[f\"{name}_Prediction\"] = np.nan\n",
    "            preds_rows.append(row)\n",
    "\n",
    "    preds = pd.DataFrame(preds_rows)\n",
    "\n",
    "    # Metrics aggregated across all backtest forecasts\n",
    "    metrics = []\n",
    "    for name in models.keys():\n",
    "        col = f\"{name}_Prediction\"\n",
    "        valid = preds.dropna(subset=[col, \"Actual_Budget\"]).copy()\n",
    "        if valid.empty:\n",
    "            continue\n",
    "        y_true = valid[\"Actual_Budget\"].values.astype(float)\n",
    "        y_pred = valid[col].values.astype(float)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mape = float(np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), 1e-12))) * 100.0)\n",
    "        metrics.append({\"Model\": name, \"Count\": len(valid), \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE_%\": mape})\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics).sort_values(\"MAE\")\n",
    "\n",
    "    # Save\n",
    "    OUT_PRED.parent.mkdir(parents=True, exist_ok=True)\n",
    "    preds.to_csv(OUT_PRED, index=False)\n",
    "    metrics_df.to_csv(OUT_METRICS, index=False)\n",
    "    print(f\"Saved predictions: {OUT_PRED}\")\n",
    "    print(f\"Saved metrics:     {OUT_METRICS}\")\n",
    "    if not metrics_df.empty:\n",
    "        print(metrics_df.to_string(index=False))\n",
    "\n",
    "    # Basic plots\n",
    "    if not metrics_df.empty and not preds.empty:\n",
    "        # Metrics bars\n",
    "        for metric in [\"MAE\", \"RMSE\", \"MAPE_%\", \"R2\"]:\n",
    "            if metric not in metrics_df.columns:\n",
    "                continue\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            order = metrics_df.sort_values(metric, ascending=(metric != \"R2\"))[\"Model\"]\n",
    "            sns.barplot(data=metrics_df, x=\"Model\", y=metric, order=order)\n",
    "            plt.title(f\"Backtest {metric} by model\")\n",
    "            plt.tight_layout()\n",
    "            out = PLOTS / f\"backtest_{metric.lower()}.png\"\n",
    "            plt.savefig(out, dpi=300); plt.close()\n",
    "            print(f\"Saved: {out}\")\n",
    "\n",
    "        # Error over years for best model\n",
    "        best = metrics_df.iloc[0][\"Model\"]\n",
    "        col = f\"{best}_Prediction\"\n",
    "        year_err = preds.dropna(subset=[col, \"Actual_Budget\"]).copy()\n",
    "        year_err[\"Abs_Error\"] = (year_err[col] - year_err[\"Actual_Budget\"]).abs()\n",
    "        yearly = year_err.groupby(\"Year_End\")[\"Abs_Error\"].median().reset_index()\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.lineplot(data=yearly, x=\"Year_End\", y=\"Abs_Error\", marker=\"o\")\n",
    "        plt.title(f\"Median absolute error over years ({best})\")\n",
    "        plt.tight_layout()\n",
    "        out = PLOTS / \"backtest_error_over_years.png\"\n",
    "        plt.savefig(out, dpi=300); plt.close()\n",
    "        print(f\"Saved: {out}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7b42b",
   "metadata": {},
   "source": [
    "5. Model comparison and diagnostics (backtest vs single‑year)\n",
    "\n",
    "- Builds a combined leaderboard of metrics from both runs (MAE/RMSE/R2/MAPE + MedianAE/P90AE/Hit10%/Hit20%).\n",
    "- Checks rank agreement between backtest and single‑year (Kendall tau).\n",
    "- Finds hardest/easiest ministries (median absolute error) for the best backtest model.\n",
    "- Compares FY 23‑24 absolute errors to each ministry’s historical median error.\n",
    "- Quick calibration for the best model (Pred vs Actual linear fit) to detect systematic bias.\n",
    "```5. Model comparison and diagnostics (backtest vs single‑year)\n",
    "\n",
    "- Builds a combined leaderboard of metrics from both runs (MAE/RMSE/R2/MAPE + MedianAE/P90AE/Hit10%/Hit20%).\n",
    "- Checks rank agreement between backtest and single‑year (Kendall tau).\n",
    "- Finds hardest/easiest ministries (median absolute error) for the best backtest model.\n",
    "- Compares FY 23‑24 absolute errors to each ministry’s historical median error.\n",
    "- Quick calibration for the best model (Pred vs Actual linear fit) to detect systematic bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de96fb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined leaderboard (backtest first):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>BT_Count_x</th>\n",
       "      <th>BT_MedianAE</th>\n",
       "      <th>BT_P90AE</th>\n",
       "      <th>BT_MeanError</th>\n",
       "      <th>BT_Hit10%</th>\n",
       "      <th>BT_Hit20%</th>\n",
       "      <th>Single_Count_x</th>\n",
       "      <th>Single_MedianAE</th>\n",
       "      <th>Single_P90AE</th>\n",
       "      <th>...</th>\n",
       "      <th>BT_Count_y</th>\n",
       "      <th>BT_MAE</th>\n",
       "      <th>BT_RMSE</th>\n",
       "      <th>BT_R2</th>\n",
       "      <th>BT_MAPE_%</th>\n",
       "      <th>Single_Count_y</th>\n",
       "      <th>Single_MAE</th>\n",
       "      <th>Single_RMSE</th>\n",
       "      <th>Single_R2</th>\n",
       "      <th>Single_MAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBM</td>\n",
       "      <td>549</td>\n",
       "      <td>1219.428844</td>\n",
       "      <td>33454.128934</td>\n",
       "      <td>-5.638307e+03</td>\n",
       "      <td>18.943534</td>\n",
       "      <td>39.162113</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2883.914091</td>\n",
       "      <td>27527.437481</td>\n",
       "      <td>...</td>\n",
       "      <td>549</td>\n",
       "      <td>1.085168e+04</td>\n",
       "      <td>3.434682e+04</td>\n",
       "      <td>5.502673e-01</td>\n",
       "      <td>1.273510e+02</td>\n",
       "      <td>61.0</td>\n",
       "      <td>8315.143387</td>\n",
       "      <td>18891.344179</td>\n",
       "      <td>0.876074</td>\n",
       "      <td>180.666640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>549</td>\n",
       "      <td>1549.772501</td>\n",
       "      <td>36820.062055</td>\n",
       "      <td>-7.531923e+03</td>\n",
       "      <td>10.018215</td>\n",
       "      <td>25.500911</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3547.925000</td>\n",
       "      <td>28403.459967</td>\n",
       "      <td>...</td>\n",
       "      <td>549</td>\n",
       "      <td>1.227256e+04</td>\n",
       "      <td>3.379402e+04</td>\n",
       "      <td>5.646273e-01</td>\n",
       "      <td>1.126442e+02</td>\n",
       "      <td>61.0</td>\n",
       "      <td>10427.826005</td>\n",
       "      <td>23416.769803</td>\n",
       "      <td>0.809589</td>\n",
       "      <td>151.629900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HGB</td>\n",
       "      <td>549</td>\n",
       "      <td>2365.908499</td>\n",
       "      <td>51710.063909</td>\n",
       "      <td>-9.816809e+03</td>\n",
       "      <td>5.282332</td>\n",
       "      <td>9.289617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>549</td>\n",
       "      <td>1.662989e+04</td>\n",
       "      <td>4.008722e+04</td>\n",
       "      <td>3.873767e-01</td>\n",
       "      <td>1.086272e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>549</td>\n",
       "      <td>1444.737600</td>\n",
       "      <td>29355.372091</td>\n",
       "      <td>1.737282e+14</td>\n",
       "      <td>20.400729</td>\n",
       "      <td>37.887067</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3342.977253</td>\n",
       "      <td>25206.988093</td>\n",
       "      <td>...</td>\n",
       "      <td>549</td>\n",
       "      <td>1.737282e+14</td>\n",
       "      <td>4.070558e+15</td>\n",
       "      <td>-6.316689e+21</td>\n",
       "      <td>2.840390e+11</td>\n",
       "      <td>61.0</td>\n",
       "      <td>10911.426538</td>\n",
       "      <td>23961.010083</td>\n",
       "      <td>0.800635</td>\n",
       "      <td>154.165701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear</td>\n",
       "      <td>549</td>\n",
       "      <td>1958.822291</td>\n",
       "      <td>81094.839575</td>\n",
       "      <td>4.766114e+19</td>\n",
       "      <td>19.672131</td>\n",
       "      <td>34.426230</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2033.639473</td>\n",
       "      <td>30396.899049</td>\n",
       "      <td>...</td>\n",
       "      <td>549</td>\n",
       "      <td>4.766114e+19</td>\n",
       "      <td>1.116735e+21</td>\n",
       "      <td>-4.754251e+32</td>\n",
       "      <td>1.500797e+18</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9721.463409</td>\n",
       "      <td>19071.382845</td>\n",
       "      <td>0.873700</td>\n",
       "      <td>194.410827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>549</td>\n",
       "      <td>5602.453669</td>\n",
       "      <td>178634.396963</td>\n",
       "      <td>2.878266e+22</td>\n",
       "      <td>4.918033</td>\n",
       "      <td>9.836066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>549</td>\n",
       "      <td>2.878266e+22</td>\n",
       "      <td>6.743993e+23</td>\n",
       "      <td>-1.733867e+38</td>\n",
       "      <td>4.705406e+19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>549</td>\n",
       "      <td>2360.605765</td>\n",
       "      <td>51385.083077</td>\n",
       "      <td>5.087235e+22</td>\n",
       "      <td>5.464481</td>\n",
       "      <td>9.471767</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1867.840112</td>\n",
       "      <td>30346.412460</td>\n",
       "      <td>...</td>\n",
       "      <td>549</td>\n",
       "      <td>5.087235e+22</td>\n",
       "      <td>1.191977e+24</td>\n",
       "      <td>-5.416483e+38</td>\n",
       "      <td>8.316640e+19</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9677.767727</td>\n",
       "      <td>19042.355135</td>\n",
       "      <td>0.874084</td>\n",
       "      <td>191.514618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  BT_Count_x  BT_MedianAE       BT_P90AE  BT_MeanError  BT_Hit10%  \\\n",
       "0     GBM         549  1219.428844   33454.128934 -5.638307e+03  18.943534   \n",
       "5      RF         549  1549.772501   36820.062055 -7.531923e+03  10.018215   \n",
       "1     HGB         549  2365.908499   51710.063909 -9.816809e+03   5.282332   \n",
       "6   Ridge         549  1444.737600   29355.372091  1.737282e+14  20.400729   \n",
       "3  Linear         549  1958.822291   81094.839575  4.766114e+19  19.672131   \n",
       "4     MLP         549  5602.453669  178634.396963  2.878266e+22   4.918033   \n",
       "2   Lasso         549  2360.605765   51385.083077  5.087235e+22   5.464481   \n",
       "\n",
       "   BT_Hit20%  Single_Count_x  Single_MedianAE  Single_P90AE  ...  BT_Count_y  \\\n",
       "0  39.162113            61.0      2883.914091  27527.437481  ...         549   \n",
       "5  25.500911            61.0      3547.925000  28403.459967  ...         549   \n",
       "1   9.289617             NaN              NaN           NaN  ...         549   \n",
       "6  37.887067            61.0      3342.977253  25206.988093  ...         549   \n",
       "3  34.426230            61.0      2033.639473  30396.899049  ...         549   \n",
       "4   9.836066             NaN              NaN           NaN  ...         549   \n",
       "2   9.471767            61.0      1867.840112  30346.412460  ...         549   \n",
       "\n",
       "         BT_MAE       BT_RMSE         BT_R2     BT_MAPE_%  Single_Count_y  \\\n",
       "0  1.085168e+04  3.434682e+04  5.502673e-01  1.273510e+02            61.0   \n",
       "5  1.227256e+04  3.379402e+04  5.646273e-01  1.126442e+02            61.0   \n",
       "1  1.662989e+04  4.008722e+04  3.873767e-01  1.086272e+02             NaN   \n",
       "6  1.737282e+14  4.070558e+15 -6.316689e+21  2.840390e+11            61.0   \n",
       "3  4.766114e+19  1.116735e+21 -4.754251e+32  1.500797e+18            61.0   \n",
       "4  2.878266e+22  6.743993e+23 -1.733867e+38  4.705406e+19             NaN   \n",
       "2  5.087235e+22  1.191977e+24 -5.416483e+38  8.316640e+19            61.0   \n",
       "\n",
       "     Single_MAE   Single_RMSE  Single_R2  Single_MAPE_%  \n",
       "0   8315.143387  18891.344179   0.876074     180.666640  \n",
       "5  10427.826005  23416.769803   0.809589     151.629900  \n",
       "1           NaN           NaN        NaN            NaN  \n",
       "6  10911.426538  23961.010083   0.800635     154.165701  \n",
       "3   9721.463409  19071.382845   0.873700     194.410827  \n",
       "4           NaN           NaN        NaN            NaN  \n",
       "2   9677.767727  19042.355135   0.874084     191.514618  \n",
       "\n",
       "[7 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank agreement (Kendall tau) between backtest and single-year MAE: 0.00 (p=1.000)\n",
      "Hardest ministries (median AE) for GBM:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Base_Ministry\n",
       "Rural Development                            58544.670265\n",
       "Agriculture and Cooperation                  44414.433090\n",
       "Road Transport and Highways                  43809.813699\n",
       "Food and Public Distribution                 37742.484652\n",
       "Elementary Education and Literacy            36993.951751\n",
       "Defence Services                             33441.248682\n",
       "Defence (Civil estimates)                    25222.581700\n",
       "Economic Affairs (centralised provisions)    19883.838692\n",
       "Health                                       17919.689064\n",
       "Drinking Water Supply                        17764.789790\n",
       "Name: AbsErr, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easiest ministries (median AE) for GBM:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Base_Ministry\n",
       "Public Enterprises              1.923152\n",
       "Parliamentary Affairs           3.676922\n",
       "Steel                          37.454800\n",
       "Shipping                       86.880021\n",
       "Company Affairs               115.630182\n",
       "Small Scale Industries        189.917503\n",
       "Food Processing Industries    190.295823\n",
       "Mines                         202.925571\n",
       "Land Resources                208.906937\n",
       "Tourism                       224.311187\n",
       "Name: AbsErr, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FY23-24 AE vs historical median AE (best model):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base_Ministry</th>\n",
       "      <th>AE_2324</th>\n",
       "      <th>Hist_MedianAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Road Transport and Highways</td>\n",
       "      <td>87063.467026</td>\n",
       "      <td>43809.813699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fertilisers</td>\n",
       "      <td>71781.230179</td>\n",
       "      <td>13544.143871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agriculture and Cooperation</td>\n",
       "      <td>62355.813946</td>\n",
       "      <td>44414.433090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Economic Affairs (centralised provisions)</td>\n",
       "      <td>35655.418802</td>\n",
       "      <td>19883.838692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>32925.598474</td>\n",
       "      <td>10743.425372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Elementary Education and Literacy</td>\n",
       "      <td>30959.097668</td>\n",
       "      <td>36993.951751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rural Development</td>\n",
       "      <td>27527.437481</td>\n",
       "      <td>58544.670265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Personnel, Public Grievances and Pensions</td>\n",
       "      <td>14679.729538</td>\n",
       "      <td>10294.790873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Drinking Water Supply</td>\n",
       "      <td>12417.719686</td>\n",
       "      <td>17764.789790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Health</td>\n",
       "      <td>10094.893491</td>\n",
       "      <td>17919.689064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Tribal Affairs</td>\n",
       "      <td>9088.333414</td>\n",
       "      <td>1954.819718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Culture</td>\n",
       "      <td>8311.649626</td>\n",
       "      <td>15227.049228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Textiles</td>\n",
       "      <td>7512.410886</td>\n",
       "      <td>1576.410808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Civil Aviation</td>\n",
       "      <td>6588.354545</td>\n",
       "      <td>1409.541750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Urban Development</td>\n",
       "      <td>6479.840866</td>\n",
       "      <td>14773.858049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Base_Ministry       AE_2324  Hist_MedianAE\n",
       "42                Road Transport and Highways  87063.467026   43809.813699\n",
       "22                                Fertilisers  71781.230179   13544.143871\n",
       "1                 Agriculture and Cooperation  62355.813946   44414.433090\n",
       "18  Economic Affairs (centralised provisions)  35655.418802   19883.838692\n",
       "53                         Telecommunications  32925.598474   10743.425372\n",
       "19          Elementary Education and Literacy  30959.097668   36993.951751\n",
       "43                          Rural Development  27527.437481   58544.670265\n",
       "37  Personnel, Public Grievances and Pensions  14679.729538   10294.790873\n",
       "17                      Drinking Water Supply  12417.719686   17764.789790\n",
       "25                                     Health  10094.893491   17919.689064\n",
       "56                             Tribal Affairs   9088.333414    1954.819718\n",
       "13                                    Culture   8311.649626   15227.049228\n",
       "54                                   Textiles   7512.410886    1576.410808\n",
       "8                              Civil Aviation   6588.354545    1409.541750\n",
       "57                          Urban Development   6479.840866   14773.858049"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration (single-year, GBM): Pred ≈ 0.757 * Actual + 3415.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "pred_single = pd.read_csv(BASE / \"ministry_macro_predictions.csv\")\n",
    "met_single  = pd.read_csv(BASE / \"macro_model_metrics.csv\")\n",
    "pred_bt     = pd.read_csv(BASE / \"ministry_macro_backtest_predictions.csv\")\n",
    "met_bt      = pd.read_csv(BASE / \"macro_model_metrics_backtest.csv\")\n",
    "\n",
    "# 1) Build per‑model error summaries\n",
    "def summarize_preds(df: pd.DataFrame, label: str):\n",
    "    rows = []\n",
    "    model_cols = [c for c in df.columns if c.endswith(\"_Prediction\")]\n",
    "    for mc in model_cols:\n",
    "        name = mc.replace(\"_Prediction\",\"\")\n",
    "        valid = df.dropna(subset=[\"Actual_Budget\", mc]).copy()\n",
    "        if valid.empty: \n",
    "            continue\n",
    "        ae = (valid[mc] - valid[\"Actual_Budget\"]).abs()\n",
    "        pe = ae / np.maximum(valid[\"Actual_Budget\"].abs(), 1e-12)\n",
    "        rows.append({\n",
    "            \"Model\": name,\n",
    "            f\"{label}_Count\": len(valid),\n",
    "            f\"{label}_MedianAE\": float(ae.median()),\n",
    "            f\"{label}_P90AE\": float(ae.quantile(0.90)),\n",
    "            f\"{label}_MeanError\": float((valid[mc] - valid[\"Actual_Budget\"]).mean()),\n",
    "            f\"{label}_Hit10%\": float((pe <= 0.10).mean()*100.0),\n",
    "            f\"{label}_Hit20%\": float((pe <= 0.20).mean()*100.0),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "sum_single = summarize_preds(pred_single, \"Single\")\n",
    "sum_bt     = summarize_preds(pred_bt, \"BT\")\n",
    "\n",
    "# 2) Merge with your existing metrics (MAE/RMSE/R2/MAPE)\n",
    "met_single = met_single.rename(columns={c: f\"Single_{c}\" for c in met_single.columns if c!=\"Model\"})\n",
    "met_bt     = met_bt.rename(columns={c: f\"BT_{c}\" for c in met_bt.columns if c!=\"Model\"})\n",
    "\n",
    "leaderboard = (\n",
    "    sum_bt.merge(sum_single, on=\"Model\", how=\"outer\")\n",
    "          .merge(met_bt, on=\"Model\", how=\"outer\")\n",
    "          .merge(met_single, on=\"Model\", how=\"outer\")\n",
    ").sort_values(\"BT_MAE\", na_position=\"last\")\n",
    "\n",
    "print(\"Combined leaderboard (backtest first):\")\n",
    "display(leaderboard)\n",
    "\n",
    "# 3) Do rankings agree? (Kendall rank correlation on MAE)\n",
    "rank_bt = leaderboard[[\"Model\",\"BT_MAE\"]].dropna().sort_values(\"BT_MAE\")\n",
    "rank_sg = leaderboard[[\"Model\",\"Single_MAE\"]].dropna().sort_values(\"Single_MAE\")\n",
    "common  = rank_bt.merge(rank_sg, on=\"Model\", how=\"inner\")\n",
    "if len(common) >= 2:\n",
    "    tau, p = kendalltau(common[\"BT_MAE\"].rank(), common[\"Single_MAE\"].rank())\n",
    "    print(f\"Rank agreement (Kendall tau) between backtest and single-year MAE: {tau:.2f} (p={p:.3f})\")\n",
    "else:\n",
    "    print(\"Not enough common models to compare ranks.\")\n",
    "\n",
    "# 4) Per-ministry difficulty (best backtest model)\n",
    "best = leaderboard.iloc[0][\"Model\"]\n",
    "col  = f\"{best}_Prediction\"\n",
    "per_min = pred_bt.dropna(subset=[\"Actual_Budget\", col]).copy()\n",
    "per_min[\"AbsErr\"] = (per_min[col] - per_min[\"Actual_Budget\"]).abs()\n",
    "hardest = per_min.groupby(\"Base_Ministry\")[\"AbsErr\"].median().sort_values(ascending=False).head(10)\n",
    "easiest = per_min.groupby(\"Base_Ministry\")[\"AbsErr\"].median().sort_values().head(10)\n",
    "print(f\"Hardest ministries (median AE) for {best}:\")\n",
    "display(hardest)\n",
    "print(f\"Easiest ministries (median AE) for {best}:\")\n",
    "display(easiest)\n",
    "\n",
    "# 5) FY23-24 vs history consistency for best model\n",
    "sg = pred_single.dropna(subset=[\"Actual_Budget\", f\"{best}_Prediction\"]).copy()\n",
    "sg[\"AE_2324\"] = (sg[f\"{best}_Prediction\"] - sg[\"Actual_Budget\"]).abs()\n",
    "hist = per_min.groupby(\"Base_Ministry\")[\"AbsErr\"].median().rename(\"Hist_MedianAE\")\n",
    "cmp = sg.merge(hist, on=\"Base_Ministry\", how=\"left\")[[\"Base_Ministry\",\"AE_2324\",\"Hist_MedianAE\"]]\n",
    "print(\"FY23-24 AE vs historical median AE (best model):\")\n",
    "display(cmp.sort_values(\"AE_2324\", ascending=False).head(15))\n",
    "\n",
    "# 6) Optional: quick calibration check for best model (single-year)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = sg[[\"Actual_Budget\"]].values\n",
    "y = sg[f\"{best}_Prediction\"].values\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print(f\"Calibration (single-year, {best}): Pred ≈ {reg.coef_[0]:.3f} * Actual + {reg.intercept_:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
