{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e49cea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using budgets: /Users/vvmohith/Desktop/PROJECT/final_data/data/standardized_budget_time_series.csv\n",
      "Using mapping: /Users/vvmohith/Desktop/PROJECT/final_data/data/ministry_to_sector12.csv\n",
      "Will save to : /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_ministry_timeseries.csv\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_ministry_timeseries.csv\n",
      "Preview:\n",
      "                        Sector_12                        Base_Ministry  \\\n",
      "0    agriculture forestry fishing  Agricultural Research and Education   \n",
      "61   agriculture forestry fishing  Agricultural Research and Education   \n",
      "122  agriculture forestry fishing  Agricultural Research and Education   \n",
      "183  agriculture forestry fishing  Agricultural Research and Education   \n",
      "244  agriculture forestry fishing  Agricultural Research and Education   \n",
      "305  agriculture forestry fishing  Agricultural Research and Education   \n",
      "366  agriculture forestry fishing  Agricultural Research and Education   \n",
      "427  agriculture forestry fishing  Agricultural Research and Education   \n",
      "488  agriculture forestry fishing  Agricultural Research and Education   \n",
      "549  agriculture forestry fishing  Agricultural Research and Education   \n",
      "\n",
      "    Fiscal_Year  Year_End  Budget_Amount  Sector_Total  Ministry_Share_Sector  \n",
      "0         05-06      2006        1942.00      27237.86               0.071298  \n",
      "61        06-07      2007        2160.00      38240.82               0.056484  \n",
      "122       07-08      2008        2460.00      44713.38               0.055017  \n",
      "183       09-10      2010        3241.40      86589.42               0.037434  \n",
      "244       10-11      2011        3818.05      93610.87               0.040786  \n",
      "305       11-12      2012        4957.60     104371.66               0.047499  \n",
      "366       12-13      2013        5392.00     109450.59               0.049264  \n",
      "427       13-14      2014        5729.17     115835.73               0.049459  \n",
      "488       15-16      2016        6320.00      21637.71               0.292083  \n",
      "549       16-17      2017        6620.00      41329.78               0.160175  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Build sector-ministry time series → final_data/data_2/data/sector_ministry_timeseries.csv\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "DATA = ROOT / \"data\"\n",
    "DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prefer inputs from data_2/data, fallback to final_data/data\n",
    "CANDIDATE_IN_DIRS = [DATA, BASE / \"data\"]\n",
    "\n",
    "def resolve_input(filename: str) -> Path:\n",
    "    for d in CANDIDATE_IN_DIRS:\n",
    "        p = d / filename\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return DATA / filename\n",
    "\n",
    "def tidy_ministry(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
    "\n",
    "def fy_end_year_short(s: str) -> int:\n",
    "    s = str(s).strip()\n",
    "    m = re.fullmatch(r\"(\\d{2})-(\\d{2})\", s)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unexpected Fiscal_Year format: {s}\")\n",
    "    return 2000 + int(m.group(2))\n",
    "\n",
    "IN_BUDGETS = resolve_input(\"standardized_budget_time_series.csv\")\n",
    "IN_MAP     = resolve_input(\"ministry_to_sector12.csv\")\n",
    "OUT_MIN    = DATA / \"sector_ministry_timeseries.csv\"\n",
    "\n",
    "print(f\"Using budgets: {IN_BUDGETS}\")\n",
    "print(f\"Using mapping: {IN_MAP}\")\n",
    "print(f\"Will save to : {OUT_MIN}\")\n",
    "\n",
    "# Load standardized budgets\n",
    "dfb = pd.read_csv(IN_BUDGETS, dtype={\"Base_Ministry\": \"string\"})\n",
    "dfb[\"Base_Ministry\"] = dfb[\"Base_Ministry\"].map(tidy_ministry)\n",
    "\n",
    "# Find FY columns like 05-06\n",
    "fy_cols = [c for c in dfb.columns if re.fullmatch(r\"\\d{2}-\\d{2}\", str(c))]\n",
    "if not fy_cols:\n",
    "    raise RuntimeError(\"No fiscal-year columns found (expected yy-yy like 05-06).\")\n",
    "\n",
    "# Coerce numerics; collapse duplicate ministry rows if any\n",
    "dfb[fy_cols] = (\n",
    "    dfb[fy_cols]\n",
    "    .replace(r\"[, \\t]\", \"\", regex=True)\n",
    "    .replace(\"\", np.nan)\n",
    "    .apply(pd.to_numeric, errors=\"coerce\")\n",
    ")\n",
    "dfb = dfb.groupby(\"Base_Ministry\", as_index=False)[fy_cols].sum(min_count=1)\n",
    "\n",
    "# Melt to long at ministry level\n",
    "long = (\n",
    "    dfb.melt(\n",
    "        id_vars=\"Base_Ministry\",\n",
    "        value_vars=fy_cols,\n",
    "        var_name=\"Fiscal_Year\",\n",
    "        value_name=\"Budget_Amount\",\n",
    "    )\n",
    "    .dropna(subset=[\"Budget_Amount\"])\n",
    ")\n",
    "\n",
    "# Map Base_Ministry → Sector_12\n",
    "map_df = pd.read_csv(IN_MAP, dtype={\"Base_Ministry\": \"string\", \"Sector_12\": \"string\"})\n",
    "map_df[\"Base_Ministry\"] = map_df[\"Base_Ministry\"].map(tidy_ministry)\n",
    "map_df[\"Sector_12\"] = map_df[\"Sector_12\"].astype(\"string\").str.strip()\n",
    "\n",
    "min_panel = long.merge(map_df, on=\"Base_Ministry\", how=\"left\")\n",
    "missing = min_panel[min_panel[\"Sector_12\"].isna()][\"Base_Ministry\"].dropna().unique().tolist()\n",
    "if missing:\n",
    "    print(f\"Warning: {len(missing)} ministries unmapped to Sector_12. Dropping them.\")\n",
    "min_panel = min_panel.dropna(subset=[\"Sector_12\"])\n",
    "\n",
    "# Compute Year_End, Sector totals, and shares\n",
    "min_panel[\"Year_End\"] = min_panel[\"Fiscal_Year\"].map(fy_end_year_short)\n",
    "min_panel[\"Sector_Total\"] = (\n",
    "    min_panel.groupby([\"Sector_12\", \"Fiscal_Year\"])[\"Budget_Amount\"].transform(\"sum\")\n",
    ")\n",
    "min_panel[\"Ministry_Share_Sector\"] = min_panel[\"Budget_Amount\"] / min_panel[\"Sector_Total\"]\n",
    "\n",
    "# Reorder columns and sort\n",
    "min_panel = min_panel[\n",
    "    [\"Sector_12\", \"Base_Ministry\", \"Fiscal_Year\", \"Year_End\", \"Budget_Amount\", \"Sector_Total\", \"Ministry_Share_Sector\"]\n",
    "].sort_values([\"Sector_12\", \"Base_Ministry\", \"Year_End\"])\n",
    "\n",
    "# Save\n",
    "min_panel.to_csv(OUT_MIN, index=False)\n",
    "print(f\"Saved: {OUT_MIN}\")\n",
    "print(\"Preview:\")\n",
    "print(min_panel.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f73f29",
   "metadata": {},
   "source": [
    "1. Build sector budget time series\n",
    "* Input: data/standardized_budget_time_series.csv, data/ministry_to_sector12.csv\n",
    "* Clean Base_Ministry, melt FY columns (yy-yy), map to Sector_12, drop unmapped, aggregate to (Sector_12, Fiscal_Year).\n",
    "* Output: data/sector_budget_timeseries.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c4d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using budgets: /Users/vvmohith/Desktop/PROJECT/final_data/data/standardized_budget_time_series.csv\n",
      "Using mapping: /Users/vvmohith/Desktop/PROJECT/final_data/data/ministry_to_sector12.csv\n",
      "Will save to : /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_timeseries.csv\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_timeseries.csv\n",
      "Sectors: 11, Years: 17, Rows: 187\n",
      "Year span: 05-06 → 23-24\n",
      "                      Sector_12 Fiscal_Year  Budget_Amount\n",
      "0  agriculture forestry fishing       05-06       27237.86\n",
      "1  agriculture forestry fishing       06-07       38240.82\n",
      "2  agriculture forestry fishing       07-08       44713.38\n",
      "3  agriculture forestry fishing       09-10       86589.42\n",
      "4  agriculture forestry fishing       10-11       93610.87\n",
      "5  agriculture forestry fishing       11-12      104371.66\n",
      "6  agriculture forestry fishing       12-13      109450.59\n",
      "7  agriculture forestry fishing       13-14      115835.73\n",
      "8  agriculture forestry fishing       15-16       21637.71\n",
      "9  agriculture forestry fishing       16-17       41329.78\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Build sector budget time series → data_2/data/sector_budget_timeseries.csv\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "DATA = ROOT / \"data\"\n",
    "DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prefer inputs from data_2/data, fallback to final_data/data\n",
    "CANDIDATE_IN_DIRS = [DATA, BASE / \"data\"]\n",
    "\n",
    "def resolve_input(filename: str) -> Path:\n",
    "    for d in CANDIDATE_IN_DIRS:\n",
    "        p = d / filename\n",
    "        if p.exists():\n",
    "            return p\n",
    "    # Default to data_2/data (even if missing) to make path explicit\n",
    "    return DATA / filename\n",
    "\n",
    "IN_BUDGETS = resolve_input(\"standardized_budget_time_series.csv\")\n",
    "IN_MAP     = resolve_input(\"ministry_to_sector12.csv\")\n",
    "OUT_SECTOR = DATA / \"sector_budget_timeseries.csv\"\n",
    "\n",
    "print(f\"Using budgets: {IN_BUDGETS}\")\n",
    "print(f\"Using mapping: {IN_MAP}\")\n",
    "print(f\"Will save to : {OUT_SECTOR}\")\n",
    "\n",
    "def tidy_ministry(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
    "\n",
    "# Load budgets\n",
    "dfb = pd.read_csv(IN_BUDGETS, dtype={\"Base_Ministry\": \"string\"})\n",
    "dfb[\"Base_Ministry\"] = dfb[\"Base_Ministry\"].map(tidy_ministry)\n",
    "\n",
    "# Identify FY columns like 05-06, 23-24, etc.\n",
    "fy_cols = [c for c in dfb.columns if re.fullmatch(r\"\\d{2}-\\d{2}\", str(c))]\n",
    "if not fy_cols:\n",
    "    raise RuntimeError(\"No fiscal-year columns found in standardized_budget_time_series.csv (expected yy-yy like 05-06).\")\n",
    "\n",
    "# Sort FY columns by end year (...05-06, 06-07, ..., 24-25)\n",
    "def fy_end_year(col: str) -> int:\n",
    "    end = int(str(col).split(\"-\")[1])\n",
    "    return 2000 + end\n",
    "\n",
    "fy_cols = sorted(fy_cols, key=fy_end_year)\n",
    "\n",
    "# Coerce numbers (remove commas/spaces), sum duplicates per ministry if any\n",
    "dfb[fy_cols] = (\n",
    "    dfb[fy_cols]\n",
    "    .replace(r\"[, \\t]\", \"\", regex=True)\n",
    "    .replace(\"\", np.nan)\n",
    "    .apply(pd.to_numeric, errors=\"coerce\")\n",
    ")\n",
    "dfb = dfb.groupby(\"Base_Ministry\", as_index=False)[fy_cols].sum(min_count=1)\n",
    "\n",
    "# Melt to long\n",
    "long = (\n",
    "    dfb.melt(\n",
    "        id_vars=\"Base_Ministry\",\n",
    "        value_vars=fy_cols,\n",
    "        var_name=\"Fiscal_Year\",\n",
    "        value_name=\"Budget_Amount\",\n",
    "    )\n",
    "    .dropna(subset=[\"Budget_Amount\"])\n",
    ")\n",
    "\n",
    "# Load mapping and clean keys\n",
    "map_df = pd.read_csv(IN_MAP, dtype={\"Base_Ministry\": \"string\", \"Sector_12\": \"string\"})\n",
    "map_df[\"Base_Ministry\"] = map_df[\"Base_Ministry\"].map(tidy_ministry)\n",
    "map_df[\"Sector_12\"] = map_df[\"Sector_12\"].astype(\"string\").str.strip()\n",
    "\n",
    "# Join mapping\n",
    "merged = long.merge(map_df, on=\"Base_Ministry\", how=\"left\")\n",
    "\n",
    "# Report unmapped ministries\n",
    "unmapped = merged[merged[\"Sector_12\"].isna()][\"Base_Ministry\"].dropna().unique().tolist()\n",
    "if unmapped:\n",
    "    print(f\"Warning: {len(unmapped)} ministries have no Sector_12 mapping. Dropping these rows.\")\n",
    "    print(\"Examples:\", unmapped[:10])\n",
    "\n",
    "# Drop unmapped and aggregate to Sector_12\n",
    "merged = merged.dropna(subset=[\"Sector_12\"])\n",
    "sector_ts = (\n",
    "    merged.groupby([\"Sector_12\", \"Fiscal_Year\"], as_index=False)\n",
    "          .agg(Budget_Amount=(\"Budget_Amount\", \"sum\"))\n",
    ")\n",
    "\n",
    "# Sort and save\n",
    "sector_ts = sector_ts.sort_values(\n",
    "    [\"Sector_12\", \"Fiscal_Year\"],\n",
    "    key=lambda s: s if s.name != \"Fiscal_Year\" else s.str.split(\"-\").str[1].astype(int)\n",
    ")\n",
    "sector_ts.to_csv(OUT_SECTOR, index=False)\n",
    "\n",
    "# Summary\n",
    "years = sorted(sector_ts[\"Fiscal_Year\"].unique(), key=lambda s: int(s.split(\"-\")[1]))\n",
    "print(f\"Saved: {OUT_SECTOR}\")\n",
    "print(f\"Sectors: {sector_ts['Sector_12'].nunique()}, Years: {len(years)}, Rows: {len(sector_ts)}\")\n",
    "print(\"Year span:\", years[0], \"→\", years[-1])\n",
    "print(sector_ts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25433d7",
   "metadata": {},
   "source": [
    "2.Integrate macro indicators\n",
    "* Input: data/macro_indicators_wb.csv\n",
    "* Keep: GDP_Growth_Rate, Inflation_CPI, Exchange_Rate_USD, Fiscal_Deficit_GDP, Global_GDP_Growth, Election_Year, High_Inflation, GDP_Growth_Lag1, Inflation_Lag1.\n",
    "* Left-join on Fiscal_Year.\n",
    "* Output: data/sector_budget_macro.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999da720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sector time series: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_timeseries.csv\n",
      "Using macro indicators : /Users/vvmohith/Desktop/PROJECT/final_data/data/macro_indicators_wb.csv\n",
      "Will save to           : /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_macro.csv\n",
      "\n",
      "Diagnostics:\n",
      "Sector FY count: 17 rows: 187\n",
      "Macro  FY count: 20 rows: 20\n",
      "FYs with missing lag values (expected for first available FY if prior year absent): ['05-06']\n",
      "\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_macro.csv\n",
      "Preview:\n",
      "                      Sector_12 Fiscal_Year  Budget_Amount  GDP_Growth_Rate  \\\n",
      "0  agriculture forestry fishing       05-06       27237.86         8.060733   \n",
      "1  agriculture forestry fishing       06-07       38240.82         7.660815   \n",
      "2  agriculture forestry fishing       07-08       44713.38         3.086698   \n",
      "3  agriculture forestry fishing       09-10       86589.42         8.497585   \n",
      "4  agriculture forestry fishing       10-11       93610.87         5.241316   \n",
      "5  agriculture forestry fishing       11-12      104371.66         5.456388   \n",
      "6  agriculture forestry fishing       12-13      109450.59         6.386106   \n",
      "7  agriculture forestry fishing       13-14      115835.73         7.410228   \n",
      "8  agriculture forestry fishing       15-16       21637.71         8.256306   \n",
      "9  agriculture forestry fishing       16-17       41329.78         6.795383   \n",
      "\n",
      "   Inflation_CPI  Exchange_Rate_USD  Fiscal_Deficit_GDP  Global_GDP_Growth  \\\n",
      "0            4.2              44.27                 4.0                4.1   \n",
      "1            6.6              45.28                 3.4                4.3   \n",
      "2            6.2              40.24                 2.7                3.0   \n",
      "3           12.3              47.42                 6.4                4.6   \n",
      "4           10.5              45.58                 6.5                3.3   \n",
      "5            8.4              47.92                 5.9                3.5   \n",
      "6           10.2              53.21                 5.9                3.4   \n",
      "7            9.4              60.50                 4.5                3.6   \n",
      "8            4.9              65.46                 3.9                3.3   \n",
      "9            4.5              67.07                 3.5                3.8   \n",
      "\n",
      "   Election_Year  High_Inflation  GDP_Growth_Lag1  Inflation_Lag1  \n",
      "0            0.0             0.0              NaN             NaN  \n",
      "1            0.0             1.0         8.060733             4.2  \n",
      "2            0.0             1.0         7.660815             6.6  \n",
      "3            1.0             1.0         7.861889             9.1  \n",
      "4            0.0             1.0         8.497585            12.3  \n",
      "5            0.0             1.0         5.241316            10.5  \n",
      "6            0.0             1.0         5.456388             8.4  \n",
      "7            0.0             1.0         6.386106            10.2  \n",
      "8            0.0             0.0         7.996254             5.9  \n",
      "9            0.0             0.0         8.256306             4.9  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Integrate macro indicators → final_data/data_2/data/sector_budget_macro.csv\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "DATA = ROOT / \"data\"\n",
    "DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prefer inputs from data_2/data, fallback to final_data/data\n",
    "CANDIDATE_IN_DIRS = [DATA, BASE / \"data\"]\n",
    "\n",
    "def resolve_input(filename: str) -> Path:\n",
    "    for d in CANDIDATE_IN_DIRS:\n",
    "        p = d / filename\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return DATA / filename  # explicit default\n",
    "\n",
    "def fy_end_year(s: str) -> int:\n",
    "    # Accept \"yy-yy\", \"yyyy-yy\", optional \"FY\" prefix, extra spaces\n",
    "    s = str(s).strip().upper().replace(\"FY\", \"\")\n",
    "    m = re.fullmatch(r\"\\s*(\\d{2,4})\\s*-\\s*(\\d{2})\\s*\", s)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unexpected Fiscal_Year format: {s}\")\n",
    "    end2 = int(m.group(2))\n",
    "    # Assume 2000s\n",
    "    return 2000 + end2\n",
    "\n",
    "def to_short_fy_from_end(end_year: int) -> str:\n",
    "    yy = end_year % 100\n",
    "    return f\"{(yy-1)%100:02d}-{yy:02d}\"\n",
    "\n",
    "IN_SECTOR = resolve_input(\"sector_budget_timeseries.csv\")\n",
    "IN_MACRO  = resolve_input(\"macro_indicators_wb.csv\")\n",
    "OUT_MERGE = DATA / \"sector_budget_macro.csv\"\n",
    "\n",
    "print(f\"Using sector time series: {IN_SECTOR}\")\n",
    "print(f\"Using macro indicators : {IN_MACRO}\")\n",
    "print(f\"Will save to           : {OUT_MERGE}\")\n",
    "\n",
    "# Load sector time series\n",
    "sector = pd.read_csv(IN_SECTOR, dtype={\"Sector_12\": \"string\", \"Fiscal_Year\": \"string\"})\n",
    "sector[\"Fiscal_Year\"] = sector[\"Fiscal_Year\"].str.strip()\n",
    "sector[\"Budget_Amount\"] = pd.to_numeric(sector[\"Budget_Amount\"], errors=\"coerce\")\n",
    "\n",
    "# Load macros\n",
    "macro_cols_pref = [\n",
    "    \"GDP_Growth_Rate\", \"Inflation_CPI\", \"Exchange_Rate_USD\", \"Fiscal_Deficit_GDP\",\n",
    "    \"Global_GDP_Growth\", \"Election_Year\", \"High_Inflation\", \"GDP_Growth_Lag1\", \"Inflation_Lag1\"\n",
    "]\n",
    "mac = pd.read_csv(IN_MACRO, dtype={\"Fiscal_Year\": \"string\"})\n",
    "mac[\"Fiscal_Year\"] = mac[\"Fiscal_Year\"].str.strip()\n",
    "\n",
    "# Keep only preferred columns that exist\n",
    "present_initial = [c for c in macro_cols_pref if c in mac.columns]\n",
    "keep_cols = [\"Fiscal_Year\"] + present_initial\n",
    "mac = mac[keep_cols].copy()\n",
    "\n",
    "# Coerce numerics\n",
    "for c in mac.columns:\n",
    "    if c != \"Fiscal_Year\":\n",
    "        mac[c] = pd.to_numeric(mac[c], errors=\"coerce\")\n",
    "\n",
    "# Normalize FY and recompute lags from base series\n",
    "mac[\"Year_End\"] = mac[\"Fiscal_Year\"].map(fy_end_year)\n",
    "mac = mac.sort_values(\"Year_End\")\n",
    "if \"GDP_Growth_Rate\" in mac.columns:\n",
    "    mac[\"GDP_Growth_Lag1\"] = mac[\"GDP_Growth_Rate\"].shift(1)\n",
    "if \"Inflation_CPI\" in mac.columns:\n",
    "    mac[\"Inflation_Lag1\"] = mac[\"Inflation_CPI\"].shift(1)\n",
    "\n",
    "# Collapse duplicates by FY (mean numeric)\n",
    "mac[\"Fiscal_Year\"] = mac[\"Year_End\"].map(to_short_fy_from_end)\n",
    "mac = mac.groupby(\"Fiscal_Year\", as_index=False).mean(numeric_only=True)\n",
    "\n",
    "# Columns present after computing lags\n",
    "present = [c for c in macro_cols_pref if c in mac.columns]\n",
    "\n",
    "# Merge (left) on Fiscal_Year\n",
    "merged = sector.merge(mac, on=\"Fiscal_Year\", how=\"left\")\n",
    "\n",
    "# Order columns\n",
    "ordered = [\"Sector_12\", \"Fiscal_Year\", \"Budget_Amount\"] + present\n",
    "merged = merged[ordered]\n",
    "\n",
    "# Diagnostics\n",
    "print(\"\\nDiagnostics:\")\n",
    "print(\"Sector FY count:\", sector[\"Fiscal_Year\"].nunique(), \"rows:\", len(sector))\n",
    "print(\"Macro  FY count:\", mac[\"Fiscal_Year\"].nunique(), \"rows:\", len(mac))\n",
    "\n",
    "lag_cols = [c for c in [\"GDP_Growth_Lag1\", \"Inflation_Lag1\"] if c in merged.columns]\n",
    "if lag_cols:\n",
    "    na_by_fy = merged.groupby(\"Fiscal_Year\")[lag_cols].apply(lambda df: df.isna().all()).reset_index()\n",
    "    na_any = na_by_fy.set_index(\"Fiscal_Year\")[lag_cols].any(axis=1)\n",
    "    if na_any.any():\n",
    "        missing_fys = na_any[na_any].index.tolist()\n",
    "        print(\"FYs with missing lag values (expected for first available FY if prior year absent):\", missing_fys)\n",
    "\n",
    "# Save\n",
    "merged.to_csv(OUT_MERGE, index=False)\n",
    "print(f\"\\nSaved: {OUT_MERGE}\")\n",
    "print(\"Preview:\")\n",
    "print(merged.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9d729",
   "metadata": {},
   "source": [
    "3.Integrate sector growth (shares of GDP)\n",
    "* Input: data/sector_shares_gdp.csv\n",
    "* Melt FY columns (YYYY-YY) to long, map sector keys → Sector_12 (normalize/fuzzy-match), convert to short FY (yy-yy).\n",
    "* Join with macro panel on (Sector_12, Fiscal_Year).\n",
    "* Output: data/sector_budget_macro_panel.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ceffd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using macro panel : /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_macro.csv\n",
      "Using sector TS   : /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_timeseries.csv\n",
      "Using shares file : /Users/vvmohith/Desktop/PROJECT/final_data/data/sector_shares_gdp.csv\n",
      "Will save to      : /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_macro_panel.csv\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_macro_panel.csv\n",
      "Macro rows: 187 → Panel rows: 187\n",
      "Share coverage in merged panel: 100.0%\n",
      "Preview:\n",
      "                      Sector_12 Fiscal_Year  Budget_Amount  GDP_Growth_Rate  \\\n",
      "0  agriculture forestry fishing       05-06       27237.86         8.060733   \n",
      "1  agriculture forestry fishing       06-07       38240.82         7.660815   \n",
      "2  agriculture forestry fishing       07-08       44713.38         3.086698   \n",
      "3  agriculture forestry fishing       09-10       86589.42         8.497585   \n",
      "4  agriculture forestry fishing       10-11       93610.87         5.241316   \n",
      "5  agriculture forestry fishing       11-12      104371.66         5.456388   \n",
      "6  agriculture forestry fishing       12-13      109450.59         6.386106   \n",
      "7  agriculture forestry fishing       13-14      115835.73         7.410228   \n",
      "8  agriculture forestry fishing       15-16       21637.71         8.256306   \n",
      "9  agriculture forestry fishing       16-17       41329.78         6.795383   \n",
      "\n",
      "   Inflation_CPI  Exchange_Rate_USD  Fiscal_Deficit_GDP  Global_GDP_Growth  \\\n",
      "0            4.2              44.27                 4.0                4.1   \n",
      "1            6.6              45.28                 3.4                4.3   \n",
      "2            6.2              40.24                 2.7                3.0   \n",
      "3           12.3              47.42                 6.4                4.6   \n",
      "4           10.5              45.58                 6.5                3.3   \n",
      "5            8.4              47.92                 5.9                3.5   \n",
      "6           10.2              53.21                 5.9                3.4   \n",
      "7            9.4              60.50                 4.5                3.6   \n",
      "8            4.9              65.46                 3.9                3.3   \n",
      "9            4.5              67.07                 3.5                3.8   \n",
      "\n",
      "   Election_Year  High_Inflation  GDP_Growth_Lag1  Inflation_Lag1  \\\n",
      "0            0.0             0.0              NaN             NaN   \n",
      "1            0.0             1.0         8.060733             4.2   \n",
      "2            0.0             1.0         7.660815             6.6   \n",
      "3            1.0             1.0         7.861889             9.1   \n",
      "4            0.0             1.0         8.497585            12.3   \n",
      "5            0.0             1.0         5.241316            10.5   \n",
      "6            0.0             1.0         5.456388             8.4   \n",
      "7            0.0             1.0         6.386106            10.2   \n",
      "8            0.0             0.0         7.996254             5.9   \n",
      "9            0.0             0.0         8.256306             4.9   \n",
      "\n",
      "   Sector_Share_GDP  \n",
      "0              18.2  \n",
      "1              17.9  \n",
      "2              17.7  \n",
      "3              17.6  \n",
      "4              17.6  \n",
      "5              17.5  \n",
      "6              17.1  \n",
      "7              17.0  \n",
      "8              16.1  \n",
      "9              15.6  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Integrate sector growth (shares of GDP) → final_data/data_2/data/sector_budget_macro_panel.csv\n",
    "\n",
    "import re\n",
    "import difflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "DATA = ROOT / \"data\"\n",
    "DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prefer inputs from data_2/data, fallback to final_data/data\n",
    "CANDIDATE_IN_DIRS = [DATA, BASE / \"data\"]\n",
    "\n",
    "def resolve_input(filename: str) -> Path:\n",
    "    for d in CANDIDATE_IN_DIRS:\n",
    "        p = d / filename\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return DATA / filename  # explicit default\n",
    "\n",
    "def norm_txt(s: str) -> str:\n",
    "    s = str(s).lower().strip()\n",
    "    s = re.sub(r\"[\\u2013\\u2014–—]\", \"-\", s)        # normalize dashes\n",
    "    s = re.sub(r\"[^a-z0-9\\s/&-]+\", \" \", s)        # drop punctuation except separators\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def fy_end_year_any(s: str) -> int:\n",
    "    # Accept \"yyyy-yy\", \"yy-yy\", optional \"FY\" prefix, extra spaces/dashes\n",
    "    s = str(s).strip().upper().replace(\"FY\", \"\")\n",
    "    s = re.sub(r\"[\\u2013\\u2014–—]\", \"-\", s)\n",
    "    m = re.fullmatch(r\"\\s*(\\d{4})\\s*-\\s*(\\d{2})\\s*\", s)\n",
    "    if m:\n",
    "        return 2000 + int(m.group(2))  # end year from second part\n",
    "    m2 = re.fullmatch(r\"\\s*(\\d{2})\\s*-\\s*(\\d{2})\\s*\", s)\n",
    "    if m2:\n",
    "        return 2000 + int(m2.group(2))\n",
    "    raise ValueError(f\"Unexpected Fiscal_Year format: {s}\")\n",
    "\n",
    "def to_short_fy_from_end(end_year: int) -> str:\n",
    "    yy = end_year % 100\n",
    "    return f\"{(yy-1)%100:02d}-{yy:02d}\"\n",
    "\n",
    "IN_MACRO_PANEL = resolve_input(\"sector_budget_macro.csv\")\n",
    "IN_SECTOR_TS   = resolve_input(\"sector_budget_timeseries.csv\")\n",
    "IN_SHARES      = resolve_input(\"sector_shares_gdp.csv\")\n",
    "OUT_PANEL      = DATA / \"sector_budget_macro_panel.csv\"\n",
    "\n",
    "print(f\"Using macro panel : {IN_MACRO_PANEL}\")\n",
    "print(f\"Using sector TS   : {IN_SECTOR_TS}\")\n",
    "print(f\"Using shares file : {IN_SHARES}\")\n",
    "print(f\"Will save to      : {OUT_PANEL}\")\n",
    "\n",
    "# Load macro panel (may be empty if macro CSV had only headers)\n",
    "macro_panel = pd.read_csv(IN_MACRO_PANEL, dtype={\"Sector_12\": \"string\", \"Fiscal_Year\": \"string\"})\n",
    "macro_panel[\"Fiscal_Year\"] = macro_panel[\"Fiscal_Year\"].astype(\"string\").str.strip()\n",
    "\n",
    "# Canonical Sector_12 list (fallback to sector TS if macro panel empty)\n",
    "canon_sectors = macro_panel[\"Sector_12\"].dropna().unique().tolist()\n",
    "if not canon_sectors:\n",
    "    sector_ts = pd.read_csv(IN_SECTOR_TS, dtype={\"Sector_12\": \"string\", \"Fiscal_Year\": \"string\"})\n",
    "    canon_sectors = sector_ts[\"Sector_12\"].dropna().unique().tolist()\n",
    "\n",
    "canon_norm_map = {norm_txt(s): s for s in canon_sectors}\n",
    "\n",
    "# Load sector shares (wide format with FY columns like 2005-06)\n",
    "shares = pd.read_csv(IN_SHARES)\n",
    "# Heuristic to find sector name column\n",
    "candidate_keys = [\n",
    "    \"Sector_12\", \"Sector\", \"Sector_Name\", \"Sector Key\", \"Sector_Key\",\n",
    "    \"sector\", \"Industry\", \"Category\", \"SectorName\", \"SectorName12\"\n",
    "]\n",
    "key_col = next((c for c in candidate_keys if c in shares.columns), None)\n",
    "if key_col is None:\n",
    "    raise RuntimeError(\n",
    "        f\"Could not find a sector key column in {IN_SHARES.name}. \"\n",
    "        f\"Tried: {candidate_keys}\"\n",
    "    )\n",
    "\n",
    "# Identify FY columns that look like YYYY-YY (also tolerate FY prefix and unicode dashes)\n",
    "fy_cols = [c for c in shares.columns if re.fullmatch(r\"\\s*(?:FY)?\\s*\\d{4}\\s*[-\\u2013\\u2014–—]\\s*\\d{2}\\s*\", str(c))]\n",
    "if not fy_cols:\n",
    "    raise RuntimeError(\"No fiscal-year columns found in sector_shares_gdp.csv (expected like 2005-06).\")\n",
    "\n",
    "# Melt to long\n",
    "long = shares.melt(\n",
    "    id_vars=[key_col],\n",
    "    value_vars=fy_cols,\n",
    "    var_name=\"Fiscal_Year_raw\",\n",
    "    value_name=\"Sector_Share_GDP\"\n",
    ")\n",
    "\n",
    "# Clean share values (e.g., \"12.3%\" -> 12.3). Values are kept as percentage points, not 0-1.\n",
    "long[\"Sector_Share_GDP\"] = (\n",
    "    long[\"Sector_Share_GDP\"]\n",
    "    .astype(\"string\")\n",
    "    .str.replace(\"%\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    "    .str.strip()\n",
    "    .replace({\"\": np.nan})\n",
    ")\n",
    "long[\"Sector_Share_GDP\"] = pd.to_numeric(long[\"Sector_Share_GDP\"], errors=\"coerce\")\n",
    "long = long.dropna(subset=[\"Sector_Share_GDP\"])\n",
    "\n",
    "# Normalize FY to short format yy-yy\n",
    "fy_raw = long[\"Fiscal_Year_raw\"].astype(\"string\").str.replace(\"FY\", \"\", case=False, regex=False)\n",
    "fy_raw = fy_raw.str.replace(\"\\u2013\", \"-\", regex=False).str.replace(\"\\u2014\", \"-\", regex=False).str.replace(\"–\", \"-\", regex=False).str.replace(\"—\", \"-\", regex=False)\n",
    "end_year = fy_raw.map(fy_end_year_any)\n",
    "long[\"Fiscal_Year\"] = end_year.map(to_short_fy_from_end)\n",
    "\n",
    "# Map sector keys → Sector_12 (exact-normalized, then fuzzy)\n",
    "long[\"key_norm\"] = long[key_col].astype(\"string\").map(norm_txt)\n",
    "long[\"Sector_12\"] = long[\"key_norm\"].map(canon_norm_map)\n",
    "\n",
    "unmatched = long[long[\"Sector_12\"].isna()][\"key_norm\"].dropna().unique().tolist()\n",
    "if unmatched:\n",
    "    canon_keys = list(canon_norm_map.keys())\n",
    "    resolved = {}\n",
    "    for k in unmatched:\n",
    "        match = difflib.get_close_matches(k, canon_keys, n=1, cutoff=0.86)\n",
    "        if match:\n",
    "            resolved[k] = canon_norm_map[match[0]]\n",
    "    if resolved:\n",
    "        long.loc[long[\"Sector_12\"].isna(), \"Sector_12\"] = long.loc[long[\"Sector_12\"].isna(), \"key_norm\"].map(resolved)\n",
    "\n",
    "# Final unmatched report\n",
    "still_unmatched = long[long[\"Sector_12\"].isna()][key_col].dropna().unique().tolist()\n",
    "if still_unmatched:\n",
    "    print(f\"Warning: {len(still_unmatched)} sector names could not be mapped to Sector_12. Examples:\", still_unmatched[:8])\n",
    "\n",
    "# Keep necessary columns and aggregate per (Sector_12, Fiscal_Year)\n",
    "shares_panel = (\n",
    "    long.dropna(subset=[\"Sector_12\"])\n",
    "        .groupby([\"Sector_12\", \"Fiscal_Year\"], as_index=False)\n",
    "        .agg(Sector_Share_GDP=(\"Sector_Share_GDP\", \"mean\"))\n",
    ")\n",
    "\n",
    "# Join with macro panel on (Sector_12, Fiscal_Year)\n",
    "# Keep all rows from macro panel; shares fill where available\n",
    "merged_panel = macro_panel.merge(\n",
    "    shares_panel,\n",
    "    on=[\"Sector_12\", \"Fiscal_Year\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Save\n",
    "merged_panel.to_csv(OUT_PANEL, index=False)\n",
    "\n",
    "# Diagnostics\n",
    "print(\"Saved:\", OUT_PANEL)\n",
    "print(\"Macro rows:\", len(macro_panel), \"→ Panel rows:\", len(merged_panel))\n",
    "if len(shares_panel):\n",
    "    coverage = (\n",
    "        merged_panel[\"Sector_Share_GDP\"].notna().mean() * 100.0\n",
    "        if len(merged_panel) else 0.0\n",
    "    )\n",
    "    print(f\"Share coverage in merged panel: {coverage:.1f}%\")\n",
    "else:\n",
    "    print(\"Warning: No valid share rows parsed from sector_shares_gdp.csv\")\n",
    "\n",
    "print(\"Preview:\")\n",
    "print(merged_panel.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31444de3",
   "metadata": {},
   "source": [
    "4.Feature engineering (growth-focused)\n",
    "* Add Year_End; sector lags: Budget_Lag1/Lag2, Budget_Growth_Lag1; shares: Sector_Share_Lag1, Sector_Share_Growth.\n",
    "* Add log levels and YoY log-diff growth: Budget_Log, Share_Log, Budget_Log_Diff1, Share_Log_Diff1; add 3y MA smoothing: Budget_LogDiff1_MA3, Share_LogDiff1_MA3.\n",
    "* Add Trend, Inflation_x_Election, GDPGrowth_x_Election. Clean inf/NaN.\n",
    "* Output (overwrite): data/sector_budget_macro_panel.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f15c722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using panel: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_macro_panel.csv\n",
      "Will save to: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_macro_panel.csv\n",
      "Saved: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_macro_panel.csv\n",
      "Preview:\n",
      "                      Sector_12 Fiscal_Year  Budget_Amount  GDP_Growth_Rate  \\\n",
      "0  agriculture forestry fishing       05-06       27237.86         8.060733   \n",
      "1  agriculture forestry fishing       06-07       38240.82         7.660815   \n",
      "2  agriculture forestry fishing       07-08       44713.38         3.086698   \n",
      "3  agriculture forestry fishing       09-10       86589.42         8.497585   \n",
      "4  agriculture forestry fishing       10-11       93610.87         5.241316   \n",
      "5  agriculture forestry fishing       11-12      104371.66         5.456388   \n",
      "6  agriculture forestry fishing       12-13      109450.59         6.386106   \n",
      "7  agriculture forestry fishing       13-14      115835.73         7.410228   \n",
      "8  agriculture forestry fishing       15-16       21637.71         8.256306   \n",
      "9  agriculture forestry fishing       16-17       41329.78         6.795383   \n",
      "\n",
      "   Inflation_CPI  Exchange_Rate_USD  Fiscal_Deficit_GDP  Global_GDP_Growth  \\\n",
      "0            4.2              44.27                 4.0                4.1   \n",
      "1            6.6              45.28                 3.4                4.3   \n",
      "2            6.2              40.24                 2.7                3.0   \n",
      "3           12.3              47.42                 6.4                4.6   \n",
      "4           10.5              45.58                 6.5                3.3   \n",
      "5            8.4              47.92                 5.9                3.5   \n",
      "6           10.2              53.21                 5.9                3.4   \n",
      "7            9.4              60.50                 4.5                3.6   \n",
      "8            4.9              65.46                 3.9                3.3   \n",
      "9            4.5              67.07                 3.5                3.8   \n",
      "\n",
      "   Election_Year  High_Inflation  ...  Sector_Share_Growth  Budget_Log  \\\n",
      "0            0.0             0.0  ...                  NaN   10.212363   \n",
      "1            0.0             1.0  ...            -0.016484   10.551659   \n",
      "2            0.0             1.0  ...            -0.011173   10.708028   \n",
      "3            1.0             1.0  ...            -0.005650   11.368933   \n",
      "4            0.0             1.0  ...             0.000000   11.446902   \n",
      "5            0.0             1.0  ...            -0.005682   11.555713   \n",
      "6            0.0             1.0  ...            -0.022857   11.603228   \n",
      "7            0.0             1.0  ...            -0.005848   11.659928   \n",
      "8            0.0             0.0  ...            -0.052941    9.982193   \n",
      "9            0.0             0.0  ...            -0.031056   10.629339   \n",
      "\n",
      "   Share_Log  Budget_Log_Diff1  Share_Log_Diff1  Budget_LogDiff1_MA3  \\\n",
      "0   2.901422               NaN              NaN                  NaN   \n",
      "1   2.884801          0.339296        -0.016621             0.339296   \n",
      "2   2.873565          0.156369        -0.011236             0.247832   \n",
      "3   2.867899          0.660905        -0.005666             0.385523   \n",
      "4   2.867899          0.077969         0.000000             0.298414   \n",
      "5   2.862201          0.108812        -0.005698             0.282562   \n",
      "6   2.839078          0.047515        -0.023122             0.078099   \n",
      "7   2.833213          0.056700        -0.005865             0.071009   \n",
      "8   2.778819         -1.677735        -0.054394            -0.524507   \n",
      "9   2.747271          0.647146        -0.031548            -0.324630   \n",
      "\n",
      "   Share_LogDiff1_MA3  Trend  Inflation_x_Election  GDPGrowth_x_Election  \n",
      "0                 NaN      1                   0.0              0.000000  \n",
      "1           -0.016621      2                   0.0              0.000000  \n",
      "2           -0.013928      3                   0.0              0.000000  \n",
      "3           -0.011174      4                  12.3              8.497585  \n",
      "4           -0.005634      5                   0.0              0.000000  \n",
      "5           -0.003788      6                   0.0              0.000000  \n",
      "6           -0.009607      7                   0.0              0.000000  \n",
      "7           -0.011562      8                   0.0              0.000000  \n",
      "8           -0.027794      9                   0.0              0.000000  \n",
      "9           -0.030603     10                   0.0              0.000000  \n",
      "\n",
      "[10 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Feature engineering (growth-focused) → final_data/data_2/data/sector_budget_macro_panel.csv\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "DATA = ROOT / \"data\"\n",
    "DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prefer inputs from data_2/data, fallback to final_data/data\n",
    "CANDIDATE_IN_DIRS = [DATA, BASE / \"data\"]\n",
    "\n",
    "def resolve_input(filename: str) -> Path:\n",
    "    for d in CANDIDATE_IN_DIRS:\n",
    "        p = d / filename\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return DATA / filename  # explicit default\n",
    "\n",
    "def fy_end_year_short(s: str) -> int:\n",
    "    s = str(s).strip()\n",
    "    m = re.fullmatch(r\"(\\d{2})-(\\d{2})\", s)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unexpected Fiscal_Year format: {s}\")\n",
    "    return 2000 + int(m.group(2))\n",
    "\n",
    "IN_PANEL = resolve_input(\"sector_budget_macro_panel.csv\")\n",
    "OUT_PANEL = DATA / \"sector_budget_macro_panel.csv\"\n",
    "\n",
    "print(f\"Using panel: {IN_PANEL}\")\n",
    "print(f\"Will save to: {OUT_PANEL}\")\n",
    "\n",
    "# Load\n",
    "panel = pd.read_csv(IN_PANEL, dtype={\"Sector_12\": \"string\", \"Fiscal_Year\": \"string\"})\n",
    "panel[\"Fiscal_Year\"] = panel[\"Fiscal_Year\"].str.strip()\n",
    "\n",
    "# Ensure key numerics\n",
    "for c in [\"Budget_Amount\", \"Sector_Share_GDP\", \"GDP_Growth_Rate\", \"Inflation_CPI\", \"Election_Year\"]:\n",
    "    if c in panel.columns:\n",
    "        panel[c] = pd.to_numeric(panel[c], errors=\"coerce\")\n",
    "\n",
    "# Year_End\n",
    "panel[\"Year_End\"] = panel[\"Fiscal_Year\"].map(fy_end_year_short)\n",
    "\n",
    "# Sort for time-aware ops\n",
    "panel = panel.sort_values([\"Sector_12\", \"Year_End\"])\n",
    "\n",
    "# Sector lags for budget\n",
    "panel[\"Budget_Lag1\"] = panel.groupby(\"Sector_12\")[\"Budget_Amount\"].shift(1)\n",
    "panel[\"Budget_Lag2\"] = panel.groupby(\"Sector_12\")[\"Budget_Amount\"].shift(2)\n",
    "panel[\"Budget_Growth_Lag1\"] = (panel[\"Budget_Amount\"] / panel[\"Budget_Lag1\"]) - 1\n",
    "\n",
    "# Sector lags for shares\n",
    "if \"Sector_Share_GDP\" in panel.columns:\n",
    "    panel[\"Sector_Share_Lag1\"] = panel.groupby(\"Sector_12\")[\"Sector_Share_GDP\"].shift(1)\n",
    "    panel[\"Sector_Share_Growth\"] = (panel[\"Sector_Share_GDP\"] / panel[\"Sector_Share_Lag1\"]) - 1\n",
    "\n",
    "# Logs and YoY log-diff growth\n",
    "panel[\"Budget_Log\"] = np.log(panel[\"Budget_Amount\"].where(panel[\"Budget_Amount\"] > 0))\n",
    "if \"Sector_Share_GDP\" in panel.columns:\n",
    "    panel[\"Share_Log\"] = np.log(panel[\"Sector_Share_GDP\"].where(panel[\"Sector_Share_GDP\"] > 0))\n",
    "\n",
    "panel[\"Budget_Log_Diff1\"] = panel.groupby(\"Sector_12\")[\"Budget_Log\"].diff(1)\n",
    "if \"Sector_Share_GDP\" in panel.columns:\n",
    "    panel[\"Share_Log_Diff1\"] = panel.groupby(\"Sector_12\")[\"Share_Log\"].diff(1)\n",
    "\n",
    "# 3y moving average smoothing of log-diff\n",
    "panel[\"Budget_LogDiff1_MA3\"] = panel.groupby(\"Sector_12\")[\"Budget_Log_Diff1\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "if \"Sector_Share_GDP\" in panel.columns:\n",
    "    panel[\"Share_LogDiff1_MA3\"] = panel.groupby(\"Sector_12\")[\"Share_Log_Diff1\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "\n",
    "# Trend (within sector)\n",
    "panel[\"Trend\"] = panel.groupby(\"Sector_12\").cumcount() + 1\n",
    "\n",
    "# Interactions\n",
    "if {\"Inflation_CPI\", \"Election_Year\"}.issubset(panel.columns):\n",
    "    panel[\"Inflation_x_Election\"] = panel[\"Inflation_CPI\"] * panel[\"Election_Year\"]\n",
    "if {\"GDP_Growth_Rate\", \"Election_Year\"}.issubset(panel.columns):\n",
    "    panel[\"GDPGrowth_x_Election\"] = panel[\"GDP_Growth_Rate\"] * panel[\"Election_Year\"]\n",
    "\n",
    "# Clean inf/NaN artifacts from divisions/logs\n",
    "panel.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Save (overwrite)\n",
    "panel.to_csv(OUT_PANEL, index=False)\n",
    "print(\"Saved:\", OUT_PANEL)\n",
    "print(\"Preview:\")\n",
    "print(panel.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50749f0a",
   "metadata": {},
   "source": [
    "5.Define splits and scaling (whitelist features)\n",
    "* Hold out FY23-24 (Year_End=2024) for test; train on ≤2023; validation = 2023.\n",
    "* Whitelist features: Sector_Share_* (level/lag/growth/logdiff/MA3), Budget_Lag1/Lag2/Budget_Growth_Lag1, macro fields above, interactions, Trend.\n",
    "* Fit median-impute + StandardScaler on train only; transform all rows.\n",
    "* Outputs: data/sector_budget_features_train.csv, data/sector_budget_features_test_2024.csv, data/feature_columns.json, data/feature_imputer_scaler.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78c3e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using panel: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_macro_panel.csv\n",
      "Will save train: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_features_train.csv\n",
      "Will save test : /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_features_test_2024.csv\n",
      "Saved:\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_features_train.csv\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_features_test_2024.csv\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/feature_columns.json\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/feature_imputer_scaler.joblib\n",
      "Train rows: 176 Test rows: 11\n",
      "n_features: 21\n",
      "Example cols: ['Sector_12', 'Fiscal_Year', 'Year_End', 'Budget_Amount', 'Split', 'z_Sector_Share_GDP', 'z_Sector_Share_Lag1', 'z_Sector_Share_Growth'] ...\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Define splits and scaling (whitelist features)\n",
    "# Outputs (all under data_2/data):\n",
    "# - final_data/data_2/data/sector_budget_features_train.csv\n",
    "# - final_data/data_2/data/sector_budget_features_test_2024.csv\n",
    "# - final_data/data_2/data/feature_columns.json\n",
    "# - final_data/data_2/data/feature_imputer_scaler.joblib\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "DATA2 = ROOT / \"data\"\n",
    "DATA2.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inputs come from data_2/data only\n",
    "CANDIDATE_IN_DIRS = [DATA2]\n",
    "\n",
    "def resolve_input(filename: str) -> Path:\n",
    "    for d in CANDIDATE_IN_DIRS:\n",
    "        p = d / filename\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return DATA2 / filename  # explicit default\n",
    "\n",
    "def fy_end_year_short(s: str) -> int:\n",
    "    s = str(s).strip()\n",
    "    m = re.fullmatch(r\"(\\d{2})-(\\d{2})\", s)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unexpected Fiscal_Year format: {s}\")\n",
    "    return 2000 + int(m.group(2))\n",
    "\n",
    "IN_PANEL = resolve_input(\"sector_budget_macro_panel.csv\")\n",
    "OUT_TRAIN = DATA2 / \"sector_budget_features_train.csv\"\n",
    "OUT_TEST  = DATA2 / \"sector_budget_features_test_2024.csv\"\n",
    "OUT_COLS  = DATA2 / \"feature_columns.json\"\n",
    "OUT_MODEL = DATA2 / \"feature_imputer_scaler.joblib\"\n",
    "\n",
    "print(f\"Using panel: {IN_PANEL}\")\n",
    "print(f\"Will save train: {OUT_TRAIN}\")\n",
    "print(f\"Will save test : {OUT_TEST}\")\n",
    "\n",
    "# Load panel\n",
    "panel = pd.read_csv(IN_PANEL, dtype={\"Sector_12\": \"string\", \"Fiscal_Year\": \"string\"})\n",
    "panel[\"Fiscal_Year\"] = panel[\"Fiscal_Year\"].str.strip()\n",
    "\n",
    "# Ensure numerics for potential features and target\n",
    "num_candidates = [\n",
    "    \"Budget_Amount\",\n",
    "    \"Sector_Share_GDP\", \"Sector_Share_Lag1\", \"Sector_Share_Growth\",\n",
    "    \"Share_Log\", \"Share_Log_Diff1\", \"Share_LogDiff1_MA3\",\n",
    "    \"Budget_Lag1\", \"Budget_Lag2\", \"Budget_Growth_Lag1\",\n",
    "    \"GDP_Growth_Rate\", \"Inflation_CPI\", \"Exchange_Rate_USD\", \"Fiscal_Deficit_GDP\",\n",
    "    \"Global_GDP_Growth\", \"Election_Year\", \"High_Inflation\", \"GDP_Growth_Lag1\", \"Inflation_Lag1\",\n",
    "    \"Inflation_x_Election\", \"GDPGrowth_x_Election\",\n",
    "    \"Trend\", \"Year_End\"\n",
    "]\n",
    "for c in num_candidates:\n",
    "    if c in panel.columns:\n",
    "        panel[c] = pd.to_numeric(panel[c], errors=\"coerce\")\n",
    "\n",
    "# Ensure Year_End\n",
    "if \"Year_End\" not in panel.columns:\n",
    "    panel[\"Year_End\"] = panel[\"Fiscal_Year\"].map(fy_end_year_short)\n",
    "\n",
    "# Define whitelist\n",
    "macro_cols = [\n",
    "    \"GDP_Growth_Rate\", \"Inflation_CPI\", \"Exchange_Rate_USD\", \"Fiscal_Deficit_GDP\",\n",
    "    \"Global_GDP_Growth\", \"Election_Year\", \"High_Inflation\", \"GDP_Growth_Lag1\", \"Inflation_Lag1\",\n",
    "]\n",
    "budget_cols = [\"Budget_Lag1\", \"Budget_Lag2\", \"Budget_Growth_Lag1\"]\n",
    "share_cols  = [\"Sector_Share_GDP\", \"Sector_Share_Lag1\", \"Sector_Share_Growth\",\n",
    "               \"Share_Log\", \"Share_Log_Diff1\", \"Share_LogDiff1_MA3\"]\n",
    "interaction_cols = [\"Inflation_x_Election\", \"GDPGrowth_x_Election\"]\n",
    "trend_cols = [\"Trend\"]\n",
    "\n",
    "whitelist = share_cols + budget_cols + macro_cols + interaction_cols + trend_cols\n",
    "features = [c for c in whitelist if c in panel.columns]\n",
    "\n",
    "if not features:\n",
    "    raise RuntimeError(\"No whitelist features present in panel. Ensure Step 3/4 created the engineered columns.\")\n",
    "\n",
    "# Split flags\n",
    "panel[\"Split\"] = np.where(panel[\"Year_End\"] == 2024, \"test\",\n",
    "                   np.where(panel[\"Year_End\"] == 2023, \"val\", \"train\"))\n",
    "\n",
    "train_mask = panel[\"Year_End\"] <= 2023\n",
    "test_mask  = panel[\"Year_End\"] == 2024\n",
    "\n",
    "# Fit imputer + scaler on train only\n",
    "X_train = panel.loc[train_mask, features]\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "_ = scaler.fit(X_train_imp)\n",
    "\n",
    "# Transform all rows\n",
    "X_all_imp = imputer.transform(panel[features])\n",
    "X_all_std = scaler.transform(X_all_imp)\n",
    "\n",
    "z_cols = [f\"z_{c}\" for c in features]\n",
    "for i, c in enumerate(z_cols):\n",
    "    panel[c] = X_all_std[:, i]\n",
    "\n",
    "# Prepare outputs\n",
    "base_cols = [\"Sector_12\", \"Fiscal_Year\", \"Year_End\", \"Budget_Amount\", \"Split\"]\n",
    "present_base = [c for c in base_cols if c in panel.columns]\n",
    "out_cols = present_base + z_cols\n",
    "\n",
    "train_out = panel.loc[panel[\"Split\"].isin([\"train\", \"val\"]), out_cols].copy()\n",
    "test_out  = panel.loc[test_mask, out_cols].copy()\n",
    "\n",
    "# Save CSVs and artifacts to data_2/data\n",
    "train_out.to_csv(OUT_TRAIN, index=False)\n",
    "test_out.to_csv(OUT_TEST, index=False)\n",
    "\n",
    "meta = {\n",
    "    \"original_features\": features,\n",
    "    \"z_features\": z_cols,\n",
    "    \"target\": \"Budget_Amount\",\n",
    "    \"split\": {\"train_max_year_end\": 2023, \"validation_year_end\": 2023, \"test_year_end\": 2024},\n",
    "}\n",
    "with open(OUT_COLS, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "artifacts = {\n",
    "    \"imputer\": imputer,\n",
    "    \"scaler\": scaler,\n",
    "    \"feature_names\": features,\n",
    "    \"z_feature_names\": z_cols,\n",
    "}\n",
    "dump(artifacts, OUT_MODEL)\n",
    "\n",
    "# Diagnostics\n",
    "print(\"Saved:\")\n",
    "print(\" -\", OUT_TRAIN)\n",
    "print(\" -\", OUT_TEST)\n",
    "print(\" -\", OUT_COLS)\n",
    "print(\" -\", OUT_MODEL)\n",
    "print(\"Train rows:\", len(train_out), \"Test rows:\", len(test_out))\n",
    "print(\"n_features:\", len(features))\n",
    "print(\"Example cols:\", out_cols[:8], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ff30df",
   "metadata": {},
   "source": [
    "6.Baseline models (same FY23-24 sample as DL)\n",
    "* Build Naive(Lag1) from panel for FY2024 rows evaluated by DL.\n",
    "* Train LinearRegression, Ridge, GBM on z_ features using train ≤2023; evaluate on same FY23-24 rows.\n",
    "* Metrics: MAE, RMSE, R2, MAPE_%.\n",
    "* Output: data/metrics/sector_baseline_metrics_23_24.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fa6acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_features_train.csv\n",
      "Test  features: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_features_test_2024.csv\n",
      "Panel (for Naive): /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_budget_macro_panel.csv\n",
      "Metrics will be saved to: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/metrics/sector_baseline_metrics_23_24.csv\n",
      "\n",
      "Saved metrics: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/metrics/sector_baseline_metrics_23_24.csv\n",
      "              model  n_eval           MAE          RMSE        R2     MAPE_%\n",
      "0        Naive_Lag1      11  22696.873636  33404.003003  0.908105  12.774786\n",
      "1  LinearRegression      11  23256.136970  27133.149205  0.939369  23.561556\n",
      "2             Ridge      11  24358.801538  28983.020707  0.930820  22.826874\n",
      "3               GBM      11  13344.972027  16743.237586  0.976913   9.394340\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Baseline models (train ≤2023, test on FY2024) → final_data/data_2/data/metrics/sector_baseline_metrics_23_24.csv\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "DATA2 = ROOT / \"data\"\n",
    "METRICS_DIR = DATA2 / \"metrics\"\n",
    "METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inputs\n",
    "IN_FEATS_TRAIN = DATA2 / \"sector_budget_features_train.csv\"\n",
    "IN_FEATS_TEST  = DATA2 / \"sector_budget_features_test_2024.csv\"\n",
    "IN_PANEL       = DATA2 / \"sector_budget_macro_panel.csv\"   # for Naive(Lag1)\n",
    "IN_COLS        = DATA2 / \"feature_columns.json\"\n",
    "\n",
    "# Output\n",
    "OUT_METRICS = METRICS_DIR / \"sector_baseline_metrics_23_24.csv\"\n",
    "\n",
    "print(f\"Train features: {IN_FEATS_TRAIN}\")\n",
    "print(f\"Test  features: {IN_FEATS_TEST}\")\n",
    "print(f\"Panel (for Naive): {IN_PANEL}\")\n",
    "print(f\"Metrics will be saved to: {OUT_METRICS}\")\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(IN_FEATS_TRAIN)\n",
    "test_df  = pd.read_csv(IN_FEATS_TEST)\n",
    "\n",
    "# Feature list\n",
    "with open(IN_COLS, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "z_features = meta.get(\"z_features\", [])\n",
    "\n",
    "# Drop rows without target (safety)\n",
    "train_df = train_df.dropna(subset=[\"Budget_Amount\"]).copy()\n",
    "test_eval = test_df.dropna(subset=[\"Budget_Amount\"]).copy()\n",
    "\n",
    "X_train = train_df[z_features]\n",
    "y_train = train_df[\"Budget_Amount\"].values\n",
    "\n",
    "X_test = test_eval[z_features]\n",
    "y_test = test_eval[\"Budget_Amount\"].values\n",
    "\n",
    "def mape_pct(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    mask = (y_true != 0) & np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if not np.any(mask):\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0\n",
    "\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    # Version-agnostic RMSE (older sklearn has no `squared` kwarg)\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = mape_pct(y_true, y_pred)\n",
    "    return mae, rmse, r2, mape\n",
    "\n",
    "results = []\n",
    "\n",
    "# 1) Naive(Lag1) using Budget_Lag1 from the engineered panel for Year_End=2024\n",
    "panel = pd.read_csv(IN_PANEL)\n",
    "# Ensure numeric\n",
    "if \"Budget_Lag1\" in panel.columns:\n",
    "    panel[\"Budget_Lag1\"] = pd.to_numeric(panel[\"Budget_Lag1\"], errors=\"coerce\")\n",
    "# Join on (Sector_12, Fiscal_Year) for FY2024 rows only\n",
    "naive_merge = test_eval[[\"Sector_12\", \"Fiscal_Year\", \"Budget_Amount\"]].merge(\n",
    "    panel[[\"Sector_12\", \"Fiscal_Year\", \"Budget_Lag1\"]],\n",
    "    on=[\"Sector_12\", \"Fiscal_Year\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "naive_valid = naive_merge.dropna(subset=[\"Budget_Amount\", \"Budget_Lag1\"]).copy()\n",
    "if len(naive_valid):\n",
    "    y_true_nv = naive_valid[\"Budget_Amount\"].values\n",
    "    y_pred_nv = naive_valid[\"Budget_Lag1\"].values\n",
    "    mae, rmse, r2, mape = eval_metrics(y_true_nv, y_pred_nv)\n",
    "    results.append({\n",
    "        \"model\": \"Naive_Lag1\",\n",
    "        \"n_eval\": int(len(naive_valid)),\n",
    "        \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE_%\": mape\n",
    "    })\n",
    "else:\n",
    "    results.append({\n",
    "        \"model\": \"Naive_Lag1\",\n",
    "        \"n_eval\": 0, \"MAE\": np.nan, \"RMSE\": np.nan, \"R2\": np.nan, \"MAPE_%\": np.nan\n",
    "    })\n",
    "\n",
    "# 2) Linear Regression\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "pred_lin = lin.predict(X_test)\n",
    "mae, rmse, r2, mape = eval_metrics(y_test, pred_lin)\n",
    "results.append({\n",
    "    \"model\": \"LinearRegression\",\n",
    "    \"n_eval\": int(len(y_test)),\n",
    "    \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE_%\": mape\n",
    "})\n",
    "\n",
    "# 3) Ridge\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "pred_ridge = ridge.predict(X_test)\n",
    "mae, rmse, r2, mape = eval_metrics(y_test, pred_ridge)\n",
    "results.append({\n",
    "    \"model\": \"Ridge\",\n",
    "    \"n_eval\": int(len(y_test)),\n",
    "    \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE_%\": mape\n",
    "})\n",
    "\n",
    "# 4) Gradient Boosting Regressor (GBM)\n",
    "gbm = GradientBoostingRegressor(random_state=42)\n",
    "gbm.fit(X_train, y_train)\n",
    "pred_gbm = gbm.predict(X_test)\n",
    "mae, rmse, r2, mape = eval_metrics(y_test, pred_gbm)\n",
    "results.append({\n",
    "    \"model\": \"GBM\",\n",
    "    \"n_eval\": int(len(y_test)),\n",
    "    \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE_%\": mape\n",
    "})\n",
    "\n",
    "metrics_df = pd.DataFrame(results, columns=[\"model\", \"n_eval\", \"MAE\", \"RMSE\", \"R2\", \"MAPE_%\"])\n",
    "metrics_df.to_csv(OUT_METRICS, index=False)\n",
    "\n",
    "print(\"\\nSaved metrics:\", OUT_METRICS)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f08503",
   "metadata": {},
   "source": [
    "7.Deep learning (residual learning + embeddings, lookback=5)\n",
    "* Build sequences per sector on z_ features (t-5..t-1 → residual log-growth at t vs Naive(Lag1)).\n",
    "* Add sector embeddings; train with Huber loss, EarlyStopping, ReduceLROnPlateau; validate on 2023.\n",
    "* Calibrate blend α on 2023 between DL and Naive, then evaluate FY23-24.\n",
    "* Train variants: GRU_L5_U64, LSTM_L5_U64, StackedGRU_L5_64_32, BiGRU_L5_U64, TCN_L5_F64_K3; also ensemble average.\n",
    "* Outputs: data/sector_dl_predictions_23_24.csv (per model), results/fy2425/metrics/* (summaries), results/fy2425/plots/* (DL vs baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "705184f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature metadata and panels...\n",
      "Built sequences with lookback=5:\n",
      "Train: (110, 5, 21) Val: (11, 5, 21) Test: (11, 5, 21) n_features: 21 n_sectors: 11\n",
      "\n",
      "Training models...\n",
      "\n",
      "Model: GRU_L5_U64\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x301f2bec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "  α=0.64 | 2024 Blend MAE=31179.28 RMSE=45580.17 R2=0.829 MAPE%=17.79\n",
      "\n",
      "Model: LSTM_L5_U64\n",
      "  α=0.60 | 2024 Blend MAE=22559.93 RMSE=33410.99 R2=0.908 MAPE%=12.17\n",
      "\n",
      "Model: StackedGRU_L5_64_32\n",
      "  α=1.00 | 2024 Blend MAE=26500.98 RMSE=40899.77 R2=0.862 MAPE%=14.34\n",
      "\n",
      "Model: BiGRU_L5_U64\n",
      "  α=0.58 | 2024 Blend MAE=32831.00 RMSE=43556.30 R2=0.844 MAPE%=16.36\n",
      "\n",
      "Model: TCN_L5_F64_K3\n",
      "  α=0.43 | 2024 Blend MAE=20721.56 RMSE=31558.48 R2=0.918 MAPE%=11.82\n",
      "\n",
      "Saved predictions: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/data/sector_dl_predictions_23_24.csv\n",
      "Saved DL metrics: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/metrics/dl_metrics_23_24.csv\n",
      "Saved combined metrics: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/metrics/metrics_all_23_24.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/wzy1hvwd7bd4plh9mwvg9yyc0000gn/T/ipykernel_5688/1460091616.py:374: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=dfx, x=\"model\", y=metric, palette=palette)\n",
      "/var/folders/ty/wzy1hvwd7bd4plh9mwvg9yyc0000gn/T/ipykernel_5688/1460091616.py:374: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=dfx, x=\"model\", y=metric, palette=palette)\n",
      "/var/folders/ty/wzy1hvwd7bd4plh9mwvg9yyc0000gn/T/ipykernel_5688/1460091616.py:374: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=dfx, x=\"model\", y=metric, palette=palette)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plots to: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/plots\n",
      "Saved scatter: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/plots/actual_vs_pred_best.png\n",
      "\n",
      "Step 7 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/wzy1hvwd7bd4plh9mwvg9yyc0000gn/T/ipykernel_5688/1460091616.py:374: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=dfx, x=\"model\", y=metric, palette=palette)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Deep learning (residual learning + embeddings, lookback=5)\n",
    "# - Build sequences per sector on z_ features (t-5..t-1 → residual log-growth at t vs Naive(Lag1)).\n",
    "# - Sector embeddings; Huber loss; EarlyStopping + ReduceLROnPlateau; validate on 2023.\n",
    "# - Calibrate blend α on 2023 between DL and Naive; evaluate on FY2024.\n",
    "# - Train: GRU_L5_U64, LSTM_L5_U64, StackedGRU_L5_64_32, BiGRU_L5_U64, TCN_L5_F64_K3; ensemble average.\n",
    "# - Save predictions CSV and metrics/plots under data_2.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TF setup\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models, callbacks, optimizers, losses\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"TensorFlow is required for Step 7. Install with: pip3 install tensorflow\") from e\n",
    "\n",
    "# Paths\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "DATA = ROOT / \"data\"\n",
    "RESULTS_ROOT = ROOT / \"results_Data_2\"\n",
    "PLOTS_DIR = RESULTS_ROOT / \"plots\"\n",
    "METRICS_DIR = RESULTS_ROOT / \"metrics\"\n",
    "RESULTS_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inputs\n",
    "IN_TRAIN = DATA / \"sector_budget_features_train.csv\"\n",
    "IN_TEST  = DATA / \"sector_budget_features_test_2024.csv\"\n",
    "IN_META  = DATA / \"feature_columns.json\"\n",
    "IN_PANEL = DATA / \"sector_budget_macro_panel.csv\"  # has Budget_Lag1, Budget_Log_Diff1\n",
    "IN_BASELINE = DATA / \"metrics\" / \"sector_baseline_metrics_23_24.csv\"\n",
    "\n",
    "# Outputs\n",
    "OUT_PRED_CSV = DATA / \"sector_dl_predictions_23_24.csv\"\n",
    "OUT_METRICS_CSV = METRICS_DIR / \"dl_metrics_23_24.csv\"\n",
    "OUT_METRICS_ALL_CSV = METRICS_DIR / \"metrics_all_23_24.csv\"\n",
    "\n",
    "LOOKBACK = 5\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Loading feature metadata and panels...\")\n",
    "with open(IN_META, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "z_features = meta.get(\"z_features\", [])\n",
    "if not z_features:\n",
    "    raise RuntimeError(\"No z_features found. Run Step 5 first.\")\n",
    "\n",
    "# Load features (train contains train+val(2023); test is 2024)\n",
    "train_df = pd.read_csv(IN_TRAIN)\n",
    "test_df  = pd.read_csv(IN_TEST)\n",
    "\n",
    "# Merge with engineered panel to get targets and naive baseline\n",
    "# ...existing code...\n",
    "# Merge with engineered panel to get targets and naive baseline\n",
    "panel = pd.read_csv(IN_PANEL, dtype={\"Sector_12\": \"string\", \"Fiscal_Year\": \"string\"})\n",
    "for c in [\"Budget_Amount\", \"Budget_Lag1\", \"Budget_Log_Diff1\", \"Year_End\"]:\n",
    "    if c in panel.columns:\n",
    "        panel[c] = pd.to_numeric(panel[c], errors=\"coerce\")\n",
    "panel[\"Fiscal_Year\"] = panel[\"Fiscal_Year\"].astype(\"string\").str.strip()\n",
    "\n",
    "# ...existing code...\n",
    "# Merge feature frames to have all years up to 2024\n",
    "feats_all = pd.concat([train_df, test_df], ignore_index=True)\n",
    "feats_all[\"Fiscal_Year\"] = feats_all[\"Fiscal_Year\"].astype(\"string\").str.strip()\n",
    "\n",
    "# Attach target residual and naive baseline (from engineered panel)\n",
    "# IMPORTANT: do NOT include Budget_Amount from panel to avoid *_x/*_y suffixes\n",
    "use_cols = [\"Sector_12\", \"Fiscal_Year\", \"Year_End\", \"Budget_Lag1\", \"Budget_Log_Diff1\"]\n",
    "panel_use = panel[use_cols].copy()\n",
    "feats = feats_all.merge(panel_use, on=[\"Sector_12\", \"Fiscal_Year\", \"Year_End\"], how=\"left\")\n",
    "\n",
    "# If previous runs created *_x/*_y, coalesce to a single column\n",
    "def _coalesce(df, base):\n",
    "    if base in df.columns:\n",
    "        return df\n",
    "    x, y = f\"{base}_x\", f\"{base}_y\"\n",
    "    if x in df.columns or y in df.columns:\n",
    "        df[base] = df.get(x).combine_first(df.get(y))\n",
    "        df.drop(columns=[c for c in [x, y] if c in df.columns], inplace=True)\n",
    "    return df\n",
    "\n",
    "feats = _coalesce(feats, \"Budget_Amount\")\n",
    "\n",
    "# Final sanity\n",
    "if \"Budget_Amount\" not in feats.columns:\n",
    "    raise RuntimeError(\n",
    "        \"Budget_Amount missing after merge. Ensure Step 5 outputs include Budget_Amount \"\n",
    "        \"and re-run Step 5 (splits/scaling) before Step 8.\"\n",
    "    )\n",
    "\n",
    "# Sector index, features, embedding dims\n",
    "sectors = feats[\"Sector_12\"].astype(\"string\").fillna(\"UNK\").unique().tolist()\n",
    "# ...existing code...\n",
    "sector2id = {s: i for i, s in enumerate(sorted(sectors))}\n",
    "n_sectors = len(sector2id)\n",
    "n_features = len(z_features)\n",
    "embed_dim = max(4, min(16, int(round(math.sqrt(n_sectors)))))\n",
    "\n",
    "def build_sequences(df: pd.DataFrame, lookback: int, target_year: int | None = None):\n",
    "    X_list, S_list, y_list, keys = [], [], [], []\n",
    "    A_list, N_list = [], []\n",
    "    for s, g in df.groupby(\"Sector_12\", sort=False):\n",
    "        g = g.sort_values(\"Year_End\")\n",
    "        Z = g[z_features].values\n",
    "        y = g[\"Budget_Log_Diff1\"].values\n",
    "        A = g[\"Budget_Amount\"].values\n",
    "        N = g[\"Budget_Lag1\"].values\n",
    "        yrs = g[\"Year_End\"].values\n",
    "        fyears = g[\"Fiscal_Year\"].values\n",
    "\n",
    "        sid = sector2id.get(s, 0)\n",
    "        for i in range(lookback, len(g)):\n",
    "            # keep only desired target year if specified\n",
    "            if target_year is not None and int(yrs[i]) != int(target_year):\n",
    "                continue\n",
    "            if not np.isfinite(y[i]) or not np.isfinite(N[i]) or N[i] <= 0:\n",
    "                continue\n",
    "            X_seq = Z[i - lookback:i, :]\n",
    "            X_list.append(X_seq.astype(np.float32))\n",
    "            S_list.append(np.int32(sid))\n",
    "            y_list.append(np.float32(y[i]))\n",
    "            A_list.append(np.float64(A[i]))\n",
    "            N_list.append(np.float64(N[i]))\n",
    "            keys.append((str(s), str(fyears[i]), int(yrs[i])))\n",
    "    return (\n",
    "        np.array(X_list, dtype=np.float32),\n",
    "        np.array(S_list, dtype=np.int32),\n",
    "        np.array(y_list, dtype=np.float32),\n",
    "        np.array(A_list, dtype=np.float64),\n",
    "        np.array(N_list, dtype=np.float64),\n",
    "        keys,\n",
    "    )\n",
    "\n",
    "# Build from history ≤ target year, and filter targets inside\n",
    "feats_hist_tr = feats[feats[\"Year_End\"] <= 2022].copy()\n",
    "feats_hist_va = feats[feats[\"Year_End\"] <= 2023].copy()\n",
    "feats_hist_te = feats[feats[\"Year_End\"] <= 2024].copy()\n",
    "\n",
    "X_tr, S_tr, y_tr, A_tr, N_tr, K_tr = build_sequences(feats_hist_tr, LOOKBACK, target_year=None)\n",
    "X_va, S_va, y_va, A_va, N_va, K_va = build_sequences(feats_hist_va, LOOKBACK, target_year=2023)\n",
    "X_te, S_te, y_te, A_te, N_te, K_te = build_sequences(feats_hist_te, LOOKBACK, target_year=2024)\n",
    "\n",
    "print(f\"Built sequences with lookback={LOOKBACK}:\")\n",
    "print(\"Train:\", X_tr.shape, \"Val:\", X_va.shape, \"Test:\", X_te.shape, \"n_features:\", n_features, \"n_sectors:\", n_sectors)\n",
    "\n",
    "if X_tr.shape[0] == 0:\n",
    "    raise RuntimeError(f\"No training sequences with lookback={LOOKBACK}. Reduce lookback or check feature z_ columns.\")\n",
    "\n",
    "def huber_model_core(model_type: str, units_main: int = 64, kernel_size: int = 3):\n",
    "    seq_in = layers.Input(shape=(LOOKBACK, n_features), name=\"seq_in\")\n",
    "    sec_in = layers.Input(shape=(), dtype=\"int32\", name=\"sec_in\")\n",
    "    emb = layers.Embedding(input_dim=n_sectors, output_dim=embed_dim, name=\"sector_emb\")(sec_in)\n",
    "    emb_v = layers.Flatten()(emb)\n",
    "\n",
    "    if model_type == \"gru\":\n",
    "        enc = layers.GRU(units_main, name=\"enc_gru\")(seq_in)\n",
    "    elif model_type == \"lstm\":\n",
    "        enc = layers.LSTM(units_main, name=\"enc_lstm\")(seq_in)\n",
    "    elif model_type == \"bigru\":\n",
    "        enc = layers.Bidirectional(layers.GRU(units_main, name=\"enc_bigru_base\"), name=\"enc_bigru\")(seq_in)\n",
    "    elif model_type == \"stacked_gru\":\n",
    "        x = layers.GRU(units_main, return_sequences=True, name=\"enc_gru_1\")(seq_in)\n",
    "        enc = layers.GRU(max(16, units_main // 2), name=\"enc_gru_2\")(x)\n",
    "    elif model_type == \"tcn\":\n",
    "        # lightweight TCN via dilated causal Conv1D blocks\n",
    "        x = seq_in\n",
    "        for d in [1, 2, 4]:\n",
    "            res = x\n",
    "            x = layers.Conv1D(filters=units_main, kernel_size=kernel_size, padding=\"causal\", dilation_rate=d, activation=\"relu\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Dropout(0.1)(x)\n",
    "            # match channels for residual\n",
    "            if res.shape[-1] != x.shape[-1]:\n",
    "                res = layers.Conv1D(filters=units_main, kernel_size=1, padding=\"same\")(res)\n",
    "            x = layers.Add()([res, x])\n",
    "            x = layers.Activation(\"relu\")(x)\n",
    "        enc = layers.GlobalAveragePooling1D()(x)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}\")\n",
    "\n",
    "    z = layers.Concatenate()([enc, emb_v])\n",
    "    z = layers.Dense(64, activation=\"relu\")(z)\n",
    "    z = layers.Dropout(0.2)(z)\n",
    "    out = layers.Dense(1, name=\"residual_log_growth\")(z)\n",
    "\n",
    "    model = models.Model(inputs=[seq_in, sec_in], outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=losses.Huber(delta=1.0),\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError(name=\"mae\")]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "MODEL_SPECS = {\n",
    "    \"GRU_L5_U64\":        (\"gru\",          64, 3),\n",
    "    \"LSTM_L5_U64\":       (\"lstm\",         64, 3),\n",
    "    \"StackedGRU_L5_64_32\": (\"stacked_gru\", 64, 3),\n",
    "    \"BiGRU_L5_U64\":      (\"bigru\",        64, 3),\n",
    "    \"TCN_L5_F64_K3\":     (\"tcn\",          64, 3),\n",
    "}\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=7, min_lr=1e-5)\n",
    "cb = [es, rlr]\n",
    "\n",
    "def metrics_all(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if not np.any(mask):\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    yt, yp = y_true[mask], y_pred[mask]\n",
    "    mae = np.mean(np.abs(yt - yp))\n",
    "    rmse = float(np.sqrt(np.mean((yt - yp) ** 2)))\n",
    "    r2 = 1.0 - (np.sum((yt - yp) ** 2) / np.sum((yt - np.mean(yt)) ** 2) if np.sum((yt - np.mean(yt)) ** 2) > 0 else np.nan)\n",
    "    mape = np.mean(np.abs((yt - yp) / yt)) * 100.0 if np.all(yt != 0) else np.nan\n",
    "    return mae, rmse, r2, mape\n",
    "\n",
    "def best_alpha(naive_lvl, dl_lvl, actual_lvl):\n",
    "    # Find α in [0,1] minimizing MAE on validation set\n",
    "    alphas = np.linspace(0.0, 1.0, 101)\n",
    "    best_a, best_mae = 0.0, float(\"inf\")\n",
    "    for a in alphas:\n",
    "        blend = a * dl_lvl + (1 - a) * naive_lvl\n",
    "        mae = np.mean(np.abs(actual_lvl - blend))\n",
    "        if mae < best_mae:\n",
    "            best_mae, best_a = mae, a\n",
    "    return float(best_a), float(best_mae)\n",
    "\n",
    "# Train and evaluate\n",
    "model_preds_test = {}\n",
    "model_preds_val = {}\n",
    "model_alphas = {}\n",
    "dl_metrics_rows = []\n",
    "\n",
    "\n",
    "print(\"\\nTraining models...\")\n",
    "for name, (mtype, units_main, ksz) in MODEL_SPECS.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = huber_model_core(mtype, units_main=units_main, kernel_size=ksz)\n",
    "    hist = model.fit(\n",
    "        x=[X_tr, S_tr], y=y_tr,\n",
    "        validation_data=([X_va, S_va], y_va) if len(X_va) else None,\n",
    "        epochs=200, batch_size=32, verbose=0, callbacks=cb\n",
    "    )\n",
    "\n",
    "    # Predict residuals (guard empty arrays)\n",
    "    has_val = len(X_va) > 0\n",
    "    has_test = len(X_te) > 0\n",
    "\n",
    "    res_val = model.predict([X_va, S_va], verbose=0).reshape(-1) if has_val else np.array([], dtype=np.float32)\n",
    "    res_te  = model.predict([X_te, S_te], verbose=0).reshape(-1) if has_test else np.array([], dtype=np.float32)\n",
    "\n",
    "    # Reconstruct levels: B_hat = B_naive * exp(residual)\n",
    "    dl_val_lvl = (N_va * np.exp(res_val)) if has_val else np.array([], dtype=np.float64)\n",
    "    dl_te_lvl  = (N_te * np.exp(res_te))  if has_test else np.array([], dtype=np.float64)\n",
    "\n",
    "    # Calibrate α on 2023 (fallback if no val)\n",
    "    if has_val:\n",
    "        alpha, _ = best_alpha(N_va, dl_val_lvl, A_va)\n",
    "    else:\n",
    "        alpha = 1.0  # default to DL only when no validation to tune blend\n",
    "    model_alphas[name] = alpha\n",
    "\n",
    "    # Blend on val/test\n",
    "    val_blend = (alpha * dl_val_lvl + (1 - alpha) * N_va) if has_val else np.array([], dtype=np.float64)\n",
    "    te_blend  = (alpha * dl_te_lvl  + (1 - alpha) * N_te) if has_test else np.array([], dtype=np.float64)\n",
    "\n",
    "    # Save preds\n",
    "    model_preds_val[name] = {\"dl\": dl_val_lvl, \"blend\": val_blend}\n",
    "    model_preds_test[name] = {\"dl\": dl_te_lvl,  \"blend\": te_blend}\n",
    "\n",
    "    # Metrics on 2024 (test)\n",
    "    mae, rmse, r2, mape = metrics_all(A_te, te_blend) if has_test else (np.nan, np.nan, np.nan, np.nan)\n",
    "    dl_metrics_rows.append({\n",
    "        \"model\": f\"{name}_Blend\",\n",
    "        \"n_eval\": int(len(A_te)),\n",
    "        \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE_%\": mape,\n",
    "        \"alpha\": alpha\n",
    "    })\n",
    "    mae2, rmse2, r22, mape2 = metrics_all(A_te, dl_te_lvl) if has_test else (np.nan, np.nan, np.nan, np.nan)\n",
    "    dl_metrics_rows.append({\n",
    "        \"model\": f\"{name}_DL_Level\",\n",
    "        \"n_eval\": int(len(A_te)),\n",
    "        \"MAE\": mae2, \"RMSE\": rmse2, \"R2\": r22, \"MAPE_%\": mape2,\n",
    "        \"alpha\": np.nan\n",
    "    })\n",
    "    print(f\"  α={alpha:.2f} | 2024 Blend MAE={mae:.2f} RMSE={rmse:.2f} R2={r2:.3f} MAPE%={mape:.2f}\")\n",
    "\n",
    "# Ensemble of blended predictions (mean across models)\n",
    "if len(model_preds_test):\n",
    "    te_blends_stack = np.column_stack([model_preds_test[m][\"blend\"] for m in MODEL_SPECS.keys()])\n",
    "    ens_blend = te_blends_stack.mean(axis=1) if te_blends_stack.size else np.array([], dtype=np.float64)\n",
    "    mae, rmse, r2, mape = metrics_all(A_te, ens_blend) if len(A_te) else (np.nan, np.nan, np.nan, np.nan)\n",
    "    dl_metrics_rows.append({\n",
    "        \"model\": \"Ensemble_Blend\",\n",
    "        \"n_eval\": int(len(A_te)),\n",
    "        \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE_%\": mape,\n",
    "        \"alpha\": np.nan\n",
    "    })\n",
    "\n",
    "# Build predictions dataframe for FY2024\n",
    "pred_rows = []\n",
    "if len(K_te):\n",
    "    for i, (sec, fy, ye) in enumerate(K_te):\n",
    "        row = {\n",
    "            \"Sector_12\": sec,\n",
    "            \"Fiscal_Year\": fy,\n",
    "            \"Year_End\": ye,\n",
    "            \"Actual\": float(A_te[i]),\n",
    "            \"Naive_Lag1\": float(N_te[i]),\n",
    "        }\n",
    "        for m in MODEL_SPECS.keys():\n",
    "            row[f\"{m}_DL_Level\"] = float(model_preds_test[m][\"dl\"][i]) if len(model_preds_test[m][\"dl\"]) else np.nan\n",
    "            row[f\"{m}_Blend\"]    = float(model_preds_test[m][\"blend\"][i]) if len(model_preds_test[m][\"blend\"]) else np.nan\n",
    "        if \"ens_blend\" in locals() and len(ens_blend):\n",
    "            row[\"Ensemble_Blend\"] = float(ens_blend[i])\n",
    "        pred_rows.append(row)\n",
    "\n",
    "# Safely build/save predictions even if empty\n",
    "if pred_rows:\n",
    "    pred_df = pd.DataFrame(pred_rows).sort_values([\"Sector_12\"]).reset_index(drop=True)\n",
    "else:\n",
    "    cols = [\"Sector_12\",\"Fiscal_Year\",\"Year_End\",\"Actual\",\"Naive_Lag1\"] \\\n",
    "           + [f\"{m}_DL_Level\" for m in MODEL_SPECS.keys()] \\\n",
    "           + [f\"{m}_Blend\" for m in MODEL_SPECS.keys()]\n",
    "    if \"ens_blend\" in locals():\n",
    "        cols += [\"Ensemble_Blend\"]\n",
    "    pred_df = pd.DataFrame(columns=cols)\n",
    "    print(\"Warning: No FY2024 sequences available for lookback,\"\n",
    "          \" predictions CSV will be empty. Consider reducing LOOKBACK.\")\n",
    "\n",
    "pred_df.to_csv(OUT_PRED_CSV, index=False)\n",
    "print(\"\\nSaved predictions:\", OUT_PRED_CSV)\n",
    "# ...existing code...\n",
    "\n",
    "# Save DL metrics\n",
    "dl_metrics_df = pd.DataFrame(dl_metrics_rows, columns=[\"model\",\"n_eval\",\"MAE\",\"RMSE\",\"R2\",\"MAPE_%\",\"alpha\"])\n",
    "dl_metrics_df.to_csv(OUT_METRICS_CSV, index=False)\n",
    "print(\"Saved DL metrics:\", OUT_METRICS_CSV)\n",
    "\n",
    "# Combine with baseline (Linear/Ridge/GBM) if available\n",
    "if IN_BASELINE.exists():\n",
    "    base_metrics = pd.read_csv(IN_BASELINE)\n",
    "    # Ensure consistent columns\n",
    "    common_cols = [\"model\",\"n_eval\",\"MAE\",\"RMSE\",\"R2\",\"MAPE_%\"]\n",
    "    base_metrics = base_metrics[common_cols]\n",
    "    all_metrics = pd.concat([base_metrics, dl_metrics_df[common_cols]], ignore_index=True)\n",
    "else:\n",
    "    all_metrics = dl_metrics_df.drop(columns=[\"alpha\"])\n",
    "\n",
    "all_metrics.to_csv(OUT_METRICS_ALL_CSV, index=False)\n",
    "print(\"Saved combined metrics:\", OUT_METRICS_ALL_CSV)\n",
    "\n",
    "# Plots: compare MAE/RMSE/R2/MAPE across models\n",
    "def barplot_metric(df, metric, out_path):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    dfx = df.copy()\n",
    "    dfx = dfx.sort_values(metric, ascending=(metric not in [\"R2\"]))\n",
    "    palette = [\"#4c78a8\" if \"DL\" not in m and \"Blend\" not in m else \"#59a14f\" for m in dfx[\"model\"]]\n",
    "    sns.barplot(data=dfx, x=\"model\", y=metric, palette=palette)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "barplot_metric(all_metrics, \"MAE\",   PLOTS_DIR / \"dl_vs_baselines_23_24_MAE.png\")\n",
    "barplot_metric(all_metrics, \"RMSE\",  PLOTS_DIR / \"dl_vs_baselines_23_24_RMSE.png\")\n",
    "barplot_metric(all_metrics, \"R2\",    PLOTS_DIR / \"dl_vs_baselines_23_24_R2.png\")\n",
    "barplot_metric(all_metrics, \"MAPE_%\",PLOTS_DIR / \"dl_vs_baselines_23_24_MAPE_%.png\")\n",
    "\n",
    "print(\"Saved plots to:\", PLOTS_DIR)\n",
    "\n",
    "# Optional: scatter Actual vs Best (Ensemble_Blend if present, else best blend)\n",
    "best_series = None\n",
    "best_name = None\n",
    "if \"ens_blend\" in locals():\n",
    "    best_series = ens_blend\n",
    "    best_name = \"Ensemble_Blend\"\n",
    "else:\n",
    "    # choose best by lowest MAE among blends\n",
    "    blend_rows = [r for r in dl_metrics_rows if r[\"model\"].endswith(\"_Blend\")]\n",
    "    if blend_rows:\n",
    "        best_name = min(blend_rows, key=lambda r: r[\"MAE\"])[\"model\"]\n",
    "        mkey = best_name.replace(\"_Blend\",\"\")\n",
    "        best_series = model_preds_test[mkey][\"blend\"]\n",
    "\n",
    "# Guard empty arrays before plotting\n",
    "if best_series is not None and len(A_te) and len(best_series):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(A_te, best_series, alpha=0.6)\n",
    "    lim = [0, max(np.max(A_te), np.max(best_series))*1.05]\n",
    "    plt.plot(lim, lim, \"k--\", lw=1)\n",
    "    plt.xlabel(\"Actual (FY2024)\")\n",
    "    plt.ylabel(f\"Predicted ({best_name})\")\n",
    "    plt.title(\"Actual vs Predicted (FY2024)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / \"actual_vs_pred_best.png\", dpi=150)\n",
    "    plt.close()\n",
    "    print(\"Saved scatter:\", PLOTS_DIR / \"actual_vs_pred_best.png\")\n",
    "\n",
    "print(\"\\nStep 7 complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ab1b8",
   "metadata": {},
   "source": [
    "8.Forecast next FY (optional FY24-25)\n",
    "* Create last lookback window per sector from latest year; predict FY24-25 levels via residual+naive reconstruction; attach last actual and growth vs 2024.\n",
    "* Save ensemble forecast and context; plot preds vs actuals if available.\n",
    "* Outputs: results/fy2425/sector_dl_forecast_2425.csv, results/fy2425/sector_dl_forecast_2425_with_context.csv, results/fy2425/forecasts/, results/fy2425/plots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c11713db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8: Training models (for forecast) and tuning α on 2023...\n",
      "  Training GRU_L5_U64 ...\n",
      "    α tuned on 2023: 1.00\n",
      "  Training LSTM_L5_U64 ...\n",
      "    α tuned on 2023: 0.00\n",
      "  Training StackedGRU_L5_64_32 ...\n",
      "    α tuned on 2023: 0.91\n",
      "  Training BiGRU_L5_U64 ...\n",
      "    α tuned on 2023: 0.23\n",
      "  Training TCN_L5_F64_K3 ...\n",
      "    α tuned on 2023: 0.65\n",
      "\n",
      "Built last windows for 2025 forecast: n_sectors=11, X_2025.shape=(11, 5, 21)\n",
      "\n",
      "Saved forecast CSVs and plots:\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/sector_dl_forecast_2425.csv\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/sector_dl_forecast_2425_with_context.csv\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/forecasts\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/plots\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Forecast next FY (FY2024-25) → final_data/data_2/results_Data_2/fy2425/*\n",
    "# - Create last lookback window (ending 2024) per sector on z_ features\n",
    "# - Predict residual for 2025, reconstruct level via B_2025 = B_2024 * exp(residual)\n",
    "# - Calibrate blend α on 2023 (same as Step 7), then produce blended 2025 forecasts\n",
    "# - Save ensemble forecast and context; plot predictions (and vs actual if FY2025 is available)\n",
    "#\n",
    "# Outputs (under results_Data_2/fy2425):\n",
    "# - sector_dl_forecast_2425.csv\n",
    "# - sector_dl_forecast_2425_with_context.csv\n",
    "# - forecasts/ (per-model CSVs)\n",
    "# - plots/\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models, callbacks, optimizers, losses\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"TensorFlow is required for Step 8. Install with: pip3 install tensorflow\") from e\n",
    "\n",
    "# Paths\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "DATA = ROOT / \"data\"\n",
    "RESULTS_ROOT = ROOT / \"results_Data_2\"\n",
    "FY_DIR = RESULTS_ROOT / \"fy2425\"\n",
    "FORECASTS_DIR = FY_DIR / \"forecasts\"\n",
    "PLOTS_DIR = FY_DIR / \"plots\"\n",
    "\n",
    "FY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FORECASTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inputs\n",
    "IN_TRAIN = DATA / \"sector_budget_features_train.csv\"   # ≤2023\n",
    "IN_TEST  = DATA / \"sector_budget_features_test_2024.csv\"  # 2024\n",
    "IN_META  = DATA / \"feature_columns.json\"\n",
    "IN_PANEL = DATA / \"sector_budget_macro_panel.csv\"  # has Budget_Amount, Budget_Lag1, Budget_Log_Diff1\n",
    "\n",
    "# Outputs\n",
    "OUT_FORECAST_CSV = FY_DIR / \"sector_dl_forecast_2425.csv\"\n",
    "OUT_FORECAST_CTX = FY_DIR / \"sector_dl_forecast_2425_with_context.csv\"\n",
    "\n",
    "LOOKBACK = 5\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Load feature meta\n",
    "with open(IN_META, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "z_features = meta.get(\"z_features\", [])\n",
    "if not z_features:\n",
    "    raise RuntimeError(\"No z_features found. Run Step 5 first.\")\n",
    "\n",
    "# Load inputs\n",
    "train_df = pd.read_csv(IN_TRAIN)\n",
    "test_df  = pd.read_csv(IN_TEST)\n",
    "\n",
    "panel = pd.read_csv(IN_PANEL, dtype={\"Sector_12\": \"string\", \"Fiscal_Year\": \"string\"})\n",
    "for c in [\"Budget_Amount\", \"Budget_Lag1\", \"Budget_Log_Diff1\", \"Year_End\"]:\n",
    "    if c in panel.columns:\n",
    "        panel[c] = pd.to_numeric(panel[c], errors=\"coerce\")\n",
    "panel[\"Fiscal_Year\"] = panel[\"Fiscal_Year\"].astype(\"string\").str.strip()\n",
    "\n",
    "# Merge feature frames to have all years up to 2024\n",
    "feats_all = pd.concat([train_df, test_df], ignore_index=True)\n",
    "feats_all[\"Fiscal_Year\"] = feats_all[\"Fiscal_Year\"].astype(\"string\").str.strip()\n",
    "\n",
    "# Attach target residual and naive baseline (from engineered panel)\n",
    "# IMPORTANT: do NOT include Budget_Amount from panel to avoid *_x/*_y suffixes\n",
    "use_cols = [\"Sector_12\", \"Fiscal_Year\", \"Year_End\", \"Budget_Lag1\", \"Budget_Log_Diff1\"]\n",
    "panel_use = panel[use_cols].copy()\n",
    "feats = feats_all.merge(panel_use, on=[\"Sector_12\", \"Fiscal_Year\", \"Year_End\"], how=\"left\")\n",
    "\n",
    "# If previous runs created *_x/*_y, coalesce to a single column\n",
    "def _coalesce(df, base):\n",
    "    if base in df.columns:\n",
    "        return df\n",
    "    x, y = f\"{base}_x\", f\"{base}_y\"\n",
    "    if x in df.columns or y in df.columns:\n",
    "        df[base] = df.get(x).combine_first(df.get(y))\n",
    "        df.drop(columns=[c for c in [x, y] if c in df.columns], inplace=True)\n",
    "    return df\n",
    "\n",
    "feats = _coalesce(feats, \"Budget_Amount\")\n",
    "\n",
    "# Final sanity\n",
    "if \"Budget_Amount\" not in feats.columns:\n",
    "    raise RuntimeError(\n",
    "        \"Budget_Amount missing after merge. Ensure Step 5 outputs include Budget_Amount \"\n",
    "        \"and re-run Step 5 (splits/scaling) before Step 8.\"\n",
    "    )\n",
    "\n",
    "# Sector index, features, embedding dims\n",
    "sectors = feats[\"Sector_12\"].astype(\"string\").fillna(\"UNK\").unique().tolist()\n",
    "sector2id = {s: i for i, s in enumerate(sorted(sectors))}\n",
    "n_sectors = len(sector2id)\n",
    "n_features = len(z_features)\n",
    "embed_dim = max(4, min(16, int(round(math.sqrt(n_sectors)))))\n",
    "\n",
    "# Train/val/test sequences (same protocol as Step 7)\n",
    "def build_sequences(df: pd.DataFrame, lookback: int, target_year: int | None = None):\n",
    "    X_list, S_list, y_list, keys = [], [], [], []\n",
    "    A_list, N_list = [], []\n",
    "    for s, g in df.groupby(\"Sector_12\", sort=False):\n",
    "        g = g.sort_values(\"Year_End\")\n",
    "        Z = g[z_features].values\n",
    "        y = g[\"Budget_Log_Diff1\"].values\n",
    "        A = g[\"Budget_Amount\"].values\n",
    "        N = g[\"Budget_Lag1\"].values\n",
    "        yrs = g[\"Year_End\"].values\n",
    "        fyears = g[\"Fiscal_Year\"].values\n",
    "\n",
    "        sid = sector2id.get(s, 0)\n",
    "        for i in range(lookback, len(g)):\n",
    "            if target_year is not None and int(yrs[i]) != int(target_year):\n",
    "                continue\n",
    "            if not np.isfinite(y[i]) or not np.isfinite(N[i]) or N[i] <= 0:\n",
    "                continue\n",
    "            X_seq = Z[i - lookback:i, :]\n",
    "            X_list.append(X_seq.astype(np.float32))\n",
    "            S_list.append(np.int32(sid))\n",
    "            y_list.append(np.float32(y[i]))\n",
    "            A_list.append(np.float64(A[i]))\n",
    "            N_list.append(np.float64(N[i]))\n",
    "            keys.append((str(s), str(fyears[i]), int(yrs[i])))\n",
    "    return (\n",
    "        np.array(X_list, dtype=np.float32),\n",
    "        np.array(S_list, dtype=np.int32),\n",
    "        np.array(y_list, dtype=np.float32),\n",
    "        np.array(A_list, dtype=np.float64),\n",
    "        np.array(N_list, dtype=np.float64),\n",
    "        keys,\n",
    "    )\n",
    "\n",
    "feats_hist_tr = feats[feats[\"Year_End\"] <= 2022].copy()\n",
    "feats_hist_va = feats[feats[\"Year_End\"] <= 2023].copy()\n",
    "\n",
    "X_tr, S_tr, y_tr, A_tr, N_tr, K_tr = build_sequences(feats_hist_tr, LOOKBACK, target_year=None)\n",
    "X_va, S_va, y_va, A_va, N_va, K_va = build_sequences(feats_hist_va, LOOKBACK, target_year=2023)\n",
    "\n",
    "if X_tr.shape[0] == 0:\n",
    "    raise RuntimeError(f\"No training sequences with lookback={LOOKBACK}. Reduce lookback or check z_ features.\")\n",
    "\n",
    "# Model core (same as Step 7)\n",
    "def huber_model_core(model_type: str, units_main: int = 64, kernel_size: int = 3):\n",
    "    seq_in = layers.Input(shape=(LOOKBACK, n_features), name=\"seq_in\")\n",
    "    sec_in = layers.Input(shape=(), dtype=\"int32\", name=\"sec_in\")\n",
    "    emb = layers.Embedding(input_dim=n_sectors, output_dim=embed_dim, name=\"sector_emb\")(sec_in)\n",
    "    emb_v = layers.Flatten()(emb)\n",
    "\n",
    "    if model_type == \"gru\":\n",
    "        enc = layers.GRU(units_main, name=\"enc_gru\")(seq_in)\n",
    "    elif model_type == \"lstm\":\n",
    "        enc = layers.LSTM(units_main, name=\"enc_lstm\")(seq_in)\n",
    "    elif model_type == \"bigru\":\n",
    "        enc = layers.Bidirectional(layers.GRU(units_main, name=\"enc_bigru_base\"), name=\"enc_bigru\")(seq_in)\n",
    "    elif model_type == \"stacked_gru\":\n",
    "        x = layers.GRU(units_main, return_sequences=True, name=\"enc_gru_1\")(seq_in)\n",
    "        enc = layers.GRU(max(16, units_main // 2), name=\"enc_gru_2\")(x)\n",
    "    elif model_type == \"tcn\":\n",
    "        x = seq_in\n",
    "        for d in [1, 2, 4]:\n",
    "            res = x\n",
    "            x = layers.Conv1D(filters=units_main, kernel_size=kernel_size, padding=\"causal\", dilation_rate=d, activation=\"relu\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Dropout(0.1)(x)\n",
    "            if res.shape[-1] != x.shape[-1]:\n",
    "                res = layers.Conv1D(filters=units_main, kernel_size=1, padding=\"same\")(res)\n",
    "            x = layers.Add()([res, x])\n",
    "            x = layers.Activation(\"relu\")(x)\n",
    "        enc = layers.GlobalAveragePooling1D()(x)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}\")\n",
    "\n",
    "    z = layers.Concatenate()([enc, emb_v])\n",
    "    z = layers.Dense(64, activation=\"relu\")(z)\n",
    "    z = layers.Dropout(0.2)(z)\n",
    "    out = layers.Dense(1, name=\"residual_log_growth\")(z)\n",
    "\n",
    "    model = models.Model(inputs=[seq_in, sec_in], outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=losses.Huber(delta=1.0),\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError(name=\"mae\")]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "MODEL_SPECS = {\n",
    "    \"GRU_L5_U64\":          (\"gru\",         64, 3),\n",
    "    \"LSTM_L5_U64\":         (\"lstm\",        64, 3),\n",
    "    \"StackedGRU_L5_64_32\": (\"stacked_gru\", 64, 3),\n",
    "    \"BiGRU_L5_U64\":        (\"bigru\",       64, 3),\n",
    "    \"TCN_L5_F64_K3\":       (\"tcn\",         64, 3),\n",
    "}\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=7, min_lr=1e-5)\n",
    "cb = [es, rlr]\n",
    "\n",
    "def best_alpha(naive_lvl, dl_lvl, actual_lvl):\n",
    "    alphas = np.linspace(0.0, 1.0, 101)\n",
    "    best_a, best_mae = 0.0, float(\"inf\")\n",
    "    for a in alphas:\n",
    "        blend = a * dl_lvl + (1 - a) * naive_lvl\n",
    "        mae = np.mean(np.abs(actual_lvl - blend))\n",
    "        if mae < best_mae:\n",
    "            best_mae, best_a = mae, a\n",
    "    return float(best_a), float(best_mae)\n",
    "\n",
    "# Train models, tune α on 2023\n",
    "print(\"\\nStep 8: Training models (for forecast) and tuning α on 2023...\")\n",
    "model_objs = {}\n",
    "model_alphas = {}\n",
    "\n",
    "for name, (mtype, units_main, ksz) in MODEL_SPECS.items():\n",
    "    print(f\"  Training {name} ...\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = huber_model_core(mtype, units_main=units_main, kernel_size=ksz)\n",
    "    _ = model.fit(\n",
    "        x=[X_tr, S_tr], y=y_tr,\n",
    "        validation_data=([X_va, S_va], y_va) if len(X_va) else None,\n",
    "        epochs=200, batch_size=32, verbose=0, callbacks=cb\n",
    "    )\n",
    "    # Val residuals -> levels\n",
    "    if len(X_va):\n",
    "        res_val = model.predict([X_va, S_va], verbose=0).reshape(-1)\n",
    "        dl_val_lvl = (N_va * np.exp(res_val))\n",
    "        alpha, _ = best_alpha(N_va, dl_val_lvl, A_va)\n",
    "    else:\n",
    "        alpha = 1.0\n",
    "    model_objs[name] = model\n",
    "    model_alphas[name] = alpha\n",
    "    print(f\"    α tuned on 2023: {alpha:.2f}\")\n",
    "\n",
    "# Build last windows (ending 2024) for each sector for 2025 inference\n",
    "feats_2024 = feats[feats[\"Year_End\"] <= 2024].copy()\n",
    "\n",
    "last_rows = []\n",
    "X_2025_list, S_2025_list, N_2025_list, keys_2025 = [], [], [], []\n",
    "\n",
    "for s, g in feats_2024.groupby(\"Sector_12\", sort=False):\n",
    "    g = g.sort_values(\"Year_End\")\n",
    "    if len(g) < LOOKBACK:\n",
    "        continue\n",
    "    # Need last window ending Year_End=2024\n",
    "    if (g[\"Year_End\"] == 2024).any():\n",
    "        # get indices for last LOOKBACK rows ending 2024\n",
    "        g_idx = g.index.tolist()\n",
    "        # ensure last row is 2024\n",
    "        last_idx = g[g[\"Year_End\"] == 2024].index[-1]\n",
    "        # position of last_idx within g\n",
    "        pos = g.index.get_loc(last_idx)\n",
    "        if pos + 1 >= LOOKBACK:\n",
    "            window_idx = g_idx[pos + 1 - LOOKBACK: pos + 1]\n",
    "            Z = g.loc[window_idx, z_features].values\n",
    "            if Z.shape != (LOOKBACK, n_features):\n",
    "                continue\n",
    "            # Naive for 2025 is last actual (2024 Budget)\n",
    "            a_last = g.loc[last_idx, \"Budget_Amount\"]\n",
    "            if not np.isfinite(a_last) or a_last <= 0:\n",
    "                continue\n",
    "            X_2025_list.append(Z.astype(np.float32))\n",
    "            S_2025_list.append(np.int32(sector2id.get(s, 0)))\n",
    "            N_2025_list.append(float(a_last))\n",
    "            keys_2025.append((str(s), \"24-25\", 2025, float(a_last)))\n",
    "\n",
    "X_2025 = np.array(X_2025_list, dtype=np.float32)\n",
    "S_2025 = np.array(S_2025_list, dtype=np.int32)\n",
    "N_2025 = np.array(N_2025_list, dtype=np.float64)\n",
    "\n",
    "print(f\"\\nBuilt last windows for 2025 forecast: n_sectors={len(keys_2025)}, X_2025.shape={X_2025.shape}\")\n",
    "\n",
    "if X_2025.shape[0] == 0:\n",
    "    print(\"Warning: No sectors have sufficient history for the chosen LOOKBACK to forecast 2025. Consider reducing LOOKBACK.\")\n",
    "    # still write empty outputs\n",
    "    pd.DataFrame(columns=[\"Sector_12\",\"Fiscal_Year\",\"Year_End\",\"Naive_Lag1_2024\",\"Ensemble_Blend_2025\",\"Growth_vs_2024_%\"]).to_csv(OUT_FORECAST_CSV, index=False)\n",
    "    pd.DataFrame(columns=[\"Sector_12\",\"Fiscal_Year\",\"Year_End\"]).to_csv(OUT_FORECAST_CTX, index=False)\n",
    "else:\n",
    "    # Predict per model; reconstruct DL level and blend with α; build ensemble\n",
    "    model_forecasts = {}\n",
    "    for name, model in model_objs.items():\n",
    "        res_pred = model.predict([X_2025, S_2025], verbose=0).reshape(-1)\n",
    "        dl_level = N_2025 * np.exp(res_pred)  # B_2025_DL\n",
    "        alpha = model_alphas[name]\n",
    "        blend = alpha * dl_level + (1 - alpha) * N_2025\n",
    "        model_forecasts[name] = {\"dl\": dl_level, \"blend\": blend}\n",
    "\n",
    "        # Save per-model forecast CSV\n",
    "        rows = []\n",
    "        for i, (sec, fy, ye, naive_2024) in enumerate(keys_2025):\n",
    "            rows.append({\n",
    "                \"Sector_12\": sec,\n",
    "                \"Fiscal_Year\": fy,\n",
    "                \"Year_End\": ye,\n",
    "                \"Naive_Lag1_2024\": naive_2024,\n",
    "                f\"{name}_DL_2025\": float(dl_level[i]),\n",
    "                f\"{name}_Blend_2025\": float(blend[i]),\n",
    "                \"alpha\": float(alpha)\n",
    "            })\n",
    "        pd.DataFrame(rows).to_csv(FORECASTS_DIR / f\"{name}_forecast_2425.csv\", index=False)\n",
    "\n",
    "    # Ensemble across blended forecasts\n",
    "    blends_stack = np.column_stack([model_forecasts[m][\"blend\"] for m in MODEL_SPECS.keys()])\n",
    "    ens_blend = blends_stack.mean(axis=1)\n",
    "\n",
    "    # Build compact forecast CSV\n",
    "    compact_rows = []\n",
    "    for i, (sec, fy, ye, naive_2024) in enumerate(keys_2025):\n",
    "        comp = {\n",
    "            \"Sector_12\": sec,\n",
    "            \"Fiscal_Year\": fy,\n",
    "            \"Year_End\": ye,\n",
    "            \"Naive_Lag1_2024\": float(naive_2024),\n",
    "            \"Ensemble_Blend_2025\": float(ens_blend[i]),\n",
    "        }\n",
    "        # Growth vs 2024 in %\n",
    "        if naive_2024 and np.isfinite(naive_2024):\n",
    "            comp[\"Growth_vs_2024_%\"] = float((ens_blend[i] - naive_2024) / naive_2024 * 100.0)\n",
    "        else:\n",
    "            comp[\"Growth_vs_2024_%\"] = np.nan\n",
    "        compact_rows.append(comp)\n",
    "    compact_df = pd.DataFrame(compact_rows).sort_values([\"Sector_12\"]).reset_index(drop=True)\n",
    "    compact_df.to_csv(OUT_FORECAST_CSV, index=False)\n",
    "\n",
    "    # Build context-rich forecast CSV (include per-model DL and Blend, ensemble, alpha per model)\n",
    "    ctx_rows = []\n",
    "    for i, (sec, fy, ye, naive_2024) in enumerate(keys_2025):\n",
    "        row = {\n",
    "            \"Sector_12\": sec,\n",
    "            \"Fiscal_Year\": fy,\n",
    "            \"Year_End\": ye,\n",
    "            \"Naive_Lag1_2024\": float(naive_2024),\n",
    "            \"Ensemble_Blend_2025\": float(ens_blend[i]),\n",
    "            \"Growth_vs_2024_%\": float((ens_blend[i] - naive_2024) / naive_2024 * 100.0) if naive_2024 else np.nan,\n",
    "        }\n",
    "        for m in MODEL_SPECS.keys():\n",
    "            row[f\"{m}_DL_2025\"] = float(model_forecasts[m][\"dl\"][i])\n",
    "            row[f\"{m}_Blend_2025\"] = float(model_forecasts[m][\"blend\"][i])\n",
    "            row[f\"{m}_alpha\"] = float(model_alphas[m])\n",
    "        ctx_rows.append(row)\n",
    "    ctx_df = pd.DataFrame(ctx_rows).sort_values([\"Sector_12\"]).reset_index(drop=True)\n",
    "    ctx_df.to_csv(OUT_FORECAST_CTX, index=False)\n",
    "\n",
    "    # Plot: bar plot of Ensemble forecast vs naive (2024), sorted by growth\n",
    "    plot_df = compact_df.copy()\n",
    "    plot_df[\"Growth_vs_2024_%\"] = pd.to_numeric(plot_df[\"Growth_vs_2024_%\"], errors=\"coerce\")\n",
    "    plot_df = plot_df.dropna(subset=[\"Growth_vs_2024_%\"]).sort_values(\"Growth_vs_2024_%\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=plot_df, x=\"Sector_12\", y=\"Growth_vs_2024_%\", color=\"#59a14f\")\n",
    "    plt.title(\"Forecasted Growth vs 2024 (Ensemble Blend) — FY2024-25\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / \"forecast_growth_vs_2024.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # Optional: if actual 2025 exists in panel, plot vs actual\n",
    "    has_2025 = (panel[\"Year_End\"] == 2025).any()\n",
    "    if has_2025:\n",
    "        actual_2025 = (\n",
    "            panel.loc[panel[\"Year_End\"] == 2025, [\"Sector_12\", \"Budget_Amount\"]]\n",
    "                 .dropna()\n",
    "                 .groupby(\"Sector_12\", as_index=False)[\"Budget_Amount\"].sum()\n",
    "        )\n",
    "        merged = compact_df.merge(actual_2025, on=\"Sector_12\", how=\"left\", suffixes=(\"\", \"_Actual_2025\"))\n",
    "        merged = merged.rename(columns={\"Budget_Amount\": \"Actual_2025\"})\n",
    "        merged_nonan = merged.dropna(subset=[\"Actual_2025\"])\n",
    "        if len(merged_nonan):\n",
    "            plt.figure(figsize=(6,6))\n",
    "            plt.scatter(merged_nonan[\"Actual_2025\"], merged_nonan[\"Ensemble_Blend_2025\"], alpha=0.6)\n",
    "            lim = [0, max(merged_nonan[\"Actual_2025\"].max(), merged_nonan[\"Ensemble_Blend_2025\"].max()) * 1.05]\n",
    "            plt.plot(lim, lim, \"k--\", lw=1)\n",
    "            plt.xlabel(\"Actual 2025\")\n",
    "            plt.ylabel(\"Forecast 2025 (Ensemble Blend)\")\n",
    "            plt.title(\"Actual vs Forecast (FY2024-25)\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(PLOTS_DIR / \"actual_vs_forecast_2025.png\", dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "    print(\"\\nSaved forecast CSVs and plots:\")\n",
    "    print(\" -\", OUT_FORECAST_CSV)\n",
    "    print(\" -\", OUT_FORECAST_CTX)\n",
    "    print(\" -\", FORECASTS_DIR)\n",
    "    print(\" -\", PLOTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a7b8620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ministry sequences (L=5) — Train:(610, 5, 28) Val:(61, 5, 28) Test:(61, 5, 28) n_features:28 n_sectors:11 n_min:61\n",
      "\n",
      "Training DL (ministry) and tuning α on 2023...\n",
      "  GRU_L5_U64...\n",
      "    α=1.00\n",
      "  LSTM_L5_U64...\n",
      "    α=0.00\n",
      "  StackedGRU_L5_64_32...\n",
      "    α=0.87\n",
      "  BiGRU_L5_U64...\n",
      "    α=0.21\n",
      "  TCN_L5_F64_K3...\n",
      "    α=0.00\n",
      "\n",
      "Saved ministry metrics (FY2024): /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/metrics/ministry_metrics_23_24.csv\n",
      "2025 ministry windows: 61 ministries\n",
      "\n",
      "Saved ministry forecasts:\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/ministry_forecast_2425.csv\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/ministry_forecast_2425_with_context.csv\n",
      " - per-model files: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/forecasts\n",
      " - plots: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/plots\n"
     ]
    }
   ],
   "source": [
    "# Step 8 (Ministry): FY2024-25 ministry-wise forecasts (DL vs Linear) → results_Data_2/fy2425/ministries/*\n",
    "# - Build ministry-level features from sector_ministry_timeseries + sector panel/macros\n",
    "# - Residual learning on log-growth vs Naive(Lag1); embeddings for Sector and Ministry; validate α on 2023\n",
    "# - Linear baselines (OLS, Ridge) on flattened lookback windows; same residual reconstruction and α tuning\n",
    "# - Evaluate on FY2024; forecast FY2025 from windows ending 2024; save combined outputs\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# TensorFlow (for DL)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models, callbacks, optimizers, losses\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"TensorFlow is required for this step. Install with: pip3 install tensorflow\") from e\n",
    "\n",
    "# Paths\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "DATA = ROOT / \"data\"\n",
    "RESULTS_ROOT = ROOT / \"results_Data_2\"\n",
    "\n",
    "FY_DIR = RESULTS_ROOT / \"fy2425\" / \"ministries\"\n",
    "FORECASTS_DIR = FY_DIR / \"forecasts\"\n",
    "PLOTS_DIR = FY_DIR / \"plots\"\n",
    "METRICS_DIR = RESULTS_ROOT / \"metrics\"\n",
    "\n",
    "FY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FORECASTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inputs\n",
    "IN_MIN_TS   = DATA / \"sector_ministry_timeseries.csv\"       # ministry-level long ts with Sector_12\n",
    "IN_SECTOR_P = DATA / \"sector_budget_macro_panel.csv\"        # sector-level engineered panel (Step 4)\n",
    "IN_MACRO    = DATA / \"macro_indicators_wb.csv\"              # for safety if needed (not strictly required)\n",
    "\n",
    "# Outputs\n",
    "OUT_MIN_COMPACT = FY_DIR / \"ministry_forecast_2425.csv\"\n",
    "OUT_MIN_CONTEXT = FY_DIR / \"ministry_forecast_2425_with_context.csv\"\n",
    "OUT_MIN_METRICS = METRICS_DIR / \"ministry_metrics_23_24.csv\"\n",
    "\n",
    "LOOKBACK = 5\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "def fy_end_year_short(s: str) -> int:\n",
    "    s = str(s).strip()\n",
    "    m = re.fullmatch(r\"(\\d{2})-(\\d{2})\", s)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unexpected Fiscal_Year format: {s}\")\n",
    "    return 2000 + int(m.group(2))\n",
    "\n",
    "# Load ministry time series\n",
    "min_ts = pd.read_csv(IN_MIN_TS, dtype={\"Sector_12\":\"string\",\"Base_Ministry\":\"string\",\"Fiscal_Year\":\"string\"})\n",
    "min_ts[\"Fiscal_Year\"] = min_ts[\"Fiscal_Year\"].astype(\"string\").str.strip()\n",
    "for c in [\"Budget_Amount\",\"Sector_Total\",\"Ministry_Share_Sector\",\"Year_End\"]:\n",
    "    if c in min_ts.columns:\n",
    "        min_ts[c] = pd.to_numeric(min_ts[c], errors=\"coerce\")\n",
    "if \"Year_End\" not in min_ts.columns:\n",
    "    min_ts[\"Year_End\"] = min_ts[\"Fiscal_Year\"].map(fy_end_year_short)\n",
    "\n",
    "# Attach sector-level engineered/macros from panel (Step 4 output)\n",
    "sec_panel = pd.read_csv(IN_SECTOR_P, dtype={\"Sector_12\":\"string\",\"Fiscal_Year\":\"string\"})\n",
    "sec_panel[\"Fiscal_Year\"] = sec_panel[\"Fiscal_Year\"].astype(\"string\").str.strip()\n",
    "# choose useful sector/macros cols if present\n",
    "sec_keep = [\n",
    "    \"Sector_12\",\"Fiscal_Year\",\"Year_End\",\n",
    "    \"Sector_Share_GDP\",\"Sector_Share_Lag1\",\"Sector_Share_Growth\",\n",
    "    \"Share_Log_Diff1\",\"Share_LogDiff1_MA3\",\n",
    "    \"GDP_Growth_Rate\",\"Inflation_CPI\",\"Exchange_Rate_USD\",\"Fiscal_Deficit_GDP\",\n",
    "    \"Global_GDP_Growth\",\"Election_Year\",\"High_Inflation\",\"GDP_Growth_Lag1\",\"Inflation_Lag1\",\n",
    "    \"Inflation_x_Election\",\"GDPGrowth_x_Election\",\"Trend\"\n",
    "]\n",
    "sec_use = [c for c in sec_keep if c in sec_panel.columns]\n",
    "sec_p = sec_panel[sec_use].copy()\n",
    "# prefix sector cols to avoid collision\n",
    "pref = {}\n",
    "for c in sec_p.columns:\n",
    "    if c not in [\"Sector_12\",\"Fiscal_Year\",\"Year_End\"]:\n",
    "        pref[c] = f\"Sec_{c}\"\n",
    "sec_p = sec_p.rename(columns=pref)\n",
    "\n",
    "# Merge sector/macros into ministry rows\n",
    "df = min_ts.merge(sec_p, on=[\"Sector_12\",\"Fiscal_Year\",\"Year_End\"], how=\"left\")\n",
    "\n",
    "# Engineering at ministry level\n",
    "df = df.sort_values([\"Sector_12\",\"Base_Ministry\",\"Year_End\"])\n",
    "# Budget lags and growth\n",
    "df[\"Min_Budget_Lag1\"] = df.groupby([\"Sector_12\",\"Base_Ministry\"])[\"Budget_Amount\"].shift(1)\n",
    "df[\"Min_Budget_Lag2\"] = df.groupby([\"Sector_12\",\"Base_Ministry\"])[\"Budget_Amount\"].shift(2)\n",
    "df[\"Min_Budget_Log\"]  = np.log(df[\"Budget_Amount\"].where(df[\"Budget_Amount\"]>0))\n",
    "df[\"Min_Budget_Log_Diff1\"] = df.groupby([\"Sector_12\",\"Base_Ministry\"])[\"Min_Budget_Log\"].diff(1)\n",
    "df[\"Min_Budget_LogDiff1_MA3\"] = df.groupby([\"Sector_12\",\"Base_Ministry\"])[\"Min_Budget_Log_Diff1\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "df[\"Min_Budget_Growth_Lag1\"] = df[\"Budget_Amount\"]/df[\"Min_Budget_Lag1\"] - 1\n",
    "\n",
    "# Ministry share lag/growth/log-diff\n",
    "if \"Ministry_Share_Sector\" in df.columns:\n",
    "    df[\"Min_Share_Lag1\"] = df.groupby([\"Sector_12\",\"Base_Ministry\"])[\"Ministry_Share_Sector\"].shift(1)\n",
    "    df[\"Min_Share_Growth\"] = df[\"Ministry_Share_Sector\"]/df[\"Min_Share_Lag1\"] - 1\n",
    "    df[\"Min_Share_Log\"] = np.log(df[\"Ministry_Share_Sector\"].where(df[\"Ministry_Share_Sector\"]>0))\n",
    "    df[\"Min_Share_Log_Diff1\"] = df.groupby([\"Sector_12\",\"Base_Ministry\"])[\"Min_Share_Log\"].diff(1)\n",
    "    df[\"Min_Share_LogDiff1_MA3\"] = df.groupby([\"Sector_12\",\"Base_Ministry\"])[\"Min_Share_Log_Diff1\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "\n",
    "# Trend within ministry\n",
    "df[\"Min_Trend\"] = df.groupby([\"Sector_12\",\"Base_Ministry\"]).cumcount() + 1\n",
    "\n",
    "# Clean inf artifacts\n",
    "df.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Define feature whitelist (present columns only)\n",
    "min_feats = [\n",
    "    \"Min_Budget_Lag1\",\"Min_Budget_Lag2\",\"Min_Budget_Growth_Lag1\",\n",
    "    \"Min_Budget_Log_Diff1\",\"Min_Budget_LogDiff1_MA3\",\n",
    "    \"Ministry_Share_Sector\",\"Min_Share_Lag1\",\"Min_Share_Growth\",\n",
    "    \"Min_Share_Log_Diff1\",\"Min_Share_LogDiff1_MA3\",\"Min_Trend\"\n",
    "]\n",
    "sec_feats = [\n",
    "    \"Sec_Sector_Share_GDP\",\"Sec_Sector_Share_Lag1\",\"Sec_Sector_Share_Growth\",\n",
    "    \"Sec_Share_Log_Diff1\",\"Sec_Share_LogDiff1_MA3\",\n",
    "    \"Sec_GDP_Growth_Rate\",\"Sec_Inflation_CPI\",\"Sec_Exchange_Rate_USD\",\"Sec_Fiscal_Deficit_GDP\",\n",
    "    \"Sec_Global_GDP_Growth\",\"Sec_Election_Year\",\"Sec_High_Inflation\",\n",
    "    \"Sec_GDP_Growth_Lag1\",\"Sec_Inflation_Lag1\",\n",
    "    \"Sec_Inflation_x_Election\",\"Sec_GDPGrowth_x_Election\",\"Sec_Trend\"\n",
    "]\n",
    "feat_cols = [c for c in (min_feats + sec_feats) if c in df.columns]\n",
    "\n",
    "# Split flags: train ≤2023, val=2023, test=2024\n",
    "if \"Year_End\" not in df.columns:\n",
    "    df[\"Year_End\"] = df[\"Fiscal_Year\"].map(fy_end_year_short)\n",
    "df[\"Split\"] = np.where(df[\"Year_End\"]==2024, \"test\",\n",
    "                np.where(df[\"Year_End\"]==2023, \"val\", \"train\"))\n",
    "train_mask = df[\"Year_End\"] <= 2023\n",
    "val_mask   = df[\"Year_End\"] == 2023\n",
    "test_mask  = df[\"Year_End\"] == 2024\n",
    "\n",
    "# Impute+scale on train only\n",
    "for c in feat_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "scaler  = StandardScaler()\n",
    "X_train = df.loc[train_mask, feat_cols]\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "_ = scaler.fit(X_train_imp)\n",
    "\n",
    "X_all_imp = imputer.transform(df[feat_cols])\n",
    "X_all_std = scaler.transform(X_all_imp)\n",
    "z_cols = [f\"z_{c}\" for c in feat_cols]\n",
    "for i, c in enumerate(z_cols):\n",
    "    df[c] = X_all_std[:, i]\n",
    "\n",
    "# Identity mappings\n",
    "sectors = sorted(df[\"Sector_12\"].dropna().astype(\"string\").unique().tolist())\n",
    "mins    = sorted(df[\"Base_Ministry\"].dropna().astype(\"string\").unique().tolist())\n",
    "sector2id = {s:i for i,s in enumerate(sectors)}\n",
    "min2id    = {m:i for i,m in enumerate(mins)}\n",
    "n_sectors = len(sector2id)\n",
    "n_min     = len(min2id)\n",
    "n_features = len(z_cols)\n",
    "embed_sec = max(4, min(16, int(round(math.sqrt(n_sectors)))))\n",
    "embed_min = max(4, min(16, int(round(math.sqrt(n_min)))))\n",
    "\n",
    "# Sequence builder (group by Sector_12, Base_Ministry)\n",
    "def build_sequences_min(dfin: pd.DataFrame, lookback: int, target_year: int|None):\n",
    "    X_list, S_list, M_list, y_list, keys = [], [], [], [], []\n",
    "    A_list, N_list = [], []\n",
    "    for (sec, bm), g in dfin.groupby([\"Sector_12\",\"Base_Ministry\"], sort=False):\n",
    "        g = g.sort_values(\"Year_End\")\n",
    "        Z = g[z_cols].values\n",
    "        y = g[\"Min_Budget_Log_Diff1\"].values\n",
    "        A = g[\"Budget_Amount\"].values\n",
    "        N = g[\"Min_Budget_Lag1\"].values\n",
    "        yrs = g[\"Year_End\"].values\n",
    "        fyears = g[\"Fiscal_Year\"].values\n",
    "\n",
    "        sid = np.int32(sector2id.get(str(sec), 0))\n",
    "        mid = np.int32(min2id.get(str(bm), 0))\n",
    "        for i in range(lookback, len(g)):\n",
    "            if target_year is not None and int(yrs[i]) != int(target_year):\n",
    "                continue\n",
    "            if not np.isfinite(y[i]) or not np.isfinite(N[i]) or N[i] <= 0:\n",
    "                continue\n",
    "            X_list.append(Z[i-lookback:i, :].astype(np.float32))\n",
    "            S_list.append(sid); M_list.append(mid)\n",
    "            y_list.append(np.float32(y[i]))\n",
    "            A_list.append(np.float64(A[i]))\n",
    "            N_list.append(np.float64(N[i]))\n",
    "            keys.append((str(sec), str(bm), str(fyears[i]), int(yrs[i])))\n",
    "    if not len(X_list):\n",
    "        return (np.zeros((0,lookback,n_features),dtype=np.float32),\n",
    "                np.zeros((0,),dtype=np.int32),\n",
    "                np.zeros((0,),dtype=np.int32),\n",
    "                np.zeros((0,),dtype=np.float32),\n",
    "                np.zeros((0,),dtype=np.float64),\n",
    "                np.zeros((0,),dtype=np.float64),\n",
    "                [])\n",
    "    return (np.stack(X_list), np.array(S_list), np.array(M_list), np.array(y_list),\n",
    "            np.array(A_list), np.array(N_list), keys)\n",
    "\n",
    "# Build split datasets for sequences\n",
    "df_hist_tr = df[df[\"Year_End\"] <= 2022].copy()\n",
    "df_hist_va = df[df[\"Year_End\"] <= 2023].copy()\n",
    "df_hist_te = df[df[\"Year_End\"] <= 2024].copy()\n",
    "\n",
    "X_tr, S_tr, M_tr, y_tr, A_tr, N_tr, K_tr = build_sequences_min(df_hist_tr, LOOKBACK, None)\n",
    "X_va, S_va, M_va, y_va, A_va, N_va, K_va = build_sequences_min(df_hist_va, LOOKBACK, 2023)\n",
    "X_te, S_te, M_te, y_te, A_te, N_te, K_te = build_sequences_min(df_hist_te, LOOKBACK, 2024)\n",
    "\n",
    "print(f\"Ministry sequences (L={LOOKBACK}) — Train:{X_tr.shape} Val:{X_va.shape} Test:{X_te.shape} n_features:{n_features} n_sectors:{n_sectors} n_min:{n_min}\")\n",
    "if X_tr.shape[0]==0:\n",
    "    raise RuntimeError(\"No ministry training sequences. Consider reducing LOOKBACK or check features.\")\n",
    "\n",
    "# DL model with sector + ministry embeddings\n",
    "def dl_model_core(model_type=\"gru\", units=64, kernel=3):\n",
    "    seq_in = layers.Input(shape=(LOOKBACK, n_features), name=\"seq_in\")\n",
    "    sec_in = layers.Input(shape=(), dtype=\"int32\", name=\"sec_in\")\n",
    "    min_in = layers.Input(shape=(), dtype=\"int32\", name=\"min_in\")\n",
    "\n",
    "    sec_emb = layers.Embedding(n_sectors, embed_sec, name=\"sec_emb\")(sec_in)\n",
    "    min_emb = layers.Embedding(n_min,     embed_min, name=\"min_emb\")(min_in)\n",
    "    sec_v, min_v = layers.Flatten()(sec_emb), layers.Flatten()(min_emb)\n",
    "\n",
    "    if model_type==\"gru\":\n",
    "        enc = layers.GRU(units, name=\"enc_gru\")(seq_in)\n",
    "    elif model_type==\"lstm\":\n",
    "        enc = layers.LSTM(units, name=\"enc_lstm\")(seq_in)\n",
    "    elif model_type==\"bigru\":\n",
    "        enc = layers.Bidirectional(layers.GRU(units, name=\"enc_bigru_base\"), name=\"enc_bigru\")(seq_in)\n",
    "    elif model_type==\"stacked_gru\":\n",
    "        x = layers.GRU(units, return_sequences=True, name=\"enc_gru_1\")(seq_in)\n",
    "        enc = layers.GRU(max(16, units//2), name=\"enc_gru_2\")(x)\n",
    "    elif model_type==\"tcn\":\n",
    "        x = seq_in\n",
    "        for d in [1,2,4]:\n",
    "            res = x\n",
    "            x = layers.Conv1D(units, kernel, padding=\"causal\", dilation_rate=d, activation=\"relu\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Dropout(0.1)(x)\n",
    "            if res.shape[-1] != x.shape[-1]:\n",
    "                res = layers.Conv1D(units, 1, padding=\"same\")(res)\n",
    "            x = layers.Add()([res, x]); x = layers.Activation(\"relu\")(x)\n",
    "        enc = layers.GlobalAveragePooling1D()(x)\n",
    "    else:\n",
    "        raise ValueError(model_type)\n",
    "\n",
    "    z = layers.Concatenate()([enc, sec_v, min_v])\n",
    "    z = layers.Dense(64, activation=\"relu\")(z)\n",
    "    z = layers.Dropout(0.2)(z)\n",
    "    out = layers.Dense(1, name=\"residual_log_growth\")(z)\n",
    "\n",
    "    model = models.Model(inputs=[seq_in, sec_in, min_in], outputs=out)\n",
    "    model.compile(optimizer=optimizers.Adam(1e-3), loss=losses.Huber(1.0),\n",
    "                  metrics=[tf.keras.metrics.MeanAbsoluteError(name=\"mae\")])\n",
    "    return model\n",
    "\n",
    "MODEL_SPECS = {\n",
    "    \"GRU_L5_U64\":          (\"gru\",         64, 3),\n",
    "    \"LSTM_L5_U64\":         (\"lstm\",        64, 3),\n",
    "    \"StackedGRU_L5_64_32\": (\"stacked_gru\", 64, 3),\n",
    "    \"BiGRU_L5_U64\":        (\"bigru\",       64, 3),\n",
    "    \"TCN_L5_F64_K3\":       (\"tcn\",         64, 3),\n",
    "}\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=7, min_lr=1e-5)\n",
    "cb = [es, rlr]\n",
    "\n",
    "def best_alpha(naive_lvl, dl_lvl, actual_lvl):\n",
    "    alphas = np.linspace(0.0, 1.0, 101)\n",
    "    best_a, best_mae = 0.0, float(\"inf\")\n",
    "    for a in alphas:\n",
    "        blend = a * dl_lvl + (1 - a) * naive_lvl\n",
    "        mae = np.mean(np.abs(actual_lvl - blend))\n",
    "        if mae < best_mae:\n",
    "            best_mae, best_a = mae, a\n",
    "    return float(best_a), float(best_mae)\n",
    "\n",
    "def metrics_all(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float); y_pred = np.asarray(y_pred, dtype=float)\n",
    "    mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if not np.any(mask): return np.nan, np.nan, np.nan, np.nan\n",
    "    yt, yp = y_true[mask], y_pred[mask]\n",
    "    mae = np.mean(np.abs(yt - yp))\n",
    "    rmse = float(np.sqrt(np.mean((yt - yp)**2)))\n",
    "    r2 = 1.0 - (np.sum((yt-yp)**2) / np.sum((yt - np.mean(yt))**2) if np.sum((yt - np.mean(yt))**2)>0 else np.nan)\n",
    "    mape = np.mean(np.abs((yt - yp)/yt)) * 100.0 if np.all(yt != 0) else np.nan\n",
    "    return mae, rmse, r2, mape\n",
    "\n",
    "# Train DL models and tune α on 2023\n",
    "print(\"\\nTraining DL (ministry) and tuning α on 2023...\")\n",
    "dl_models = {}\n",
    "dl_alphas = {}\n",
    "dl_preds_test = {}\n",
    "dl_metrics_rows = []\n",
    "\n",
    "has_val = len(X_va) > 0\n",
    "has_test = len(X_te) > 0\n",
    "\n",
    "for name, (mtype, units, ksz) in MODEL_SPECS.items():\n",
    "    print(f\"  {name}...\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = dl_model_core(mtype, units, ksz)\n",
    "    _ = model.fit([X_tr, S_tr, M_tr], y_tr,\n",
    "                  validation_data=([X_va, S_va, M_va], y_va) if has_val else None,\n",
    "                  epochs=200, batch_size=32, verbose=0, callbacks=cb)\n",
    "    # Predict residuals\n",
    "    res_val = model.predict([X_va, S_va, M_va], verbose=0).reshape(-1) if has_val else np.array([],dtype=np.float32)\n",
    "    res_te  = model.predict([X_te, S_te, M_te], verbose=0).reshape(-1) if has_test else np.array([],dtype=np.float32)\n",
    "    dl_val_lvl = (N_va * np.exp(res_val)) if has_val else np.array([],dtype=np.float64)\n",
    "    dl_te_lvl  = (N_te * np.exp(res_te))  if has_test else np.array([],dtype=np.float64)\n",
    "    # α\n",
    "    alpha, _ = best_alpha(N_va, dl_val_lvl, A_va) if has_val else (1.0, np.nan)\n",
    "    dl_alphas[name] = alpha\n",
    "    te_blend = (alpha * dl_te_lvl + (1 - alpha) * N_te) if has_test else np.array([],dtype=np.float64)\n",
    "    dl_preds_test[name] = {\"dl\": dl_te_lvl, \"blend\": te_blend}\n",
    "    # metrics\n",
    "    if has_test:\n",
    "        mae, rmse, r2, mape = metrics_all(A_te, te_blend)\n",
    "        dl_metrics_rows.append({\"model\": f\"{name}_Blend\", \"n_eval\": int(len(A_te)), \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE_%\": mape, \"alpha\": alpha})\n",
    "        mae2, rmse2, r22, mape2 = metrics_all(A_te, dl_te_lvl)\n",
    "        dl_metrics_rows.append({\"model\": f\"{name}_DL_Level\", \"n_eval\": int(len(A_te)), \"MAE\": mae2, \"RMSE\": rmse2, \"R2\": r22, \"MAPE_%\": mape2, \"alpha\": np.nan})\n",
    "    dl_models[name] = model\n",
    "    print(f\"    α={alpha:.2f}\")\n",
    "\n",
    "# DL ensemble\n",
    "if has_test and len(dl_preds_test):\n",
    "    te_stack = np.column_stack([dl_preds_test[m][\"blend\"] for m in MODEL_SPECS.keys()])\n",
    "    ens_blend = te_stack.mean(axis=1)\n",
    "    mae, rmse, r2, mape = metrics_all(A_te, ens_blend)\n",
    "    dl_metrics_rows.append({\"model\":\"DL_Ensemble_Blend\",\"n_eval\":int(len(A_te)),\"MAE\":mae,\"RMSE\":rmse,\"R2\":r2,\"MAPE_%\":mape,\"alpha\":np.nan})\n",
    "\n",
    "# Linear models on flattened windows (predict residual log-growth)\n",
    "def flatten_windows(X: np.ndarray) -> np.ndarray:\n",
    "    return X.reshape((X.shape[0], X.shape[1]*X.shape[2])) if len(X) else np.zeros((0, LOOKBACK*n_features), dtype=np.float32)\n",
    "X_tr_flat = flatten_windows(X_tr)\n",
    "X_va_flat = flatten_windows(X_va)\n",
    "X_te_flat = flatten_windows(X_te)\n",
    "\n",
    "lin_models = {\n",
    "    \"LinearOLS\": LinearRegression(),\n",
    "    \"Ridge\":     Ridge(alpha=1.0, random_state=42)\n",
    "}\n",
    "lin_alphas = {}\n",
    "lin_preds_test = {}\n",
    "for lname, lmod in lin_models.items():\n",
    "    lmod.fit(X_tr_flat, y_tr)\n",
    "    res_val = lmod.predict(X_va_flat) if has_val else np.array([],dtype=float)\n",
    "    res_te  = lmod.predict(X_te_flat) if has_test else np.array([],dtype=float)\n",
    "    dl_val_lvl = (N_va * np.exp(res_val)) if has_val else np.array([],dtype=float)\n",
    "    dl_te_lvl  = (N_te * np.exp(res_te))  if has_test else np.array([],dtype=float)\n",
    "    alpha, _ = best_alpha(N_va, dl_val_lvl, A_va) if has_val else (1.0, np.nan)\n",
    "    lin_alphas[lname] = alpha\n",
    "    te_blend = (alpha * dl_te_lvl + (1 - alpha) * N_te) if has_test else np.array([],dtype=float)\n",
    "    lin_preds_test[lname] = {\"dl\": dl_te_lvl, \"blend\": te_blend}\n",
    "    if has_test:\n",
    "        mae, rmse, r2, mape = metrics_all(A_te, te_blend)\n",
    "        dl_metrics_rows.append({\"model\": f\"{lname}_Blend\", \"n_eval\": int(len(A_te)), \"MAE\":mae,\"RMSE\":rmse,\"R2\":r2,\"MAPE_%\":mape,\"alpha\":alpha})\n",
    "        mae2, rmse2, r22, mape2 = metrics_all(A_te, dl_te_lvl)\n",
    "        dl_metrics_rows.append({\"model\": f\"{lname}_DL_Level\", \"n_eval\": int(len(A_te)), \"MAE\":mae2,\"RMSE\":rmse2,\"R2\":r22,\"MAPE_%\":mape2,\"alpha\":np.nan})\n",
    "\n",
    "# Naive baseline (FY2024 eval)\n",
    "if has_test:\n",
    "    mae, rmse, r2, mape = metrics_all(A_te, N_te)\n",
    "    dl_metrics_rows.append({\"model\":\"Naive_Lag1\",\"n_eval\":int(len(A_te)),\"MAE\":mae,\"RMSE\":rmse,\"R2\":r2,\"MAPE_%\":mape,\"alpha\":np.nan})\n",
    "\n",
    "# Save 2024 metrics\n",
    "metrics_df = pd.DataFrame(dl_metrics_rows, columns=[\"model\",\"n_eval\",\"MAE\",\"RMSE\",\"R2\",\"MAPE_%\",\"alpha\"])\n",
    "metrics_df.to_csv(OUT_MIN_METRICS, index=False)\n",
    "print(\"\\nSaved ministry metrics (FY2024):\", OUT_MIN_METRICS)\n",
    "\n",
    "# Build last windows for 2025 forecast (ending 2024)\n",
    "df_2024 = df[df[\"Year_End\"] <= 2024].copy()\n",
    "\n",
    "X_2025_list, S_2025_list, M_2025_list, N_2025_list, keys_2025 = [], [], [], [], []\n",
    "for (sec, bm), g in df_2024.groupby([\"Sector_12\",\"Base_Ministry\"], sort=False):\n",
    "    g = g.sort_values(\"Year_End\")\n",
    "    if len(g) < LOOKBACK: \n",
    "        continue\n",
    "    if (g[\"Year_End\"] == 2024).any():\n",
    "        last_idx = g[g[\"Year_End\"]==2024].index[-1]\n",
    "        pos = g.index.get_loc(last_idx)\n",
    "        if pos + 1 >= LOOKBACK:\n",
    "            idxs = g.index.tolist()[pos+1-LOOKBACK:pos+1]\n",
    "            Z = g.loc[idxs, z_cols].values\n",
    "            if Z.shape != (LOOKBACK, n_features): \n",
    "                continue\n",
    "            a_last = g.loc[last_idx, \"Budget_Amount\"]\n",
    "            if not np.isfinite(a_last) or a_last <= 0: \n",
    "                continue\n",
    "            X_2025_list.append(Z.astype(np.float32))\n",
    "            S_2025_list.append(np.int32(sector2id.get(str(sec), 0)))\n",
    "            M_2025_list.append(np.int32(min2id.get(str(bm), 0)))\n",
    "            N_2025_list.append(float(a_last))\n",
    "            keys_2025.append((str(sec), str(bm), \"24-25\", 2025, float(a_last)))\n",
    "\n",
    "X_2025 = np.array(X_2025_list, dtype=np.float32)\n",
    "S_2025 = np.array(S_2025_list, dtype=np.int32)\n",
    "M_2025 = np.array(M_2025_list, dtype=np.int32)\n",
    "N_2025 = np.array(N_2025_list, dtype=np.float64)\n",
    "print(f\"2025 ministry windows: {X_2025.shape[0]} ministries\")\n",
    "\n",
    "if X_2025.shape[0]==0:\n",
    "    # write empty skeletons\n",
    "    pd.DataFrame(columns=[\"Sector_12\",\"Base_Ministry\",\"Fiscal_Year\",\"Year_End\",\"Naive_Lag1_2024\",\"DL_Ensemble_2025\",\"Linear_Ridge_2025\",\"Growth_vs_2024_%\"]).to_csv(OUT_MIN_COMPACT, index=False)\n",
    "    pd.DataFrame(columns=[\"Sector_12\",\"Base_Ministry\",\"Fiscal_Year\",\"Year_End\"]).to_csv(OUT_MIN_CONTEXT, index=False)\n",
    "else:\n",
    "    # DL per-model forecasts\n",
    "    dl_forecasts = {}\n",
    "    for name, model in dl_models.items():\n",
    "        res = model.predict([X_2025, S_2025, M_2025], verbose=0).reshape(-1)\n",
    "        dl_lvl = N_2025 * np.exp(res)\n",
    "        alpha = dl_alphas[name]\n",
    "        blend = alpha * dl_lvl + (1 - alpha) * N_2025\n",
    "        dl_forecasts[name] = {\"dl\": dl_lvl, \"blend\": blend}\n",
    "        # save per-model file\n",
    "        rows = []\n",
    "        for i, (sec, bm, fy, ye, naive_2024) in enumerate(keys_2025):\n",
    "            rows.append({\n",
    "                \"Sector_12\": sec, \"Base_Ministry\": bm, \"Fiscal_Year\": fy, \"Year_End\": ye,\n",
    "                \"Naive_Lag1_2024\": naive_2024,\n",
    "                f\"{name}_DL_2025\": float(dl_lvl[i]), f\"{name}_Blend_2025\": float(blend[i]), \"alpha\": float(alpha)\n",
    "            })\n",
    "        pd.DataFrame(rows).to_csv(FORECASTS_DIR / f\"ministry_{name}_forecast_2425.csv\", index=False)\n",
    "\n",
    "    # DL ensemble\n",
    "    ens_stack = np.column_stack([dl_forecasts[m][\"blend\"] for m in MODEL_SPECS.keys()])\n",
    "    dl_ens = ens_stack.mean(axis=1)\n",
    "\n",
    "    # Linear forecasts (residual on flattened windows)\n",
    "    X_2025_flat = X_2025.reshape((X_2025.shape[0], LOOKBACK*n_features))\n",
    "    lin_forecasts = {}\n",
    "    for lname, lmod in lin_models.items():\n",
    "        res = lmod.predict(X_2025_flat).reshape(-1)\n",
    "        dl_lvl = N_2025 * np.exp(res)\n",
    "        alpha = lin_alphas[lname]\n",
    "        blend = alpha * dl_lvl + (1 - alpha) * N_2025\n",
    "        lin_forecasts[lname] = {\"dl\": dl_lvl, \"blend\": blend}\n",
    "        # save per-model file\n",
    "        rows = []\n",
    "        for i, (sec, bm, fy, ye, naive_2024) in enumerate(keys_2025):\n",
    "            rows.append({\n",
    "                \"Sector_12\": sec, \"Base_Ministry\": bm, \"Fiscal_Year\": fy, \"Year_End\": ye,\n",
    "                \"Naive_Lag1_2024\": naive_2024,\n",
    "                f\"{lname}_DL_2025\": float(dl_lvl[i]), f\"{lname}_Blend_2025\": float(blend[i]), \"alpha\": float(alpha)\n",
    "            })\n",
    "        pd.DataFrame(rows).to_csv(FORECASTS_DIR / f\"ministry_{lname}_forecast_2425.csv\", index=False)\n",
    "\n",
    "    # Compact combined output\n",
    "    compact_rows, ctx_rows = [], []\n",
    "    for i, (sec, bm, fy, ye, naive_2024) in enumerate(keys_2025):\n",
    "        row = {\n",
    "            \"Sector_12\": sec, \"Base_Ministry\": bm, \"Fiscal_Year\": fy, \"Year_End\": ye,\n",
    "            \"Naive_Lag1_2024\": float(naive_2024),\n",
    "            \"DL_Ensemble_2025\": float(dl_ens[i]),\n",
    "            \"Linear_Ridge_2025\": float(lin_forecasts[\"Ridge\"][\"blend\"][i]) if \"Ridge\" in lin_forecasts else np.nan,\n",
    "        }\n",
    "        row[\"Growth_vs_2024_%\"] = float((row[\"DL_Ensemble_2025\"] - naive_2024)/naive_2024*100.0) if np.isfinite(naive_2024) and naive_2024 else np.nan\n",
    "        compact_rows.append(row)\n",
    "\n",
    "        ctx = row.copy()\n",
    "        # add DL per-model and alphas\n",
    "        for m in MODEL_SPECS.keys():\n",
    "            ctx[f\"{m}_DL_2025\"] = float(dl_forecasts[m][\"dl\"][i])\n",
    "            ctx[f\"{m}_Blend_2025\"] = float(dl_forecasts[m][\"blend\"][i])\n",
    "            ctx[f\"{m}_alpha\"] = float(dl_alphas[m])\n",
    "        # add linear per-model\n",
    "        for lname in lin_models.keys():\n",
    "            ctx[f\"{lname}_DL_2025\"] = float(lin_forecasts[lname][\"dl\"][i])\n",
    "            ctx[f\"{lname}_Blend_2025\"] = float(lin_forecasts[lname][\"blend\"][i])\n",
    "            ctx[f\"{lname}_alpha\"] = float(lin_alphas[lname])\n",
    "        ctx_rows.append(ctx)\n",
    "\n",
    "    compact_df = pd.DataFrame(compact_rows).sort_values([\"Sector_12\",\"Base_Ministry\"]).reset_index(drop=True)\n",
    "    ctx_df = pd.DataFrame(ctx_rows).sort_values([\"Sector_12\",\"Base_Ministry\"]).reset_index(drop=True)\n",
    "\n",
    "    compact_df.to_csv(OUT_MIN_COMPACT, index=False)\n",
    "    ctx_df.to_csv(OUT_MIN_CONTEXT, index=False)\n",
    "\n",
    "    # Plot growth bars by ministry (top 30 by magnitude)\n",
    "    plot_df = compact_df.copy()\n",
    "    plot_df[\"Growth_vs_2024_%\"] = pd.to_numeric(plot_df[\"Growth_vs_2024_%\"], errors=\"coerce\")\n",
    "    plot_df = plot_df.dropna(subset=[\"Growth_vs_2024_%\"]).sort_values(\"Growth_vs_2024_%\", ascending=False).head(30)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.barplot(data=plot_df, x=\"Growth_vs_2024_%\", y=\"Base_Ministry\", color=\"#59a14f\")\n",
    "    plt.title(\"Ministry: Forecasted Growth vs 2024 (DL Ensemble) — FY2024-25\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / \"ministries_growth_vs_2024.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # Optional: evaluate 2025 if actuals exist in ministry TS\n",
    "    has_2025 = (min_ts[\"Year_End\"] == 2025).any()\n",
    "    if has_2025:\n",
    "        actual_2025 = (min_ts[min_ts[\"Year_End\"]==2025][[\"Sector_12\",\"Base_Ministry\",\"Budget_Amount\"]]\n",
    "                       .groupby([\"Sector_12\",\"Base_Ministry\"], as_index=False).sum())\n",
    "        merged = compact_df.merge(actual_2025, on=[\"Sector_12\",\"Base_Ministry\"], how=\"left\")\n",
    "        merged = merged.rename(columns={\"Budget_Amount\":\"Actual_2025\"})\n",
    "        eval_cols = {\n",
    "            \"DL_Ensemble_2025\": \"DL_Ensemble_2025\",\n",
    "            \"Linear_Ridge_2025\": \"Linear_Ridge_2025\",\n",
    "            \"Naive_Lag1_2024\": \"Naive_Lag1_2024\",\n",
    "        }\n",
    "        rows = []\n",
    "        for name, col in eval_cols.items():\n",
    "            m = merged.dropna(subset=[col,\"Actual_2025\"])\n",
    "            if len(m):\n",
    "                mae, rmse, r2, mape = metrics_all(m[\"Actual_2025\"].values, m[col].values)\n",
    "                rows.append({\"model\": f\"{name}_2025\", \"n_eval\": int(len(m)), \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE_%\": mape})\n",
    "        if rows:\n",
    "            m25 = pd.DataFrame(rows)\n",
    "            m25.to_csv(METRICS_DIR / \"ministry_metrics_2025_if_available.csv\", index=False)\n",
    "            print(\"Saved 2025 ministry metrics (if available):\", METRICS_DIR / \"ministry_metrics_2025_if_available.csv\")\n",
    "\n",
    "print(\"\\nSaved ministry forecasts:\")\n",
    "print(\" -\", OUT_MIN_COMPACT)\n",
    "print(\" -\", OUT_MIN_CONTEXT)\n",
    "print(\" - per-model files:\", FORECASTS_DIR)\n",
    "print(\" - plots:\", PLOTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e37df6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched ministries: 55 / 57\n",
      "Unmatched BE ministries (check naming/mapping):\n",
      "['Commerce (Commerce & Industry; see also DIPP)', 'Drinking Water Supply (within Jal Shakti)']\n",
      "\n",
      "Metrics (FY2024-25 BE):\n",
      "               model  n_eval           MAE          RMSE        R2     MAPE_%\n",
      "0   DL_Ensemble_2025      55  17334.218035  86115.170025  0.255690  17.797000\n",
      "1  Linear_Ridge_2025      55  16825.765001  86053.966996  0.256748   9.343098\n",
      "2    Naive_Lag1_2024      55  16665.533091  86044.164803  0.256917   8.611867\n",
      "\n",
      "Saved:\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/metrics/ministry_metrics_2425_vs_BE.csv\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/ministry_compare_2425_vs_BE.csv\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "# Step 9: Evaluate ministry forecasts against FY2024-25 BE (DL vs Linear vs Naive)\n",
    "import re\n",
    "import difflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "RESULTS_ROOT = ROOT / \"results_Data_2\"\n",
    "FY_DIR = RESULTS_ROOT / \"fy2425\" / \"ministries\"\n",
    "METRICS_DIR = RESULTS_ROOT / \"metrics\"\n",
    "METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IN_FORECAST = FY_DIR / \"ministry_forecast_2425.csv\"\n",
    "OUT_COMPARE = FY_DIR / \"ministry_compare_2425_vs_BE.csv\"\n",
    "OUT_METRICS = METRICS_DIR / \"ministry_metrics_2425_vs_BE.csv\"\n",
    "\n",
    "if not IN_FORECAST.exists():\n",
    "    raise FileNotFoundError(f\"Forecast not found: {IN_FORECAST}. Run Step 8 (Ministry) first.\")\n",
    "\n",
    "# Paste your FY2024-25 BE list below (exactly as in your prompt)\n",
    "BE_TEXT = \"\"\"\n",
    "Ministry/Department,2024-25 BE\n",
    "Agricultural Research and Education,9941.09\n",
    "Animal Husbandry and Dairying,4327.85\n",
    "Atomic Energy,36159.93\n",
    "Chemicals and Petro-Chemicals,(Within Chemicals & Fertilizers) Included in below\n",
    "Fertilisers,145948.45\n",
    "Civil Aviation,3113.36\n",
    "Coal,192.32\n",
    "Mines,1911.6\n",
    "Commerce (Commerce & Industry; see also DIPP),5254.58\n",
    "Industrial Policy and Promotion (now DPIIT),8200.63\n",
    "Posts,25814.0\n",
    "Telecommunications,97579.05\n",
    "Information Technology,16549.04\n",
    "Company Affairs,756.19\n",
    "Consumer Affairs,250.66\n",
    "Food and Public Distribution,205513.94\n",
    "Culture,115531.79\n",
    "Defence (Civil estimates),Part of Defence BE\n",
    "Defence Services,621941\n",
    "Development of North Eastern Region,5892.0\n",
    "Environment and Forests,3079.4\n",
    "External Affairs,18050.0\n",
    "Economic Affairs (centralised provisions),5901.31\n",
    "Food Processing Industries,3287.65\n",
    "Health,90659\n",
    "AYUSH (Ayurveda, Yoga & Naturopathy, Unani, Siddha, and Homoeopathy),3647.5\n",
    "Heavy Industry,6171.63\n",
    "Public Enterprises,33.05\n",
    "Home Affairs,219643\n",
    "Elementary Education and Literacy,68804.85\n",
    "Secondary Education and Higher Education,44094.62\n",
    "Women and Child Development,25448.75\n",
    "Information and Broadcasting,4692.0\n",
    "Labour and Employment,13221.73\n",
    "Law and Justice,3975.43\n",
    "Panchayati Raj,1016.42\n",
    "Parliamentary Affairs,63.0\n",
    "Personnel, Public Grievances and Pensions,71701.0\n",
    "Planning,824.39\n",
    "Power,20671.32\n",
    "Rural Development,190406\n",
    "Land Resources,2419.23\n",
    "Drinking Water Supply (within Jal Shakti),77223.0\n",
    "Science and Technology,7931.05\n",
    "Scientific and Industrial Research,5746.51\n",
    "Biotechnology,2683.86\n",
    "Shipping,2218.74\n",
    "Road Transport and Highways,278000\n",
    "Small Scale Industries,(within MSME)\n",
    "Social Justice and Empowerment,20671.32\n",
    "Space,12543.91\n",
    "Statistics and Programme Implementation,5443.4\n",
    "Steel,70.15\n",
    "Textiles,4389.34\n",
    "Tourism,2400.0\n",
    "Tribal Affairs,12461.88\n",
    "Urban Development,76431.6\n",
    "Water Resources,20054.67\n",
    "Youth Affairs and Sports,3397.32\n",
    "Agriculture and Cooperation,(Combined above)\n",
    "Andaman & Nicobar Islands,192.32\n",
    "\"\"\".strip()\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    s = str(s).lower().strip()\n",
    "    s = s.replace(\"&\", \" and \")\n",
    "    # unify spaces and drop punctuation except spaces and alnum\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    # optional: drop helper phrases that cause mismatch\n",
    "    s = s.replace(\" now dpiit\", \"\").replace(\" within msme\", \"\")\n",
    "    s = s.replace(\" within chemicals and fertilizers included in below\", \"\")\n",
    "    s = s.replace(\" part of defence be\", \"\").replace(\" combined above\", \"\")\n",
    "    return s\n",
    "\n",
    "def parse_be_text(txt: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for i, line in enumerate(txt.splitlines()):\n",
    "        line = line.strip()\n",
    "        if not line or i == 0:  # skip header\n",
    "            continue\n",
    "        if \",\" not in line:\n",
    "            continue\n",
    "        # split on last comma (names may contain commas in parentheses)\n",
    "        name, val = line.rsplit(\",\", 1)\n",
    "        name = name.strip()\n",
    "        val = val.strip()\n",
    "        # try numeric; skip non-numeric (notes like \"Part of Defence BE\")\n",
    "        try:\n",
    "            amt = float(val)\n",
    "        except Exception:\n",
    "            continue\n",
    "        rows.append({\"Base_Ministry_raw\": name, \"Actual_2025_BE\": amt})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not len(df):\n",
    "        raise RuntimeError(\"No numeric BE rows parsed. Check BE_TEXT format.\")\n",
    "    df[\"bm_norm\"] = df[\"Base_Ministry_raw\"].map(norm_name)\n",
    "    return df\n",
    "\n",
    "be_df = parse_be_text(BE_TEXT)\n",
    "\n",
    "# Load forecast\n",
    "fc = pd.read_csv(IN_FORECAST)\n",
    "# Keep unique ministry rows\n",
    "keep_cols = [\"Sector_12\",\"Base_Ministry\",\"Fiscal_Year\",\"Year_End\",\"Naive_Lag1_2024\",\"DL_Ensemble_2025\",\"Linear_Ridge_2025\"]\n",
    "present = [c for c in keep_cols if c in fc.columns]\n",
    "fc = fc[present].copy()\n",
    "fc[\"bm_norm\"] = fc[\"Base_Ministry\"].map(norm_name)\n",
    "\n",
    "# Fuzzy match BE -> forecast ministries\n",
    "fc_names = fc[\"bm_norm\"].dropna().unique().tolist()\n",
    "\n",
    "def best_match(name: str, choices: list[str], cutoff=0.80):\n",
    "    if name in choices:\n",
    "        return name, 1.0\n",
    "    match = difflib.get_close_matches(name, choices, n=1, cutoff=cutoff)\n",
    "    if match:\n",
    "        # compute score explicitly\n",
    "        score = difflib.SequenceMatcher(None, name, match[0]).ratio()\n",
    "        return match[0], score\n",
    "    return None, 0.0\n",
    "\n",
    "match_rows = []\n",
    "for _, r in be_df.iterrows():\n",
    "    m, score = best_match(r[\"bm_norm\"], fc_names, cutoff=0.78)\n",
    "    match_rows.append({\n",
    "        \"Base_Ministry_raw\": r[\"Base_Ministry_raw\"],\n",
    "        \"bm_norm\": r[\"bm_norm\"],\n",
    "        \"match_norm\": m,\n",
    "        \"match_score\": score,\n",
    "        \"Actual_2025_BE\": r[\"Actual_2025_BE\"],\n",
    "    })\n",
    "match_df = pd.DataFrame(match_rows)\n",
    "matched = match_df.dropna(subset=[\"match_norm\"]).copy()\n",
    "\n",
    "# Merge with forecast on matched normalized name\n",
    "fc_idx = fc.drop_duplicates(subset=[\"bm_norm\"]).set_index(\"bm_norm\")\n",
    "matched[\"bm_norm_fc\"] = matched[\"match_norm\"]\n",
    "merged = matched.join(fc_idx, on=\"bm_norm_fc\", how=\"left\", rsuffix=\"_fc\")\n",
    "\n",
    "# Drop rows without forecasts\n",
    "merged = merged.dropna(subset=[\"DL_Ensemble_2025\", \"Linear_Ridge_2025\", \"Naive_Lag1_2024\"])\n",
    "\n",
    "def metrics_all(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if not np.any(mask):\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    yt, yp = y_true[mask], y_pred[mask]\n",
    "    mae = float(np.mean(np.abs(yt - yp)))\n",
    "    rmse = float(np.sqrt(np.mean((yt - yp) ** 2)))\n",
    "    denom = np.sum((yt - yt.mean()) ** 2)\n",
    "    r2 = float(1.0 - (np.sum((yt - yp) ** 2) / denom)) if denom > 0 else np.nan\n",
    "    mape = float(np.mean(np.abs((yt - yp) / yt)) * 100.0) if np.all(yt != 0) else np.nan\n",
    "    return mae, rmse, r2, mape\n",
    "\n",
    "Y = merged[\"Actual_2025_BE\"].values\n",
    "models = {\n",
    "    \"DL_Ensemble_2025\": merged[\"DL_Ensemble_2025\"].values,\n",
    "    \"Linear_Ridge_2025\": merged[\"Linear_Ridge_2025\"].values,\n",
    "    \"Naive_Lag1_2024\": merged[\"Naive_Lag1_2024\"].values,\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, pred in models.items():\n",
    "    mae, rmse, r2, mape = metrics_all(Y, pred)\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"n_eval\": int(len(Y)),\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2,\n",
    "        \"MAPE_%\": mape\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(rows, columns=[\"model\",\"n_eval\",\"MAE\",\"RMSE\",\"R2\",\"MAPE_%\"])\n",
    "metrics_df.to_csv(OUT_METRICS, index=False)\n",
    "\n",
    "# Save detailed comparison per ministry\n",
    "out_cols = [\n",
    "    \"Base_Ministry_raw\",\"Base_Ministry\",\"Sector_12\",\n",
    "    \"Actual_2025_BE\",\"Naive_Lag1_2024\",\"DL_Ensemble_2025\",\"Linear_Ridge_2025\",\n",
    "    \"bm_norm\",\"match_norm\",\"match_score\",\"Fiscal_Year\",\"Year_End\"\n",
    "]\n",
    "present_cols = [c for c in out_cols if c in merged.columns]\n",
    "merged[present_cols].sort_values(\"Base_Ministry_raw\").to_csv(OUT_COMPARE, index=False)\n",
    "\n",
    "print(f\"Matched ministries: {merged['Base_Ministry_raw'].nunique()} / {be_df['Base_Ministry_raw'].nunique()}\")\n",
    "unmatched = match_df[match_df[\"match_norm\"].isna()]\n",
    "if len(unmatched):\n",
    "    print(\"Unmatched BE ministries (check naming/mapping):\")\n",
    "    print(unmatched[\"Base_Ministry_raw\"].tolist())\n",
    "\n",
    "print(\"\\nMetrics (FY2024-25 BE):\")\n",
    "print(metrics_df)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" -\", OUT_METRICS)\n",
    "print(\" -\", OUT_COMPARE)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c054968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/wzy1hvwd7bd4plh9mwvg9yyc0000gn/T/ipykernel_5688/1138262519.py:60: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(data=df, x=\"model\", y=metric, palette=palette)\n",
      "/var/folders/ty/wzy1hvwd7bd4plh9mwvg9yyc0000gn/T/ipykernel_5688/1138262519.py:60: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(data=df, x=\"model\", y=metric, palette=palette)\n",
      "/var/folders/ty/wzy1hvwd7bd4plh9mwvg9yyc0000gn/T/ipykernel_5688/1138262519.py:60: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(data=df, x=\"model\", y=metric, palette=palette)\n",
      "/var/folders/ty/wzy1hvwd7bd4plh9mwvg9yyc0000gn/T/ipykernel_5688/1138262519.py:60: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(data=df, x=\"model\", y=metric, palette=palette)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ministry BE comparison visuals to: /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/plots\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/plots/ministry_metrics_2425_BE_MAE.png\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/plots/ministry_metrics_2425_BE_RMSE.png\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/plots/ministry_metrics_2425_BE_R2.png\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/plots/ministry_metrics_2425_BE_MAPE.png\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/plots/ministry_top20_abs_error_DL_Ensemble.png\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/plots/ministry_top20_abs_error_Linear_Ridge.png\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/plots/ministry_actual_vs_pred_scatter_2425.png\n",
      " - /Users/vvmohith/Desktop/PROJECT/final_data/data_2/results_Data_2/fy2425/ministries/plots/ministry_pct_error_distribution_2425.png\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "# Step 10: Visuals — Ministry FY2024-25 (BE) comparison: DL vs Linear vs Naive\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "BASE = Path(\"/Users/vvmohith/Desktop/PROJECT/final_data\")\n",
    "ROOT = BASE / \"data_2\"\n",
    "RESULTS_ROOT = ROOT / \"results_Data_2\"\n",
    "FY_DIR = RESULTS_ROOT / \"fy2425\" / \"ministries\"\n",
    "PLOTS_DIR = FY_DIR / \"plots\"\n",
    "METRICS_DIR = RESULTS_ROOT / \"metrics\"\n",
    "\n",
    "COMPARE_CSV = FY_DIR / \"ministry_compare_2425_vs_BE.csv\"\n",
    "METRICS_CSV = METRICS_DIR / \"ministry_metrics_2425_vs_BE.csv\"\n",
    "\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not COMPARE_CSV.exists() or not METRICS_CSV.exists():\n",
    "    raise FileNotFoundError(\"Missing inputs. Run Step 8 (Ministry) and Step 9 first.\")\n",
    "\n",
    "cmp = pd.read_csv(COMPARE_CSV)\n",
    "metrics_df = pd.read_csv(METRICS_CSV)\n",
    "\n",
    "# Clean and compute errors\n",
    "need = [\"Base_Ministry_raw\",\"Actual_2025_BE\",\"DL_Ensemble_2025\",\"Linear_Ridge_2025\",\"Naive_Lag1_2024\"]\n",
    "cmp = cmp[[c for c in need if c in cmp.columns]].dropna()\n",
    "\n",
    "cmp[\"AE_DL\"]      = (cmp[\"DL_Ensemble_2025\"] - cmp[\"Actual_2025_BE\"]).abs()\n",
    "cmp[\"AE_Linear\"]  = (cmp[\"Linear_Ridge_2025\"] - cmp[\"Actual_2025_BE\"]).abs()\n",
    "cmp[\"AE_Naive\"]   = (cmp[\"Naive_Lag1_2024\"] - cmp[\"Actual_2025_BE\"]).abs()\n",
    "\n",
    "cmp[\"PE_DL_%\"]     = (cmp[\"DL_Ensemble_2025\"] - cmp[\"Actual_2025_BE\"]) / cmp[\"Actual_2025_BE\"] * 100.0\n",
    "cmp[\"PE_Linear_%\"] = (cmp[\"Linear_Ridge_2025\"] - cmp[\"Actual_2025_BE\"]) / cmp[\"Actual_2025_BE\"] * 100.0\n",
    "cmp[\"PE_Naive_%\"]  = (cmp[\"Naive_Lag1_2024\"] - cmp[\"Actual_2025_BE\"]) / cmp[\"Actual_2025_BE\"] * 100.0\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fmt_comma0 = FuncFormatter(lambda x, p: f\"{x:,.0f}\")\n",
    "\n",
    "# 1) Metrics bars (MAE/RMSE/R2/MAPE)\n",
    "def metric_bar(metric, higher_is_better=False, fname=\"bar.png\"):\n",
    "    df = metrics_df.copy()\n",
    "    # Order models consistently: DL, Linear, Naive\n",
    "    order = [\"DL_Ensemble_2025\",\"Linear_Ridge_2025\",\"Naive_Lag1_2024\"]\n",
    "    df[\"model\"] = pd.Categorical(df[\"model\"], categories=order, ordered=True)\n",
    "    df = df.dropna(subset=[metric]).sort_values(\n",
    "        metric, ascending=(not higher_is_better)\n",
    "    )\n",
    "    palette = df[\"model\"].map({\n",
    "        \"DL_Ensemble_2025\": \"#59a14f\",\n",
    "        \"Linear_Ridge_2025\": \"#4c78a8\",\n",
    "        \"Naive_Lag1_2024\": \"#9c9c9c\",\n",
    "    }).tolist()\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = sns.barplot(data=df, x=\"model\", y=metric, palette=palette)\n",
    "    if metric in [\"MAE\",\"RMSE\"]:\n",
    "        ax.yaxis.set_major_formatter(fmt_comma0)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.title(f\"Ministry FY2024-25 (BE) — {metric}\")\n",
    "    for i, v in enumerate(df[metric].values):\n",
    "        ax.text(i, v, f\"{v:,.0f}\" if metric in [\"MAE\",\"RMSE\"] else f\"{v:.3f}\",\n",
    "                ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / fname, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "metric_bar(\"MAE\",  higher_is_better=False, fname=\"ministry_metrics_2425_BE_MAE.png\")\n",
    "metric_bar(\"RMSE\", higher_is_better=False, fname=\"ministry_metrics_2425_BE_RMSE.png\")\n",
    "metric_bar(\"R2\",   higher_is_better=True,  fname=\"ministry_metrics_2425_BE_R2.png\")\n",
    "metric_bar(\"MAPE_%\", higher_is_better=False, fname=\"ministry_metrics_2425_BE_MAPE.png\")\n",
    "\n",
    "# 2) Top-20 absolute errors by ministry (DL and Linear)\n",
    "def topN_abs_error(df, col_err, label_pred, fname):\n",
    "    top = df.nlargest(20, col_err).copy()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = sns.barplot(data=top, x=col_err, y=\"Base_Ministry_raw\", color=\"#737373\")\n",
    "    ax.xaxis.set_major_formatter(fmt_comma0)\n",
    "    plt.xlabel(\"Absolute Error\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.title(f\"Top-20 Absolute Errors vs BE — {label_pred}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / fname, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "topN_abs_error(cmp, \"AE_DL\",     \"DL Ensemble\",   \"ministry_top20_abs_error_DL_Ensemble.png\")\n",
    "topN_abs_error(cmp, \"AE_Linear\", \"Linear Ridge\",  \"ministry_top20_abs_error_Linear_Ridge.png\")\n",
    "\n",
    "# 3) Scatter: Actual vs Pred (DL, Linear, Naive)\n",
    "def scatter_with_diag(df, pred_col, title, ax):\n",
    "    x = df[\"Actual_2025_BE\"].values\n",
    "    y = df[pred_col].values\n",
    "    # Metrics inline\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    if mask.sum():\n",
    "        mae = np.mean(np.abs(x[mask]-y[mask]))\n",
    "        ss_res = np.sum((x[mask]-y[mask])**2)\n",
    "        ss_tot = np.sum((x[mask]-x[mask].mean())**2)\n",
    "        r2 = 1 - ss_res/ss_tot if ss_tot>0 else np.nan\n",
    "    else:\n",
    "        mae, r2 = np.nan, np.nan\n",
    "    ax.scatter(x, y, alpha=0.6, s=28)\n",
    "    lim = [0, max(x.max(), y.max())*1.05]\n",
    "    ax.plot(lim, lim, \"k--\", lw=1)\n",
    "    ax.set_xlim(lim); ax.set_ylim(lim)\n",
    "    ax.xaxis.set_major_formatter(fmt_comma0)\n",
    "    ax.yaxis.set_major_formatter(fmt_comma0)\n",
    "    ax.set_title(f\"{title}\\nMAE={mae:,.0f}  R2={r2:.3f}\")\n",
    "    ax.set_xlabel(\"Actual 2024-25 BE\")\n",
    "    ax.set_ylabel(\"Predicted\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "scatter_with_diag(cmp, \"DL_Ensemble_2025\", \"DL Ensemble\", axes[0])\n",
    "scatter_with_diag(cmp, \"Linear_Ridge_2025\",\"Linear Ridge\", axes[1])\n",
    "scatter_with_diag(cmp, \"Naive_Lag1_2024\",  \"Naive (FY24)\", axes[2])\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / \"ministry_actual_vs_pred_scatter_2425.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# 4) Percentage error distribution (KDE/Hist)\n",
    "pe_long = pd.DataFrame({\n",
    "    \"DL Ensemble\": cmp[\"PE_DL_%\"],\n",
    "    \"Linear Ridge\": cmp[\"PE_Linear_%\"],\n",
    "    \"Naive (FY24)\": cmp[\"PE_Naive_%\"],\n",
    "}).melt(var_name=\"Model\", value_name=\"Pct_Error_%\").dropna()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data=pe_long, x=\"Pct_Error_%\", hue=\"Model\", kde=True, element=\"step\", stat=\"density\", common_norm=False)\n",
    "plt.axvline(0, color=\"k\", lw=1, ls=\"--\")\n",
    "plt.title(\"Percentage Error Distribution vs BE (Ministries, FY2024-25)\")\n",
    "plt.xlabel(\"Percentage Error (%)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / \"ministry_pct_error_distribution_2425.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved ministry BE comparison visuals to:\", PLOTS_DIR)\n",
    "for f in [\n",
    "    \"ministry_metrics_2425_BE_MAE.png\",\n",
    "    \"ministry_metrics_2425_BE_RMSE.png\",\n",
    "    \"ministry_metrics_2425_BE_R2.png\",\n",
    "    \"ministry_metrics_2425_BE_MAPE.png\",\n",
    "    \"ministry_top20_abs_error_DL_Ensemble.png\",\n",
    "    \"ministry_top20_abs_error_Linear_Ridge.png\",\n",
    "    \"ministry_actual_vs_pred_scatter_2425.png\",\n",
    "    \"ministry_pct_error_distribution_2425.png\",\n",
    "]:\n",
    "    print(\" -\", PLOTS_DIR / f)\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
