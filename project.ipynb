{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Ministry_05_06  \\\n",
      "94                                        grand total   \n",
      "43                                    law and justice   \n",
      "50          personnel, public grievances and pensions   \n",
      "32  ayurveda, yoga & naturopathy, unani, siddha an...   \n",
      "23                development of north eastern region   \n",
      "..                                                ...   \n",
      "78                                        state plans   \n",
      "27          economic affairs (centralised provisions)   \n",
      "81                                              doner   \n",
      "88              union territories without legislature   \n",
      "1                                                       \n",
      "\n",
      "                               Matched_Ministry_20_21  Match_Score  \n",
      "94                                        grand total          100  \n",
      "43                                64. law and justice           95  \n",
      "50  73. ministry of personnel, public grievances a...           95  \n",
      "32  4. ministry of ayurveda, yoga and naturopathy,...           95  \n",
      "23  22. ministry of development of north eastern r...           95  \n",
      "..                                                ...          ...  \n",
      "78                            38. transfers to states           64  \n",
      "27                 27. department of economic affairs           62  \n",
      "81                                   3. atomic energy           54  \n",
      "88  93. department of empowerment of persons with ...           41  \n",
      "1   1. department of agriculture, cooperation and ...            0  \n",
      "\n",
      "[95 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load datasets\n",
    "df1 = pd.read_csv(\"/Users/vvmohith/Desktop/PROJECT/dataset/05-06/05-06.csv\", delimiter=\";\", usecols=[0], encoding=\"utf-8\")\n",
    "df2 = pd.read_csv(\"/Users/vvmohith/Desktop/PROJECT/dataset/20-21/2020-2021.csv\", delimiter=\",\", skiprows=7, usecols=[0], encoding=\"utf-8\")\n",
    "\n",
    "# Rename columns\n",
    "df1.columns = [\"Ministry\"]\n",
    "df2.columns = [\"Ministry\"]\n",
    "\n",
    "# Convert to lowercase and strip spaces\n",
    "df1[\"Ministry\"] = df1[\"Ministry\"].str.lower().str.strip()\n",
    "df2[\"Ministry\"] = df2[\"Ministry\"].str.lower().str.strip()\n",
    "\n",
    "# Remove specific words from 05-06 dataset\n",
    "df1[\"Ministry\"] = df1[\"Ministry\"].str.replace(r\"\\b(revenue|capital)\\b\", \"\", regex=True).str.strip()\n",
    "\n",
    "# Remove specific rows from 2020-2021 dataset\n",
    "exclude_phrases = [\n",
    "    \"central sector schemes/projects\",\n",
    "    \"establishment expenditure of the centre\",\n",
    "    \"other central sector expenditure\"\n",
    "]\n",
    "df2 = df2[~df2[\"Ministry\"].isin(exclude_phrases)]\n",
    "\n",
    "# Drop NaN values\n",
    "df1.dropna(inplace=True)\n",
    "df2.dropna(inplace=True)\n",
    "\n",
    "# Create lists of ministries\n",
    "ministries_05_06 = df1[\"Ministry\"].unique().tolist()\n",
    "ministries_20_21 = df2[\"Ministry\"].unique().tolist()\n",
    "\n",
    "# Fuzzy match all ministries\n",
    "matches = []\n",
    "for ministry in ministries_05_06:\n",
    "    best_match, score = process.extractOne(ministry, ministries_20_21)\n",
    "    matches.append((ministry, best_match, score))\n",
    "\n",
    "# Convert to DataFrame\n",
    "matched_df = pd.DataFrame(matches, columns=[\"Ministry_05_06\", \"Matched_Ministry_20_21\", \"Match_Score\"])\n",
    "\n",
    "# Sort by match score\n",
    "matched_df = matched_df.sort_values(by=\"Match_Score\", ascending=False)\n",
    "\n",
    "# Save output to a CSV file\n",
    "matched_df.to_csv(\"/Users/vvmohith/Desktop/PROJECT/matched_ministries.csv\", index=False)\n",
    "\n",
    "# Display all matches\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved at: /Users/vvmohith/Desktop/PROJECT/dataset/cleaned_budget_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to datasets\n",
    "budget_data_folder = \"/Users/vvmohith/Desktop/PROJECT/dataset/\"  # Update with actual path\n",
    "match_file = \"/Users/vvmohith/Desktop/PROJECT/matched_ministries.csv\"  # Matched ministries file\n",
    "\n",
    "# Load matched ministries\n",
    "df_match = pd.read_csv(match_file)\n",
    "common_ministries = df_match[[\"Ministry_05_06\", \"Matched_Ministry_20_21\"]]\n",
    "\n",
    "# Initialize final dataframe\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Define the range of years\n",
    "years_available = list(range(2005, 2022))\n",
    "\n",
    "# Loop through available years and process the data\n",
    "for year in years_available:\n",
    "    folder_name = f\"{str(year)[-2:]}-{str(year+1)[-2:]}\"  # Folder names like \"05-06\"\n",
    "    file_path = os.path.join(budget_data_folder, f\"{folder_name}.csv\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter=\",\")\n",
    "        except pd.errors.ParserError:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, delimiter=\";\")\n",
    "            except pd.errors.ParserError:\n",
    "                print(f\"Skipping file due to parsing error: {file_path}\")\n",
    "                continue\n",
    "        \n",
    "        df.columns = [col.lower().strip() for col in df.columns]\n",
    "        \n",
    "        # Find column containing \"Total\" allocation\n",
    "        total_col = next((col for col in df.columns if \"total\" in col), None)\n",
    "        if total_col:\n",
    "            df = df[[\"ministry\", total_col]]\n",
    "            df.rename(columns={\"ministry\": \"Ministry\", total_col: f\"Total_{year}-{year+1}\"}, inplace=True)\n",
    "            \n",
    "            # Match ministries and merge\n",
    "            df = df.merge(common_ministries, left_on=\"Ministry\", right_on=\"Ministry_05_06\", how=\"inner\")\n",
    "            df.drop(columns=[\"Ministry_05_06\"], inplace=True)\n",
    "            df.rename(columns={\"Matched_Ministry_20_21\": \"Ministry\"}, inplace=True)\n",
    "            \n",
    "            if final_df.empty:\n",
    "                final_df = df\n",
    "            else:\n",
    "                final_df = pd.merge(final_df, df, on=\"Ministry\", how=\"outer\")\n",
    "\n",
    "# Save the final cleaned dataset\n",
    "final_csv_path = os.path.join(budget_data_folder, \"cleaned_budget_data.csv\")\n",
    "final_df.to_csv(final_csv_path, index=False)\n",
    "\n",
    "print(f\"Processed dataset saved at: {final_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing file: ./dataset/23-24/23-24.csv\n",
      "âœ… Filtered data saved to ./filtered/filtered_23-24.csv\n",
      "ðŸ“‚ Processing file: ./dataset/22-23/22-23.csv\n",
      "âœ… Filtered data saved to ./filtered/filtered_22-23.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define dataset folder and output folder\n",
    "dataset_folder = \"./dataset/\"\n",
    "output_folder = \"./filtered/\"\n",
    "\n",
    "# List of years to process\n",
    "years = [\"23-24\", \"22-23\"]  # Add other years if needed\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to check if a row should be kept\n",
    "def is_valid_row(value):\n",
    "    return str(value).strip().startswith(tuple(\"0123456789\")) or str(value).strip().lower() == \"grand total\"\n",
    "\n",
    "# Loop through years\n",
    "for year in years:\n",
    "    input_path = os.path.join(dataset_folder, year, f\"{year}.csv\")\n",
    "    output_path = os.path.join(output_folder, f\"filtered_{year}.csv\")\n",
    "\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"âŒ File not found: {input_path}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"ðŸ“‚ Processing file: {input_path}\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(input_path, delimiter=\";\", encoding=\"utf-8\")\n",
    "\n",
    "    # Keep only rows that start with a number OR are \"Grand Total\"\n",
    "    df_filtered = df[df.iloc[:, 0].apply(is_valid_row)]\n",
    "\n",
    "    # Save filtered data\n",
    "    df_filtered.to_csv(output_path, index=False, sep=\";\")\n",
    "\n",
    "    print(f\"âœ… Filtered data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/05-06/05-06.csv\n",
      "ðŸ“Œ Available Columns: ['agricultural research and education', '748.98', '687.71', '1436.69', '900.00', '775.00', '1675.00', '1150.00', '792.00', '1942.00', 'unnamed: 10']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/05-06/05-06.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/06-07/06-07.csv\n",
      "ðŸ“Œ Available Columns: ['agricultural research and education', '816.01', '773.48', '1589.49', '1070.00', '830.00', '1900.00', '1350.00', '810.00', '2160.00']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/06-07/06-07.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/07-08/07-08.csv\n",
      "ðŸ“Œ Available Columns: ['agricultural research and education', '1046.75', '829.65', '1876.40', '1430.00', '846.00', '2276.00', '1620.00', '840.00', '2460.00', 'unnamed: 10']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/07-08/07-08.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/09-10/09-10.csv\n",
      "ðŸ“Œ Available Columns: ['agricultural research and education', '1280.34', '901.65', '2181.99', '1760.00', '1200.00', '2960.00', '1760.00.1', '1481.40', '3241.40']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/09-10/09-10.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/10-11/10-11.csv\n",
      "ðŸ“Œ Available Columns: ['capital', '70.20', '0.41', '70.61', '70.45', '0.65', '71.10', '83.25', '0.60', '83.85']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/10-11/10-11.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/12-13/12-13.csv\n",
      "ðŸ“Œ Available Columns: ['unnamed: 0', 'actuals 2010-2011', 'unnamed: 3', 'unnamed: 4', 'budget 2011-2012', 'unnamed: 6', 'unnamed: 7', 'revised 2011-2012', 'unnamed: 9', 'unnamed: 10', 'budget 2012-2013', 'unnamed: 12', 'unnamed: 13']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/12-13/12-13.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/13-14/13-14.csv\n",
      "ðŸ“Œ Available Columns: ['unnamed: 0', 'actuals 2011-2012', 'unnamed: 3', 'unnamed: 4', 'budget 2012-2013', 'unnamed: 6', 'unnamed: 7', 'revised 2012-2013', 'unnamed: 9', 'unnamed: 10', 'budget 2013-2014', 'unnamed: 12', 'unnamed: 13']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/13-14/13-14.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/15-16/15-16.csv\n",
      "ðŸ“Œ Available Columns: ['unnamed: 0', 'actuals\\xa02013-2014', 'unnamed: 3', 'unnamed: 4', 'budget\\xa02014-2015', 'unnamed: 6', 'unnamed: 7', 'revised\\xa02014-2015', 'unnamed: 9', 'unnamed: 10', 'budget\\xa02015-2016', 'unnamed: 12', 'unnamed: 13']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/15-16/15-16.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/16-17/16-17.csv\n",
      "ðŸ“Œ Available Columns: ['unnamed: 0', 'actuals\\xa02014-2015', 'unnamed: 3', 'unnamed: 4', 'budget\\xa02015-2016', 'unnamed: 6', 'unnamed: 7', 'revised\\xa02015-2016', 'unnamed: 9', 'unnamed: 10', 'budget\\xa02016-2017', 'unnamed: 12', 'unnamed: 13']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/16-17/16-17.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/18-19/18-19.csv\n",
      "ðŸ“Œ Available Columns: ['ministry/department', 'revenue', 'capital', 'total', 'revenue .1', 'capital .1', 'total .1', 'revenue .2', 'capital .2', 'total .2', 'revenue .3', 'capital .3', 'total .3']\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/19-20/19-20.csv\n",
      "ðŸ“Œ Available Columns: ['unnamed: 0', 'unnamed: 1', 'unnamed: 2', 'actuals2017-2018', 'unnamed: 4', 'unnamed: 5', 'budget estimates2018-2019', 'unnamed: 7', 'unnamed: 8', 'revised estimates2018-2019', 'unnamed: 10', 'unnamed: 11', 'budget estimates2019-2020', 'unnamed: 13', 'unnamed: 14']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/19-20/19-20.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/20-21/20-21.csv\n",
      "ðŸ“Œ Available Columns: ['unnamed: 0', 'unnamed: 1', 'unnamed: 2', 'unnamed: 3', 'unnamed: 4', 'unnamed: 5', 'unnamed: 6', 'unnamed: 7', 'unnamed: 8', 'unnamed: 9', 'unnamed: 10', 'unnamed: 11', 'unnamed: 12']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/20-21/20-21.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/21-22/21-22.csv\n",
      "ðŸ“Œ Available Columns: ['3.    atomic energy', '8389.12', '9875.77', '18264.89', '9-14']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/21-22/21-22.csv. Skipping...\n",
      "\n",
      "ðŸ”¹ Processing file: /Users/vvmohith/Desktop/PROJECT/dataset/23-24/23-24.csv\n",
      "ðŸ“Œ Available Columns: ['department of atomic energy', '9096.99', '15981.50', '25078.49', 'unnamed: 4']\n",
      "âš ï¸ No valid 'Total' or 'Ministry' column found in /Users/vvmohith/Desktop/PROJECT/dataset/23-24/23-24.csv. Skipping...\n",
      "\n",
      "âœ… Processed dataset saved at: /Users/vvmohith/Desktop/PROJECT/dataset/cleaned_budget_data.csv\n",
      "ðŸ“Š Final DataFrame shape: (55, 3)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Path to datasets\n",
    "# budget_data_folder = \"/Users/vvmohith/Desktop/PROJECT/dataset/\"  # Update with actual path\n",
    "# match_file = \"/Users/vvmohith/Desktop/PROJECT/matched_ministries.csv\"  # Matched ministries file\n",
    "\n",
    "# # Load matched ministries\n",
    "# df_match = pd.read_csv(match_file)\n",
    "# common_ministries = df_match[[\"Ministry_05_06\", \"Matched_Ministry_20_21\"]]\n",
    "\n",
    "# # Initialize final dataframe\n",
    "# final_df = pd.DataFrame()\n",
    "\n",
    "# # Get available years from folder names\n",
    "# year_folders = [f for f in os.listdir(budget_data_folder) if os.path.isdir(os.path.join(budget_data_folder, f))]\n",
    "# years_available = [int(folder.split(\"-\")[0]) + 2000 for folder in year_folders if folder[:2].isdigit()]\n",
    "\n",
    "# # Process each available year\n",
    "# for year in sorted(years_available):\n",
    "#     folder_name = f\"{str(year)[-2:]}-{str(year+1)[-2:]}\"\n",
    "#     file_path = os.path.join(budget_data_folder, folder_name, f\"{folder_name}.csv\")\n",
    "\n",
    "#     if os.path.exists(file_path):\n",
    "#         print(f\"\\nðŸ”¹ Processing file: {file_path}\")\n",
    "\n",
    "#         # Try different delimiters\n",
    "#         try:\n",
    "#             df = pd.read_csv(file_path, sep=\",\", engine=\"python\", skiprows=5)  # Skip first 5 rows if needed\n",
    "#         except pd.errors.ParserError:\n",
    "#             try:\n",
    "#                 df = pd.read_csv(file_path, sep=\";\", engine=\"python\", skiprows=5)\n",
    "#             except pd.errors.ParserError:\n",
    "#                 print(f\"âš ï¸ Skipping file due to parsing error: {file_path}\")\n",
    "#                 continue\n",
    "\n",
    "#         # Drop empty columns\n",
    "#         df.dropna(axis=1, how=\"all\", inplace=True)\n",
    "        \n",
    "#         # Detect column names dynamically\n",
    "#         df.columns = [str(col).lower().strip() for col in df.columns]\n",
    "#         print(f\"ðŸ“Œ Available Columns: {df.columns.tolist()}\")\n",
    "\n",
    "#         # Find \"Total\" and \"Ministry\" columns\n",
    "#         ministry_col = next((col for col in df.columns if \"ministry\" in col or \"department\" in col), None)\n",
    "#         total_col = next((col for col in df.columns if \"total\" in col), None)\n",
    "\n",
    "#         if not ministry_col or not total_col:\n",
    "#             print(f\"âš ï¸ No valid 'Total' or 'Ministry' column found in {file_path}. Skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         # Keep only Ministry and relevant \"Total\" column\n",
    "#         df = df[[ministry_col, total_col]]\n",
    "#         df.rename(columns={ministry_col: \"Ministry\", total_col: f\"Total_{year}-{year+1}\"}, inplace=True)\n",
    "\n",
    "#         # Match ministries and merge\n",
    "#         df = df.merge(common_ministries, left_on=\"Ministry\", right_on=\"Ministry_05_06\", how=\"inner\")\n",
    "#         df.drop(columns=[\"Ministry_05_06\"], inplace=True)\n",
    "#         df.rename(columns={\"Matched_Ministry_20_21\": \"Ministry\"}, inplace=True)\n",
    "\n",
    "#         if final_df.empty:\n",
    "#             final_df = df\n",
    "#         else:\n",
    "#             final_df = pd.merge(final_df, df, on=\"Ministry\", how=\"outer\")\n",
    "\n",
    "# # Save the final cleaned dataset\n",
    "# final_csv_path = os.path.join(budget_data_folder, \"cleaned_budget_data.csv\")\n",
    "# final_df.to_csv(final_csv_path, index=False)\n",
    "\n",
    "# print(f\"\\nâœ… Processed dataset saved at: {final_csv_path}\")\n",
    "# print(f\"ðŸ“Š Final DataFrame shape: {final_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 05-06 with 94 ministries\n",
      "Loaded 06-07 with 96 ministries\n",
      "Loaded 07-08 with 123 ministries\n",
      "Loaded 09-10 with 101 ministries\n",
      "Loaded 10-11 with 101 ministries\n",
      "Loaded 12-13 with 101 ministries\n",
      "Loaded 13-14 with 102 ministries\n",
      "Loaded 15-16 with 131 ministries\n",
      "Loaded 16-17 with 127 ministries\n",
      "Loaded 19-20 with 102 ministries\n",
      "Loaded 20-21 with 104 ministries\n",
      "Loaded 21-22 with 102 ministries\n",
      "Loaded 22-23 with 96 ministries\n",
      "Loaded 23-24 with 92 ministries\n",
      "\n",
      "Merged data saved to: /Users/vvmohith/Desktop/PROJECT/dataset-final/merged_budget_data.csv\n",
      "Final shape: (914, 15)\n",
      "\n",
      "Sample of merged data:\n",
      "                                            Ministry  Total_05-06  \\\n",
      "0  Department of Agriculture Cooperation and Farm...         0.00   \n",
      "1  Department of Agriculture Cooperation and Farm...         0.00   \n",
      "2  Department of Agricultural Research and Education      1942.00   \n",
      "3                                      Atomic Energy      4995.86   \n",
      "4  Ministry of Ayurveda Yoga and Naturopathy Unan...       405.98   \n",
      "\n",
      "   Total_06-07 Total_07-08  Total_09-10  Total_10-11  Total_12-13  \\\n",
      "0         0.00           0          0.0         0.00          0.0   \n",
      "1         0.00           0          0.0         0.00          0.0   \n",
      "2      2160.00     2460.00       3241.4      3818.05       5392.0   \n",
      "3      5505.08     6130.00       7773.0      8521.00       9232.0   \n",
      "4       447.89      563.88        922.0       964.00       1178.0   \n",
      "\n",
      "   Total_13-14 Total_15-16 Total_16-17 Total_19-20 Total_20-21 Total_21-22  \\\n",
      "0         0.00           0    23228.83   129585.21   134399.77   123017.57   \n",
      "1         0.00           0    12739.96   129585.21   134399.77   123017.57   \n",
      "2      5729.17     6320.00     6620.00     8078.76     8362.58     8513.62   \n",
      "3      9833.32    10912.00    11682.48    16725.51    18228.94    18264.89   \n",
      "4      1259.00         896       926.2     1739.76     2122.08      2970.3   \n",
      "\n",
      "  Total_22-23 Total_23-24  \n",
      "0   124000.00   115531.79  \n",
      "1   124000.00   115531.79  \n",
      "2     8513.62     9504.00  \n",
      "3    22723.58    25078.49  \n",
      "4           0           0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def load_and_clean_csv(file_path, year):\n",
    "    \"\"\"Load CSV and return cleaned dataframe with year suffix in total column\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter=',')\n",
    "        # Remove numbering from ministry names if present\n",
    "        df.iloc[:, 0] = df.iloc[:, 0].str.replace(r'^\\d+\\.\\s+', '', regex=True)\n",
    "        # Remove leading/trailing whitespace\n",
    "        df.iloc[:, 0] = df.iloc[:, 0].str.strip()\n",
    "        # Rename columns\n",
    "        df.columns = ['Ministry', f'Total_{year}']\n",
    "        return df\n",
    "    except:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter=';')\n",
    "            df.iloc[:, 0] = df.iloc[:, 0].str.replace(r'^\\d+\\.\\s+', '', regex=True)\n",
    "            df.iloc[:, 0] = df.iloc[:, 0].str.strip()\n",
    "            df.columns = ['Ministry', f'Total_{year}']\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "def find_best_match(ministry_name, ministry_list, threshold=80):\n",
    "    \"\"\"Find best matching ministry name from list using fuzzy matching\"\"\"\n",
    "    if pd.isna(ministry_name) or ministry_name.strip() == '':\n",
    "        return None\n",
    "    \n",
    "    matches = process.extract(ministry_name, ministry_list, scorer=fuzz.token_sort_ratio)\n",
    "    best_match = matches[0] if matches else None\n",
    "    \n",
    "    if best_match and best_match[1] >= threshold:\n",
    "        return best_match[0]\n",
    "    return None\n",
    "\n",
    "# Path to dataset folder\n",
    "dataset_folder = \"/Users/vvmohith/Desktop/PROJECT/dataset-final/\"\n",
    "\n",
    "# Get list of all year folders\n",
    "years = []\n",
    "for year in range(5, 24):  # 05-06 to 23-24\n",
    "    folder_name = f\"{year:02d}-{(year+1):02d}\"\n",
    "    if os.path.exists(os.path.join(dataset_folder, folder_name)):\n",
    "        years.append(folder_name)\n",
    "\n",
    "# Initialize dictionary to store dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Load all CSV files\n",
    "for year in years:\n",
    "    file_path = os.path.join(dataset_folder, year, f\"{year}.csv\")\n",
    "    if os.path.exists(file_path):\n",
    "        df = load_and_clean_csv(file_path, year)\n",
    "        if df is not None:\n",
    "            dfs[year] = df\n",
    "            print(f\"Loaded {year} with {len(df)} ministries\")\n",
    "\n",
    "# Use 21-22 as reference for ministry names\n",
    "reference_year = \"21-22\"\n",
    "reference_ministries = dfs[reference_year]['Ministry'].tolist()\n",
    "\n",
    "# Create merged dataframe\n",
    "merged_df = pd.DataFrame()\n",
    "merged_df['Ministry'] = dfs[reference_year]['Ministry']\n",
    "\n",
    "# Match and merge data from all years\n",
    "for year in years:\n",
    "    if year in dfs:\n",
    "        df = dfs[year]\n",
    "        matches = {}\n",
    "        \n",
    "        # Find matches for each ministry in current year\n",
    "        for idx, row in df.iterrows():\n",
    "            match = find_best_match(row['Ministry'], reference_ministries)\n",
    "            if match:\n",
    "                matches[row['Ministry']] = match\n",
    "        \n",
    "        # Create mapping series\n",
    "        mapping_series = pd.Series(matches)\n",
    "        \n",
    "        # Map and merge\n",
    "        df['Matched_Ministry'] = df['Ministry'].map(mapping_series)\n",
    "        df = df.dropna(subset=['Matched_Ministry'])\n",
    "        \n",
    "        # Merge with final dataframe\n",
    "        merged_df = merged_df.merge(\n",
    "            df[['Matched_Ministry', f'Total_{year}']],\n",
    "            left_on='Ministry',\n",
    "            right_on='Matched_Ministry',\n",
    "            how='left'\n",
    "        )\n",
    "        merged_df = merged_df.drop('Matched_Ministry', axis=1)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "# Save merged dataframe\n",
    "output_path = os.path.join(dataset_folder, 'merged_budget_data.csv')\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nMerged data saved to: {output_path}\")\n",
    "print(f\"Final shape: {merged_df.shape}\")\n",
    "print(\"\\nSample of merged data:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 914\n",
      "Cleaned number of rows: 78\n",
      "\n",
      "Sample of merged ministries:\n",
      "                       Ministry  Total_05-06  Total_06-07  Total_07-08  \\\n",
      "0   Andaman and Nicobar Islands      1675.59      1977.93      1854.83   \n",
      "1                 Atomic Energy      4995.86      5505.08      6130.00   \n",
      "2                       Cabinet         0.00         0.00         0.00   \n",
      "3  Central Vigilance Commission         0.00         0.00         0.00   \n",
      "4                    Chandigarh       994.43      1032.90      1104.91   \n",
      "\n",
      "   Total_09-10  Total_10-11  Total_12-13  Total_13-14 Total_15-16 Total_16-17  \\\n",
      "0      2689.23      2064.31      2982.65      3192.70     3748.38     4072.02   \n",
      "1      7773.00      8521.00      9232.00      9833.32    10912.00    11682.48   \n",
      "2         0.00         0.00         0.00         0.00           0           0   \n",
      "3         0.00         0.00         0.00         0.00           0           0   \n",
      "4      1772.56      1920.89      2546.96      3074.32     3457.16     3544.54   \n",
      "\n",
      "  Total_19-20 Total_20-21 Total_21-22 Total_22-23 Total_23-24  \n",
      "0     4817.48     5164.26     5317.41     5703.65           0  \n",
      "1    16725.51    18228.94    18264.89    22723.58    25078.49  \n",
      "2      828.85     1140.38     2098.04     1711.04     1258.68  \n",
      "3       35.55       39.00       38.67       41.96       44.46  \n",
      "4      4291.7     4635.10     4661.12           0           0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "\n",
    "def standardize_ministry_names(df):\n",
    "    # Create a mapping dictionary for similar ministry names\n",
    "    ministry_mapping = {}\n",
    "    ministries = df['Ministry'].unique()\n",
    "    \n",
    "    # First pass - group similar ministries\n",
    "    for i in range(len(ministries)):\n",
    "        if ministries[i] not in ministry_mapping:\n",
    "            ministry_mapping[ministries[i]] = ministries[i]\n",
    "            for j in range(i + 1, len(ministries)):\n",
    "                # Use token_set_ratio to handle rearranged words\n",
    "                similarity = fuzz.token_set_ratio(ministries[i], ministries[j])\n",
    "                if similarity >= 80:  # Adjust threshold as needed\n",
    "                    ministry_mapping[ministries[j]] = ministries[i]\n",
    "    \n",
    "    # Apply mapping\n",
    "    df['Ministry'] = df['Ministry'].map(lambda x: ministry_mapping.get(x, x))\n",
    "    \n",
    "    # Aggregate duplicate ministries\n",
    "    return df.groupby('Ministry', as_index=False).agg({\n",
    "        col: 'max' if col.startswith('Total_') else 'first' \n",
    "        for col in df.columns if col != 'Ministry'\n",
    "    })\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"/Users/vvmohith/Desktop/PROJECT/dataset-final/merged_budget_data.csv\")\n",
    "\n",
    "# Clean and standardize ministry names\n",
    "cleaned_df = standardize_ministry_names(df)\n",
    "\n",
    "# Sort by ministry name\n",
    "cleaned_df = cleaned_df.sort_values('Ministry')\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_df.to_csv(\"/Users/vvmohith/Desktop/PROJECT/dataset-final/cleaned_merged_budget_data.csv\", index=False)\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Original number of rows: {len(df)}\")\n",
    "print(f\"Cleaned number of rows: {len(cleaned_df)}\")\n",
    "print(\"\\nSample of merged ministries:\")\n",
    "print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 05-06 data: 94 entries\n",
      "Processed 06-07 data: 96 entries\n",
      "Processed 07-08 data: 123 entries\n",
      "Processed 08-09 data: 123 entries\n",
      "Processed 09-10 data: 101 entries\n",
      "Processed 10-11 data: 101 entries\n",
      "Processed 11-12 data: 101 entries\n",
      "Processed 12-13 data: 101 entries\n",
      "Processed 13-14 data: 102 entries\n",
      "Processed 14-15 data: 102 entries\n",
      "Processed 15-16 data: 131 entries\n",
      "Processed 16-17 data: 127 entries\n",
      "Processed 17-18 data: 127 entries\n",
      "Processed 18-19 data: 127 entries\n",
      "Processed 19-20 data: 102 entries\n",
      "Processed 20-21 data: 104 entries\n",
      "Processed 21-22 data: 102 entries\n",
      "Processed 22-23 data: 96 entries\n",
      "Processed 23-24 data: 92 entries\n",
      "\n",
      "Final dataset saved to: /Users/vvmohith/Desktop/PROJECT/dataset-final/final_budget_data.csv\n",
      "Total number of unique ministries: 119964\n",
      "\n",
      "First few entries:\n",
      "   No.                         Ministry  Total_05-06  Total_06-07 Total_07-08 Total_08-09  Total_09-10  Total_10-11  Total_11-12  Total_12-13  Total_13-14  Total_14-15 Total_15-16 Total_16-17 Total_17-18 Total_18-19 Total_19-20 Total_20-21 Total_21-22 Total_22-23 Total_23-24\n",
      "0    1                   (2) Puducherry          0.0          0.0           0           0          0.0          0.0          0.0      1205.00      1268.20      1268.20     1377.01     1409.00     1409.00     1409.00           0           0           0           0           0\n",
      "1    2  (3) Andaman and Nicobar Islands          0.0          0.0           0           0          0.0          0.0          0.0      2982.65      3192.70      3192.70           0           0           0           0           0           0           0           0           0\n",
      "2    3           (3) UT Schemes(Others)          0.0          0.0           0           0          0.0          0.0          0.0         0.00         0.00         0.00     1816.00     1248.95     1248.95     1248.95           0           0           0           0           0\n",
      "3    4  (4) Andaman and Nicobar Islands          0.0          0.0           0           0          0.0          0.0          0.0         0.00         0.00         0.00     3748.38     4072.02     4072.02     4072.02           0           0           0           0           0\n",
      "4    5                   (4) Chandigarh          0.0          0.0           0           0          0.0          0.0          0.0      2546.96      3074.32      3074.32           0           0           0           0           0           0           0           0           0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "\n",
    "def clean_ministry_name(name):\n",
    "    \"\"\"Clean ministry name by removing prefixes and standardizing format\"\"\"\n",
    "    name = str(name).strip()\n",
    "    # Remove numbering at start\n",
    "    name = name.split('.', 1)[-1].strip()\n",
    "    # Remove common prefixes\n",
    "    prefixes = ['Department of', 'Ministry of']\n",
    "    for prefix in prefixes:\n",
    "        if name.startswith(prefix):\n",
    "            name = name[len(prefix):].strip()\n",
    "    return name\n",
    "\n",
    "def are_ministries_similar(name1, name2, threshold=85):\n",
    "    \"\"\"Check if two ministry names are similar using fuzzy matching\"\"\"\n",
    "    if pd.isna(name1) or pd.isna(name2):\n",
    "        return False\n",
    "    return fuzz.token_sort_ratio(str(name1).lower(), str(name2).lower()) >= threshold\n",
    "\n",
    "def combine_budget_data(files_dict):\n",
    "    \"\"\"Process and combine budget data from multiple years\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # Process each year's data\n",
    "    for year, file_path in files_dict.items():\n",
    "        try:\n",
    "            # Try different delimiters\n",
    "            for delimiter in [',', ';']:\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, delimiter=delimiter)\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Clean column names\n",
    "            df.columns = [col.lower().strip() for col in df.columns]\n",
    "            ministry_col = next(col for col in df.columns if 'ministry' in col or 'department' in col)\n",
    "            total_col = next(col for col in df.columns if 'total' in col)\n",
    "            \n",
    "            # Select and rename columns\n",
    "            year_df = df[[ministry_col, total_col]].copy()\n",
    "            year_df.columns = ['Ministry', f'Total_{year}']\n",
    "            \n",
    "            # Clean ministry names\n",
    "            year_df['Ministry'] = year_df['Ministry'].apply(clean_ministry_name)\n",
    "            \n",
    "            all_data.append(year_df)\n",
    "            print(f\"Processed {year} data: {len(year_df)} entries\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {year} data: {str(e)}\")\n",
    "    \n",
    "    # Merge all years\n",
    "    final_df = all_data[0]\n",
    "    for df in all_data[1:]:\n",
    "        final_df = pd.merge(final_df, df, on='Ministry', how='outer')\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Define the years and file paths\n",
    "years = [f\"{str(year)[-2:]}-{str(year+1)[-2:]}\" for year in range(2005, 2024)]\n",
    "files_dict = {\n",
    "    year: f\"/Users/vvmohith/Desktop/PROJECT/dataset-final/{year}/{year}.csv\"\n",
    "    for year in years\n",
    "}\n",
    "\n",
    "# Process the data\n",
    "merged_df = combine_budget_data(files_dict)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "# Sort by ministry name\n",
    "merged_df = merged_df.sort_values('Ministry')\n",
    "\n",
    "# Add numbering\n",
    "merged_df.insert(0, 'No.', range(1, len(merged_df) + 1))\n",
    "\n",
    "# Save the final cleaned dataset\n",
    "output_path = \"/Users/vvmohith/Desktop/PROJECT/dataset-final/final_budget_data.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nFinal dataset saved to: {output_path}\")\n",
    "print(f\"Total number of unique ministries: {len(merged_df)}\")\n",
    "print(\"\\nFirst few entries:\")\n",
    "print(merged_df.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Grouping similar ministries...\n",
      "\n",
      "Step 2: Combining budget data...\n",
      "Processed 05-06\n",
      "Processed 06-07\n",
      "Processed 07-08\n",
      "Processed 09-10\n",
      "Processed 10-11\n",
      "Processed 12-13\n",
      "Processed 13-14\n",
      "Processed 15-16\n",
      "Processed 16-17\n",
      "Processed 19-20\n",
      "Processed 20-21\n",
      "Processed 21-22\n",
      "Processed 22-23\n",
      "Processed 23-24\n",
      "\n",
      "Final dataset saved to: /Users/vvmohith/Desktop/PROJECT/dataset-final/final_cleaned_budget.csv\n",
      "Total number of unique ministries: 32\n",
      "\n",
      "Similar ministry groups found:\n",
      "\n",
      "Agriculture and Cooperation:\n",
      "  - Agriculture & Cooperation\n",
      "\n",
      "Dadra and Nagar Haveli:\n",
      "  - Dadra & Nagar Haveli\n",
      "\n",
      "UNION TERRITORIES + B):\n",
      "  - UNION TERRITORIES\n",
      "\n",
      "Pharmaceuticals@:\n",
      "  - Pharmaceuticals\n",
      "\n",
      "Personnel, Public Grievances and Pensions:\n",
      "  - Personnel Public Grievances and Pensions\n",
      "\n",
      "Agriculture Cooperation and Farmers' Welfare:\n",
      "  - Agriculture Cooperation and Farmers Welfare\n",
      "\n",
      "Heavy Industries:\n",
      "  - Heavy Industry\n",
      "\n",
      "Economic Affairs provisions):\n",
      "  - Economic Affairs Provisions)\n",
      "\n",
      "Total Central Assistance for States and UTs + III):\n",
      "  - TOTAL CENTRAL ASSISTANCE FOR STATES & UTs\n",
      "  - Total Central Assistance for States & UTs\n",
      "  - Total Central Assistance for States and UTs\n",
      "\n",
      "Central Pool of Resources for NER and Sikkim:\n",
      "  - Central Pool of Resources for NE and Sikkim\n",
      "\n",
      "Chemicals and Petro-Chemicals:\n",
      "  - Chemicals and Petro-chemicals\n",
      "\n",
      "Andaman and Nicobar Islands:\n",
      "  - Andaman & Nicobar Islands\n",
      "\n",
      "Central Ministries/Departments Total:\n",
      "  - Central Ministries/Departments\n",
      "\n",
      "Health Research#:\n",
      "  - Health Research\n",
      "\n",
      "UNION TERRITORIES WITHOUT LEGISLATURE + 4 + 5 + 6 + 7):\n",
      "  - UNION TERRITORIES WITH LEGISLATURE + 2 + 3)\n",
      "  - UNION TERRITORIES WITH LEGISLATURE + 2)\n",
      "  - UNION TERRITORIES WITHOUT LEGISLATURE + 5 + 6 + 7 + 8)\n",
      "  - Union Territories with Legislature\n",
      "  - Union Territories without Legislature\n",
      "\n",
      "Agricultural Research and Education:\n",
      "  - Agriculture Research and Education\n",
      "\n",
      "Ayurveda, Yoga & Naturopathy, Unani, Siddha and Homoeopathy(AYUSH):\n",
      "  - Ayurveda Yoga & Naturopathy Unani Siddha and Homoeopathy AYUSH)\n",
      "  - Ayurveda Yoga & Naturopathy Unani Siddha and Homoeopathy(AYUSH)\n",
      "  - Ayurveda Yoga and Naturopathy Unani Siddha and Homoeopathy\n",
      "  - Ayurveda, Yoga & Naturopathy, Unani, Siddha and Homoeopathy\n",
      "\n",
      "Grand Total:\n",
      "  - GRAND TOTAL\n",
      "\n",
      "Animal Husbandry, Dairying and Fisheries:\n",
      "  - Animal Husbandry Dairying and Fisheries\n",
      "  - Animal Husbandry and Dairying\n",
      "\n",
      "Panchayati Raj@:\n",
      "  - Panchayati Raj\n",
      "\n",
      "Financial Services#:\n",
      "  - Financial Services\n",
      "\n",
      "Indirect Taxes:\n",
      "  - Direct Taxes\n",
      "\n",
      "Minority Affairs@:\n",
      "  - Minority Affairs\n",
      "\n",
      "STATE PLANS DONER) Total:\n",
      "  - STATE PLANS DONER)\n",
      "\n",
      "Defence(Civil Estimates):\n",
      "  - Defence estimates)\n",
      "\n",
      "Health and Family Welfare:\n",
      "  - Health & Family Welfare\n",
      "\n",
      "STATE PLANS:\n",
      "  - State Plans\n",
      "\n",
      "The President, Parliament, Union Public Service Commission and the Secretariat of the Vice-President:\n",
      "  - The President Parliament Union Public Service Commission and the Secretariat of the Vice President\n",
      "  - The President Parliament Union Public Service Commission and the Secretariat of the Vice-President\n",
      "\n",
      "Staff Household and Allowances of the President\":\n",
      "  - Staff Household and Allowances of the President\n",
      "\n",
      "Overseas Indian Affairs@:\n",
      "  - Overseas Indian Affairs\n",
      "\n",
      "Rural Development:\n",
      "  - Urban Development\n",
      "\n",
      "Micro, Small and Medium Enterprises:\n",
      "  - Micro Small and Medium Enterprises\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def clean_ministry_name(name):\n",
    "    \"\"\"Clean ministry name by removing prefixes and standardizing format\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).strip()\n",
    "    # Remove numbering and special characters\n",
    "    name = ' '.join(word for word in name.split() if not word.startswith(('(', '#', '@')))\n",
    "    name = name.split('.', 1)[-1].strip()\n",
    "    \n",
    "    # Remove common prefixes\n",
    "    prefixes = ['Department of', 'Ministry of']\n",
    "    for prefix in prefixes:\n",
    "        if name.lower().startswith(prefix.lower()):\n",
    "            name = name[len(prefix):].strip()\n",
    "    return name\n",
    "\n",
    "def group_similar_ministries(all_files):\n",
    "    \"\"\"First step: Group similar ministry names across all years\"\"\"\n",
    "    all_ministries = set()\n",
    "    ministry_groups = {}\n",
    "    \n",
    "    # First collect all unique ministry names\n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            ministry_col = df.columns[0]  # First column is usually ministry\n",
    "            ministries = df[ministry_col].apply(clean_ministry_name)\n",
    "            all_ministries.update(ministries.dropna().unique())\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    # Remove empty strings\n",
    "    all_ministries = {m for m in all_ministries if m.strip()}\n",
    "    \n",
    "    # Group similar ministries\n",
    "    processed = set()\n",
    "    for ministry in all_ministries:\n",
    "        if ministry in processed:\n",
    "            continue\n",
    "            \n",
    "        similar_ministries = {ministry}\n",
    "        for other in all_ministries:\n",
    "            if other != ministry and other not in processed:\n",
    "                ratio = fuzz.token_sort_ratio(ministry.lower(), other.lower())\n",
    "                if ratio >= 85:  # Adjust threshold as needed\n",
    "                    similar_ministries.add(other)\n",
    "                    processed.add(other)\n",
    "        \n",
    "        if len(similar_ministries) > 1:\n",
    "            # Use the most recent (usually more detailed) name as canonical\n",
    "            canonical = max(similar_ministries, key=len)\n",
    "            ministry_groups[canonical] = similar_ministries\n",
    "            processed.update(similar_ministries)\n",
    "            \n",
    "    return ministry_groups\n",
    "\n",
    "def combine_budget_data(ministry_groups, all_files):\n",
    "    \"\"\"Second step: Combine budget data using ministry groups\"\"\"\n",
    "    # Initialize DataFrame with canonical ministry names\n",
    "    canonical_names = list(ministry_groups.keys())\n",
    "    final_df = pd.DataFrame({'Ministry': canonical_names})\n",
    "    \n",
    "    # Process each year's file\n",
    "    for file_path in sorted(all_files):\n",
    "        try:\n",
    "            year = file_path.split('/')[-2]  # Extract year from path\n",
    "            df = pd.read_csv(file_path)\n",
    "            ministry_col = df.columns[0]\n",
    "            total_col = df.columns[1]\n",
    "            \n",
    "            # Create year's data with canonical names\n",
    "            year_data = defaultdict(float)\n",
    "            \n",
    "            for _, row in df.iterrows():\n",
    "                ministry = clean_ministry_name(row[ministry_col])\n",
    "                if not ministry:\n",
    "                    continue\n",
    "                    \n",
    "                # Find canonical name for this ministry\n",
    "                canonical = None\n",
    "                for can, group in ministry_groups.items():\n",
    "                    if ministry in group or any(fuzz.token_sort_ratio(ministry, m) >= 85 for m in group):\n",
    "                        canonical = can\n",
    "                        break\n",
    "                \n",
    "                if canonical:\n",
    "                    try:\n",
    "                        value = float(str(row[total_col]).replace(',', ''))\n",
    "                        year_data[canonical] += value\n",
    "                    except (ValueError, TypeError):\n",
    "                        continue\n",
    "            \n",
    "            # Add year's data to final DataFrame\n",
    "            final_df[f'Total_{year}'] = final_df['Ministry'].map(year_data)\n",
    "            print(f\"Processed {year}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Get all CSV files\n",
    "import glob\n",
    "all_files = sorted(glob.glob(\"/Users/vvmohith/Desktop/PROJECT/dataset-final/*/[0-9][0-9]-[0-9][0-9].csv\"))\n",
    "\n",
    "print(\"Step 1: Grouping similar ministries...\")\n",
    "ministry_groups = group_similar_ministries(all_files)\n",
    "\n",
    "print(\"\\nStep 2: Combining budget data...\")\n",
    "final_df = combine_budget_data(ministry_groups, all_files)\n",
    "\n",
    "# Clean up and format\n",
    "final_df = final_df.fillna(0)\n",
    "final_df = final_df.sort_values('Ministry')\n",
    "final_df.insert(0, 'No.', range(1, len(final_df) + 1))\n",
    "\n",
    "# Save results\n",
    "output_path = \"/Users/vvmohith/Desktop/PROJECT/dataset-final/final_cleaned_budget.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nFinal dataset saved to: {output_path}\")\n",
    "print(f\"Total number of unique ministries: {len(final_df)}\")\n",
    "print(\"\\nSimilar ministry groups found:\")\n",
    "for canonical, group in ministry_groups.items():\n",
    "    if len(group) > 1:\n",
    "        print(f\"\\n{canonical}:\")\n",
    "        print(\"  - \" + \"\\n  - \".join(sorted(group - {canonical})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Identifying similar ministry names...\n",
      "Found 235 canonical ministry names\n",
      "\n",
      "Step 2: Processing budget files...\n",
      "Processing 05-06 data...\n",
      "Processing 06-07 data...\n",
      "Processing 07-08 data...\n",
      "Processing 09-10 data...\n",
      "Processing 10-11 data...\n",
      "Processing 12-13 data...\n",
      "Processing 13-14 data...\n",
      "Processing 15-16 data...\n",
      "Processing 16-17 data...\n",
      "Processing 19-20 data...\n",
      "Processing 20-21 data...\n",
      "Processing 21-22 data...\n",
      "Processing 22-23 data...\n",
      "Processing 23-24 data...\n",
      "\n",
      "Normalized budget data saved to: /Users/vvmohith/Desktop/PROJECT/dataset-final/normalized_budget_data.csv\n",
      "Total unique ministries: 235\n",
      "\n",
      "Top 10 ministries by total budget (all years):\n",
      "97. Grand Total: 25,870,098.15\n",
      "101. I. CENTRAL SECTOR: 6,185,235.88\n",
      "111. Interest Payments: 4,203,587.42\n",
      "209. b. Economic Affairs (Centralised Provisions): 3,273,487.90\n",
      "26. CENTRAL SECTOR - TOTAL: 1,944,115.76\n",
      "44. Defence Services: 1,423,309.55\n",
      "198. Transfers to States: 1,319,613.73\n",
      "45. Defence Services (Revenue): 1,122,953.00\n",
      "202. V. GRAND TOTAL (I+IV): 1,108,749.24\n",
      "29. Central Ministries/Departments Total: 998,725.45\n",
      "\n",
      "Sample normalized ministry groups:\n",
      "\n",
      "(8) Lakshadweep:\n",
      "  - (7) Lakshadweep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/wzy1hvwd7bd4plh9mwvg9yyc0000gn/T/ipykernel_1121/2048136811.py:139: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result_df = result_df.fillna(0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def clean_ministry_name(name):\n",
    "    \"\"\"Clean ministry name by removing numbering and standardizing format\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    \n",
    "    name = str(name).strip()\n",
    "    \n",
    "    # Remove numbering at start (like \"1.\" or \"23.\")\n",
    "    if '.' in name and name.split('.')[0].strip().isdigit():\n",
    "        name = name.split('.', 1)[1].strip()\n",
    "    \n",
    "    # Strip special characters and extra spaces\n",
    "    name = ' '.join(name.split())\n",
    "    return name\n",
    "\n",
    "def identify_ministry_groups():\n",
    "    \"\"\"First step: Identify groups of similar ministries\"\"\"\n",
    "    all_files = []\n",
    "    for year in range(5, 24):  # 05-06 to 22-23\n",
    "        year_folder = f\"{year:02d}-{(year+1):02d}\"\n",
    "        csv_path = f\"/Users/vvmohith/Desktop/PROJECT/dataset-final/{year_folder}/{year_folder}.csv\"\n",
    "        if os.path.exists(csv_path):\n",
    "            all_files.append(csv_path)\n",
    "    \n",
    "    # Collect all unique ministry names\n",
    "    all_ministries = set()\n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            ministry_col = df.columns[0]  # First column usually contains ministry names\n",
    "            cleaned_names = df[ministry_col].apply(clean_ministry_name)\n",
    "            all_ministries.update(cleaned_names.dropna().unique())\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    # Remove empty entries\n",
    "    all_ministries = {m for m in all_ministries if m and not m.isspace()}\n",
    "    \n",
    "    # Build standardization mapping using fuzzy matching\n",
    "    ministry_mapping = {}\n",
    "    canonical_ministries = {}\n",
    "    \n",
    "    # Sort ministries by length (descending) to prefer more detailed names\n",
    "    sorted_ministries = sorted(all_ministries, key=len, reverse=True)\n",
    "    \n",
    "    # Identify groups of similar ministries\n",
    "    for ministry in sorted_ministries:\n",
    "        # Skip if already mapped to a canonical name\n",
    "        if ministry in ministry_mapping:\n",
    "            continue\n",
    "        \n",
    "        # Start a new group with this ministry\n",
    "        similarity_group = [ministry]\n",
    "        for other in sorted_ministries:\n",
    "            if other != ministry and other not in ministry_mapping:\n",
    "                # Check if similar\n",
    "                similarity = fuzz.token_sort_ratio(ministry.lower(), other.lower())\n",
    "                if similarity >= 85:\n",
    "                    similarity_group.append(other)\n",
    "        \n",
    "        # Use most descriptive name as canonical name\n",
    "        canonical = similarity_group[0]\n",
    "        \n",
    "        # Special case for prefixes\n",
    "        for name in similarity_group:\n",
    "            if name.startswith(\"Department of\") or name.startswith(\"Ministry of\"):\n",
    "                canonical = name\n",
    "                break\n",
    "        \n",
    "        # Register the group\n",
    "        canonical_ministries[canonical] = similarity_group\n",
    "        for name in similarity_group:\n",
    "            ministry_mapping[name] = canonical\n",
    "    \n",
    "    print(f\"Found {len(canonical_ministries)} canonical ministry names\")\n",
    "    return ministry_mapping\n",
    "\n",
    "def process_budget_files(ministry_mapping):\n",
    "    \"\"\"Process all budget files and create consolidated dataset\"\"\"\n",
    "    # Initialize DataFrame with columns for each year\n",
    "    columns = ['Ministry']\n",
    "    for year in range(5, 24):\n",
    "        columns.append(f'Total_{year:02d}-{(year+1):02d}')\n",
    "    \n",
    "    result_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # Get unique canonical ministry names\n",
    "    canonical_names = set(ministry_mapping.values())\n",
    "    result_df['Ministry'] = sorted(canonical_names)\n",
    "    result_df = result_df.set_index('Ministry')\n",
    "    \n",
    "    # Process each year's budget file\n",
    "    for year in range(5, 24):\n",
    "        year_str = f\"{year:02d}-{(year+1):02d}\"\n",
    "        file_path = f\"/Users/vvmohith/Desktop/PROJECT/dataset-final/{year_str}/{year_str}.csv\"\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"Processing {year_str} data...\")\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Identify ministry and budget columns\n",
    "                ministry_col = df.columns[0]\n",
    "                budget_col = df.columns[1] if len(df.columns) > 1 else None\n",
    "                \n",
    "                if budget_col:\n",
    "                    # Create a dictionary to store budget values by canonical ministry name\n",
    "                    year_data = defaultdict(float)\n",
    "                    \n",
    "                    # Process each row\n",
    "                    for _, row in df.iterrows():\n",
    "                        ministry_name = clean_ministry_name(row[ministry_col])\n",
    "                        if ministry_name in ministry_mapping:\n",
    "                            canonical = ministry_mapping[ministry_name]\n",
    "                            try:\n",
    "                                # Convert budget to float, handling commas and other formatting\n",
    "                                budget_val = str(row[budget_col]).replace(',', '')\n",
    "                                budget_val = float(''.join(c for c in budget_val if c.isdigit() or c == '.'))\n",
    "                                year_data[canonical] += budget_val\n",
    "                            except (ValueError, TypeError):\n",
    "                                pass\n",
    "                    \n",
    "                    # Add data to results DataFrame\n",
    "                    year_col = f'Total_{year_str}'\n",
    "                    for ministry, value in year_data.items():\n",
    "                        result_df.loc[ministry, year_col] = value\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    # Fill NaN values with 0\n",
    "    result_df = result_df.fillna(0)\n",
    "    \n",
    "    # Reset index to make Ministry a column\n",
    "    result_df = result_df.reset_index()\n",
    "    \n",
    "    # Add numbering\n",
    "    result_df.insert(0, 'No.', range(1, len(result_df) + 1))\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Main execution flow\n",
    "print(\"Step 1: Identifying similar ministry names...\")\n",
    "ministry_mapping = identify_ministry_groups()\n",
    "\n",
    "print(\"\\nStep 2: Processing budget files...\")\n",
    "final_df = process_budget_files(ministry_mapping)\n",
    "\n",
    "# Save the result\n",
    "output_path = \"/Users/vvmohith/Desktop/PROJECT/dataset-final/normalized_budget_data.csv\"\n",
    "\n",
    "print(f\"\\nNormalized budget data saved to: {output_path}\")\n",
    "print(f\"Total unique ministries: {len(final_df)}\")\n",
    "\n",
    "# Display statistics\n",
    "print(\"\\nTop 10 ministries by total budget (all years):\")\n",
    "final_df['Total'] = final_df.iloc[:, 2:].sum(axis=1)\n",
    "top_ministries = final_df.sort_values('Total', ascending=False).head(10)\n",
    "for _, row in top_ministries.iterrows():\n",
    "    print(f\"{row['No.']}. {row['Ministry']}: {row['Total']:,.2f}\")\n",
    "\n",
    "print(\"\\nSample normalized ministry groups:\")\n",
    "# Show a few examples of ministry name normalization\n",
    "for canonical, names in list({name: [k for k, v in ministry_mapping.items() if v == name] \n",
    "                             for name in set(ministry_mapping.values())}.items())[:5]:\n",
    "    if len(names) > 1:\n",
    "        print(f\"\\n{canonical}:\")\n",
    "        for name in sorted(names):\n",
    "            if name != canonical:\n",
    "                print(f\"  - {name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
