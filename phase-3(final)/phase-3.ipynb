{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_standardized_sector_data_sources():\n",
    "    \"\"\"\n",
    "    Define standardized data sources for sector-wise GVA growth\n",
    "    \n",
    "    All data should come from MOSPI National Accounts Statistics\n",
    "    using Gross Value Added (GVA) at constant prices\n",
    "    \"\"\"\n",
    "    \n",
    "    data_collection_guide = {\n",
    "        'Primary_Source': {\n",
    "            'name': 'MOSPI National Accounts Statistics',\n",
    "            'url': 'https://www.mospi.gov.in/national-accounts-statistics',\n",
    "            'specific_table': 'Table 1.4 - Gross Value Added by Economic Activity at 2011-12 Prices',\n",
    "            'metric': 'Annual Growth Rate in GVA (%)',\n",
    "            'frequency': 'Annual',\n",
    "            'base_year': '2011-12 constant prices'\n",
    "        },\n",
    "        \n",
    "        'Sector_Mapping_to_MOSPI': {\n",
    "            'Infrastructure & Transport': {\n",
    "                'mospi_category': 'Transport, storage, communication and services related to broadcasting',\n",
    "                'additional_data': 'Construction (for infrastructure)',\n",
    "                'collection_method': 'Transport + 50% of Construction GVA growth'\n",
    "            },\n",
    "            \n",
    "            'Energy & Natural Resources': {\n",
    "                'mospi_category': 'Mining and quarrying + Electricity, gas, water supply and other utility services',\n",
    "                'collection_method': 'Weighted average of Mining (30%) + Utilities (70%)'\n",
    "            },\n",
    "            \n",
    "            'Agriculture & Rural': {\n",
    "                'mospi_category': 'Agriculture, forestry and fishing',\n",
    "                'collection_method': 'Direct GVA growth rate'\n",
    "            },\n",
    "            \n",
    "            'Social Services': {\n",
    "                'mospi_category': 'Public administration, defence and other services',\n",
    "                'additional_data': 'Human health and social work activities',\n",
    "                'collection_method': 'Weighted average of both categories'\n",
    "            },\n",
    "            \n",
    "            'Economic Services': {\n",
    "                'mospi_category': 'Manufacturing + Trade, hotels, transport, communication and services related to broadcasting',\n",
    "                'collection_method': 'Manufacturing (60%) + Trade services (40%)'\n",
    "            },\n",
    "            \n",
    "            'Defense & Security': {\n",
    "                'mospi_category': 'Public administration, defence and other services',\n",
    "                'collection_method': 'Extract defence component (approximately 25% of category)'\n",
    "            },\n",
    "            \n",
    "            'Communication & Technology': {\n",
    "                'mospi_category': 'Financial, real estate and professional services',\n",
    "                'additional_data': 'Information technology services',\n",
    "                'collection_method': 'IT services growth from separate IT ministry data'\n",
    "            },\n",
    "            \n",
    "            'Science & Innovation': {\n",
    "                'mospi_category': 'Financial, real estate and professional services',\n",
    "                'collection_method': 'Professional services component (20% of category)'\n",
    "            },\n",
    "            \n",
    "            'Governance & Administration': {\n",
    "                'mospi_category': 'Public administration, defence and other services',\n",
    "                'collection_method': 'Administrative component (75% of category)'\n",
    "            },\n",
    "            \n",
    "            'Culture & Tourism': {\n",
    "                'mospi_category': 'Trade, hotels, transport, communication and services related to broadcasting',\n",
    "                'collection_method': 'Hotels and restaurants component'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return data_collection_guide\n",
    "\n",
    "def create_data_collection_template():\n",
    "    \"\"\"Create template for manual data collection\"\"\"\n",
    "    \n",
    "    # Years for data collection\n",
    "    fiscal_years = ['05-06', '06-07', '07-08', '08-09', '09-10', '10-11', \n",
    "                   '11-12', '12-13', '13-14', '14-15', '15-16', '16-17', \n",
    "                   '17-18', '18-19', '19-20', '20-21', '21-22', '22-23', '23-24']\n",
    "    \n",
    "    # MOSPI categories to collect\n",
    "    mospi_categories = [\n",
    "        'Agriculture, forestry and fishing',\n",
    "        'Mining and quarrying',\n",
    "        'Manufacturing',\n",
    "        'Electricity, gas, water supply and other utility services',\n",
    "        'Construction',\n",
    "        'Trade, hotels, transport, communication and services related to broadcasting',\n",
    "        'Financial, real estate and professional services',\n",
    "        'Public administration, defence and other services'\n",
    "    ]\n",
    "    \n",
    "    collection_template = pd.DataFrame({\n",
    "        'Fiscal_Year': fiscal_years,\n",
    "        'Agriculture_Forestry_Fishing_GVA_Growth': [np.nan] * len(fiscal_years),\n",
    "        'Mining_Quarrying_GVA_Growth': [np.nan] * len(fiscal_years),\n",
    "        'Manufacturing_GVA_Growth': [np.nan] * len(fiscal_years),\n",
    "        'Utilities_GVA_Growth': [np.nan] * len(fiscal_years),\n",
    "        'Construction_GVA_Growth': [np.nan] * len(fiscal_years),\n",
    "        'Trade_Hotels_Transport_GVA_Growth': [np.nan] * len(fiscal_years),\n",
    "        'Financial_Professional_Services_GVA_Growth': [np.nan] * len(fiscal_years),\n",
    "        'Public_Admin_Defence_GVA_Growth': [np.nan] * len(fiscal_years)\n",
    "    })\n",
    "    \n",
    "    collection_template.to_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/mospi_gva_collection_template.csv', index=False)\n",
    "    \n",
    "    print(\"Data collection template created: mospi_gva_collection_template.csv\")\n",
    "    print(\"\\nInstructions:\")\n",
    "    print(\"1. Go to https://www.mospi.gov.in/national-accounts-statistics\")\n",
    "    print(\"2. Download 'National Accounts Statistics' latest release\")\n",
    "    print(\"3. Find Table 1.4 - Gross Value Added by Economic Activity\")\n",
    "    print(\"4. Extract growth rates for each category by year\")\n",
    "    print(\"5. Fill the template with actual data\")\n",
    "    \n",
    "    return collection_template\n",
    "\n",
    "def calculate_sector_growth_from_mospi_data():\n",
    "    \"\"\"\n",
    "    Calculate standardized sector growth rates from MOSPI GVA data\n",
    "    \n",
    "    This function should be run AFTER you collect actual MOSPI data\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Load your collected MOSPI data\n",
    "        mospi_data = pd.read_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/mospi_gva_collection_template.csv')\n",
    "        \n",
    "        # Check if data is filled\n",
    "        if mospi_data.iloc[:, 1:].isna().all().all():\n",
    "            print(\"Please fill the MOSPI data template first!\")\n",
    "            return create_sample_standardized_data()\n",
    "        \n",
    "        # Calculate standardized sector growth rates\n",
    "        standardized_data = mospi_data[['Fiscal_Year']].copy()\n",
    "        \n",
    "        # Agriculture & Rural = Direct agriculture GVA\n",
    "        standardized_data['Agriculture_Rural_Growth'] = mospi_data['Agriculture_Forestry_Fishing_GVA_Growth']\n",
    "        \n",
    "        # Energy & Natural Resources = 30% Mining + 70% Utilities\n",
    "        standardized_data['Energy_Natural_Resources_Growth'] = (\n",
    "            0.3 * mospi_data['Mining_Quarrying_GVA_Growth'] + \n",
    "            0.7 * mospi_data['Utilities_GVA_Growth']\n",
    "        )\n",
    "        \n",
    "        # Economic Services = 60% Manufacturing + 40% Trade\n",
    "        standardized_data['Economic_Services_Growth'] = (\n",
    "            0.6 * mospi_data['Manufacturing_GVA_Growth'] + \n",
    "            0.4 * mospi_data['Trade_Hotels_Transport_GVA_Growth']\n",
    "        )\n",
    "        \n",
    "        # Infrastructure & Transport = Trade transport component + 50% Construction\n",
    "        standardized_data['Infrastructure_Transport_Growth'] = (\n",
    "            0.7 * mospi_data['Trade_Hotels_Transport_GVA_Growth'] + \n",
    "            0.5 * mospi_data['Construction_GVA_Growth']\n",
    "        )\n",
    "        \n",
    "        # Social Services = 70% Public admin + 30% Financial services\n",
    "        standardized_data['Social_Services_Growth'] = (\n",
    "            0.7 * mospi_data['Public_Admin_Defence_GVA_Growth'] + \n",
    "            0.3 * mospi_data['Financial_Professional_Services_GVA_Growth']\n",
    "        )\n",
    "        \n",
    "        # Defense & Security = 25% of Public admin\n",
    "        standardized_data['Defense_Security_Growth'] = (\n",
    "            0.25 * mospi_data['Public_Admin_Defence_GVA_Growth']\n",
    "        )\n",
    "        \n",
    "        # Communication & Technology = Financial services (proxy for IT)\n",
    "        standardized_data['Communication_Technology_Growth'] = (\n",
    "            mospi_data['Financial_Professional_Services_GVA_Growth']\n",
    "        )\n",
    "        \n",
    "        # Science & Innovation = 20% of Financial professional services\n",
    "        standardized_data['Science_Innovation_Growth'] = (\n",
    "            0.2 * mospi_data['Financial_Professional_Services_GVA_Growth']\n",
    "        )\n",
    "        \n",
    "        # Governance & Administration = 75% of Public admin\n",
    "        standardized_data['Governance_Administration_Growth'] = (\n",
    "            0.75 * mospi_data['Public_Admin_Defence_GVA_Growth']\n",
    "        )\n",
    "        \n",
    "        # Culture & Tourism = Hotels component from Trade category\n",
    "        standardized_data['Culture_Tourism_Growth'] = (\n",
    "            0.3 * mospi_data['Trade_Hotels_Transport_GVA_Growth']  # Hotels portion\n",
    "        )\n",
    "        \n",
    "        standardized_data.to_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/standardized_sector_growth_data.csv', index=False)\n",
    "        \n",
    "        print(\"Standardized sector growth data created!\")\n",
    "        return standardized_data\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"MOSPI template not found. Creating sample data for development...\")\n",
    "        return create_sample_standardized_data()\n",
    "\n",
    "def create_sample_standardized_data():\n",
    "    \"\"\"Create sample data based on realistic MOSPI patterns for development\"\"\"\n",
    "    \n",
    "    fiscal_years = ['05-06', '06-07', '07-08', '08-09', '09-10', '10-11', \n",
    "                   '11-12', '12-13', '13-14', '14-15', '15-16', '16-17', \n",
    "                   '17-18', '18-19', '19-20', '20-21', '21-22', '22-23', '23-24']\n",
    "    \n",
    "    # Sample data based on actual MOSPI historical trends\n",
    "    sample_data = {\n",
    "        'Fiscal_Year': fiscal_years,\n",
    "        \n",
    "        # Agriculture - known for volatility\n",
    "        'Agriculture_Rural_Growth': [\n",
    "            5.1, 4.2, 5.8, 0.1, 1.0, 8.6, 3.7, 1.4, -0.2, 0.2,\n",
    "            6.3, 6.8, 5.0, 2.9, 4.3, 3.6, 3.9, 3.5, 1.4\n",
    "        ],\n",
    "        \n",
    "        # Energy - stable with crisis impacts\n",
    "        'Energy_Natural_Resources_Growth': [\n",
    "            7.2, 7.8, 6.1, 2.8, 5.9, 7.6, 4.8, 3.2, 5.4, 6.9,\n",
    "            7.1, 6.2, 5.1, 4.3, 1.5, -4.8, 8.3, 6.4, 5.7\n",
    "        ],\n",
    "        \n",
    "        # Manufacturing - cyclical\n",
    "        'Economic_Services_Growth': [\n",
    "            10.2, 11.1, 8.7, 1.8, 7.9, 9.2, 6.4, 5.1, 7.0, 7.5,\n",
    "            8.1, 6.8, 6.0, 5.5, 3.0, -6.2, 9.8, 7.8, 6.8\n",
    "        ],\n",
    "        \n",
    "        # Infrastructure - investment driven\n",
    "        'Infrastructure_Transport_Growth': [\n",
    "            11.8, 13.2, 7.9, -1.8, 8.4, 10.3, 6.1, 3.8, 6.4, 8.1,\n",
    "            8.3, 6.8, 5.7, 5.2, 1.9, -7.2, 10.8, 7.8, 6.7\n",
    "        ],\n",
    "        \n",
    "        # Social Services - steady growth\n",
    "        'Social_Services_Growth': [\n",
    "            6.8, 7.2, 8.1, 5.6, 7.0, 8.6, 7.2, 6.5, 7.7, 8.1,\n",
    "            7.9, 7.4, 6.8, 6.3, 4.6, -2.5, 7.9, 6.9, 6.4\n",
    "        ],\n",
    "        \n",
    "        # Defense - budget constrained\n",
    "        'Defense_Security_Growth': [\n",
    "            5.2, 6.1, 7.4, 4.0, 5.7, 6.9, 5.3, 4.5, 5.9, 6.2,\n",
    "            6.0, 5.6, 4.9, 4.3, 3.2, -1.0, 5.9, 5.4, 5.1\n",
    "        ],\n",
    "        \n",
    "        # IT - high growth\n",
    "        'Communication_Technology_Growth': [\n",
    "            22.3, 25.1, 19.4, 12.2, 16.8, 21.7, 16.9, 14.4, 17.1, 19.3,\n",
    "            18.8, 16.7, 14.2, 12.8, 9.4, 6.9, 15.7, 13.2, 11.8\n",
    "        ],\n",
    "        \n",
    "        # Science - R&D dependent\n",
    "        'Science_Innovation_Growth': [\n",
    "            8.4, 9.2, 7.7, 4.1, 6.8, 8.6, 6.3, 5.4, 7.1, 7.9,\n",
    "            7.6, 6.9, 6.1, 5.7, 3.2, -0.8, 7.4, 6.6, 5.9\n",
    "        ],\n",
    "        \n",
    "        # Governance - administrative efficiency\n",
    "        'Governance_Administration_Growth': [\n",
    "            3.2, 3.8, 4.1, 2.7, 3.5, 4.3, 3.1, 2.8, 3.6, 3.9,\n",
    "            3.7, 3.3, 2.9, 2.6, 1.8, 0.2, 3.1, 2.8, 2.5\n",
    "        ],\n",
    "        \n",
    "        # Tourism - highly volatile\n",
    "        'Culture_Tourism_Growth': [\n",
    "            11.8, 13.2, 9.6, -4.3, 7.9, 12.1, 8.4, 6.8, 9.2, 10.7,\n",
    "            10.3, 8.8, 7.4, 6.9, 1.1, -14.6, 11.4, 8.7, 7.1\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    df.to_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/standardized_sector_growth_data.csv', index=False)\n",
    "    \n",
    "    print(\"Sample standardized sector data created for development\")\n",
    "    print(\"Replace with actual MOSPI data for production use\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Execute data collection setup\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Show data sources\n",
    "    sources = get_standardized_sector_data_sources()\n",
    "    \n",
    "    print(\"STANDARDIZED SECTOR DATA COLLECTION GUIDE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Primary Source: {sources['Primary_Source']['name']}\")\n",
    "    print(f\"URL: {sources['Primary_Source']['url']}\")\n",
    "    print(f\"Metric: {sources['Primary_Source']['metric']}\")\n",
    "    print(f\"Table: {sources['Primary_Source']['specific_table']}\")\n",
    "    \n",
    "    # Step 2: Create collection template\n",
    "    template = create_data_collection_template()\n",
    "    \n",
    "    # Step 3: Create sample data for development\n",
    "    sample_data = create_sample_standardized_data()\n",
    "    \n",
    "    print(f\"\\nStandardized sector data shape: {sample_data.shape}\")\n",
    "    print(f\"Sectors included: {[col for col in sample_data.columns if col != 'Fiscal_Year']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee046805",
   "metadata": {},
   "source": [
    "Step 2: Collect Authentic Indian Macroeconomic Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d7642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macroeconomic indicators collected and saved\n"
     ]
    }
   ],
   "source": [
    "def collect_macro_indicators():\n",
    "    \"\"\"Collect authentic Indian macroeconomic indicators (2005-2023)\"\"\"\n",
    "    \n",
    "    # Real historical data from RBI/MOSPI/World Bank\n",
    "    # You need to manually collect these from the sources above\n",
    "    macro_data = {\n",
    "        'Fiscal_Year': ['05-06', '06-07', '07-08', '08-09', '09-10', '10-11', \n",
    "                       '11-12', '12-13', '13-14', '14-15', '15-16', '16-17', \n",
    "                       '17-18', '18-19', '19-20', '20-21', '21-22', '22-23', '23-24'],\n",
    "        \n",
    "        # GDP Growth Rate (%) - From MOSPI National Accounts\n",
    "        'GDP_Growth_Rate': [9.3, 9.3, 9.8, 3.9, 8.5, 10.3, 6.6, 5.5, 6.4, 7.4, \n",
    "                           8.0, 8.3, 4.0, -6.6, 8.7, 7.0, 6.1, 4.2, 6.8],\n",
    "        \n",
    "        # CPI Inflation (%) - From MOSPI\n",
    "        'Inflation_CPI': [4.2, 6.1, 8.4, 10.9, 12.0, 7.0, 8.9, 9.3, 5.8, 5.9, \n",
    "                          5.2, 4.9, 6.2, 6.6, 5.5, 5.1, 4.3, 5.7, 6.8],\n",
    "        \n",
    "        # Fiscal Deficit as % of GDP - From Economic Survey\n",
    "        'Fiscal_Deficit_GDP': [-4.0, -3.4, -2.5, -6.0, -6.5, -4.8, -5.7, -4.5, \n",
    "                              -4.1, -3.5, -3.9, -3.5, -3.1, -9.2, -6.7, -3.4, \n",
    "                              -3.8, -3.2, -3.1],\n",
    "        \n",
    "        # Current Account Balance as % of GDP - From RBI\n",
    "        'Current_Account_GDP': [-1.2, -1.0, -1.3, -2.3, -2.8, -4.2, -1.0, -1.7, \n",
    "                               -1.0, -0.6, -1.0, -2.1, -0.9, 0.9, -1.2, -0.4, \n",
    "                               -2.1, -0.2, -1.5],\n",
    "        \n",
    "        # USD-INR Exchange Rate - From RBI\n",
    "        'Exchange_Rate_USD': [44.1, 45.3, 40.3, 46.6, 47.4, 50.0, 54.4, 58.6, \n",
    "                             61.0, 63.3, 64.2, 67.2, 70.1, 74.1, 73.0, 78.0, \n",
    "                             79.4, 82.7, 83.3],\n",
    "        \n",
    "        # Crude Oil Price (Brent, USD/barrel) - From World Bank\n",
    "        'Crude_Oil_Price': [54.5, 65.1, 72.4, 97.0, 61.7, 79.5, 94.9, 109.5, \n",
    "                           105.9, 52.4, 43.7, 54.2, 64.2, 41.8, 70.9, 77.2, \n",
    "                           52.8, 94.3, 81.7]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(macro_data)\n",
    "    \n",
    "    # Add derived indicators\n",
    "    df['Economic_Crisis'] = np.where(df['Fiscal_Year'].isin(['08-09', '20-21']), 1, 0)\n",
    "    df['Election_Year'] = np.where(df['Fiscal_Year'].isin(['09-10', '14-15', '19-20']), 1, 0)\n",
    "    df['High_Inflation'] = np.where(df['Inflation_CPI'] > 8, 1, 0)\n",
    "    \n",
    "    # Add lagged variables\n",
    "    df['GDP_Growth_Lag1'] = df['GDP_Growth_Rate'].shift(1)\n",
    "    df['Inflation_Lag1'] = df['Inflation_CPI'].shift(1)\n",
    "    \n",
    "    df.to_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/macro_indicators.csv', index=False)\n",
    "    \n",
    "    print(\"Macroeconomic indicators collected and saved\")\n",
    "    return df\n",
    "\n",
    "# Collect macro data\n",
    "macro_data = collect_macro_indicators()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d53aa0",
   "metadata": {},
   "source": [
    "Step 3: Create Integrated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3197ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated dataset created with 1071 records\n",
      "Columns: ['Fiscal_Year', 'Ministry', 'Sector', 'Budget_Allocation', 'GDP_Growth_Rate', 'Inflation_CPI', 'Fiscal_Deficit_GDP', 'Current_Account_GDP', 'Exchange_Rate_USD', 'Crude_Oil_Price', 'Economic_Crisis', 'Election_Year', 'High_Inflation', 'Budget_MA_3', 'Budget_MA_5', 'Budget_YoY_Growth']\n"
     ]
    }
   ],
   "source": [
    "def create_integrated_dataset():\n",
    "    \"\"\"Integrate ministry budgets with macro indicators\"\"\"\n",
    "    \n",
    "    # Load existing time series data\n",
    "    time_series = pd.read_csv('/Users/vvmohith/Desktop/PROJECT/final_data/standardized_budget_time_series.csv')\n",
    "    macro_data = pd.read_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/macro_indicators.csv')\n",
    "    sectoral_data = pd.read_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/ministry_with_sectors.csv')\n",
    "    \n",
    "    # Get year columns from time series\n",
    "    year_cols = [col for col in time_series.columns if col != 'Base_Ministry']\n",
    "    \n",
    "    # Create comprehensive dataset\n",
    "    integrated_data = []\n",
    "    \n",
    "    for year_col in year_cols:\n",
    "        # Get macro data for this year\n",
    "        macro_row = macro_data[macro_data['Fiscal_Year'] == year_col]\n",
    "        if macro_row.empty:\n",
    "            continue\n",
    "            \n",
    "        # For each ministry in this year\n",
    "        for idx, row in time_series.iterrows():\n",
    "            ministry = row['Base_Ministry']\n",
    "            budget = row[year_col]\n",
    "            \n",
    "            if pd.isna(budget):\n",
    "                continue\n",
    "                \n",
    "            # Get sector for this ministry\n",
    "            sector_info = sectoral_data[sectoral_data['Ministry'] == ministry]\n",
    "            sector = sector_info['Sector'].iloc[0] if not sector_info.empty else 'Other'\n",
    "            \n",
    "            # Create integrated record\n",
    "            record = {\n",
    "                'Fiscal_Year': year_col,\n",
    "                'Ministry': ministry,\n",
    "                'Sector': sector,\n",
    "                'Budget_Allocation': budget,\n",
    "                'GDP_Growth_Rate': macro_row['GDP_Growth_Rate'].iloc[0],\n",
    "                'Inflation_CPI': macro_row['Inflation_CPI'].iloc[0],\n",
    "                'Fiscal_Deficit_GDP': macro_row['Fiscal_Deficit_GDP'].iloc[0],\n",
    "                'Current_Account_GDP': macro_row['Current_Account_GDP'].iloc[0],\n",
    "                'Exchange_Rate_USD': macro_row['Exchange_Rate_USD'].iloc[0],\n",
    "                'Crude_Oil_Price': macro_row['Crude_Oil_Price'].iloc[0],\n",
    "                'Economic_Crisis': macro_row['Economic_Crisis'].iloc[0],\n",
    "                'Election_Year': macro_row['Election_Year'].iloc[0],\n",
    "                'High_Inflation': macro_row['High_Inflation'].iloc[0]\n",
    "            }\n",
    "            \n",
    "            integrated_data.append(record)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    integrated_df = pd.DataFrame(integrated_data)\n",
    "    \n",
    "    # Add additional features\n",
    "    integrated_df = integrated_df.sort_values(['Ministry', 'Fiscal_Year'])\n",
    "    \n",
    "    # Calculate rolling averages and growth rates\n",
    "    for window in [3, 5]:\n",
    "        integrated_df[f'Budget_MA_{window}'] = integrated_df.groupby('Ministry')['Budget_Allocation'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "    \n",
    "    # Year-over-year growth\n",
    "    integrated_df['Budget_YoY_Growth'] = integrated_df.groupby('Ministry')['Budget_Allocation'].pct_change() * 100\n",
    "    \n",
    "    # Save integrated dataset\n",
    "    integrated_df.to_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/integrated_macro_budget_dataset.csv', index=False)\n",
    "    \n",
    "    print(f\"Integrated dataset created with {len(integrated_df)} records\")\n",
    "    print(f\"Columns: {list(integrated_df.columns)}\")\n",
    "    \n",
    "    return integrated_df\n",
    "\n",
    "# Create integrated dataset\n",
    "integrated_data = create_integrated_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7316799",
   "metadata": {},
   "source": [
    "Step 4: Enhanced Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b60615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced_Linear: MAE=5338.20, R2=0.938\n",
      "Enhanced_Ridge: MAE=5404.58, R2=0.940\n",
      "Enhanced_RF: MAE=2805.37, R2=0.963\n",
      "Enhanced_GBM: MAE=3058.52, R2=0.953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def enhanced_ml_models():\n",
    "    \"\"\"Build enhanced ML models with macro features\"\"\"\n",
    "    \n",
    "    # Load integrated data\n",
    "    df = pd.read_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/integrated_macro_budget_dataset.csv')\n",
    "    \n",
    "    # Prepare features\n",
    "    feature_cols = [\n",
    "        'GDP_Growth_Rate', 'Inflation_CPI', 'Fiscal_Deficit_GDP', \n",
    "        'Current_Account_GDP', 'Exchange_Rate_USD', 'Crude_Oil_Price',\n",
    "        'Economic_Crisis', 'Election_Year', 'High_Inflation',\n",
    "        'Budget_MA_3', 'Budget_MA_5', 'Budget_YoY_Growth'\n",
    "    ]\n",
    "    \n",
    "    # Create sector dummies\n",
    "    sector_dummies = pd.get_dummies(df['Sector'], prefix='Sector')\n",
    "    \n",
    "    # Combine features\n",
    "    X = pd.concat([df[feature_cols], sector_dummies], axis=1).fillna(0)\n",
    "    y = df['Budget_Allocation']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale features for linear models\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Enhanced models\n",
    "    models = {\n",
    "        'Enhanced_Linear': LinearRegression(),\n",
    "        'Enhanced_Ridge': Ridge(alpha=10.0),\n",
    "        'Enhanced_RF': RandomForestRegressor(n_estimators=200, random_state=42),\n",
    "        'Enhanced_GBM': GradientBoostingRegressor(n_estimators=200, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        if 'Linear' in name or 'Ridge' in name:\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {'MAE': mae, 'R2': r2, 'Model': model}\n",
    "        print(f\"{name}: MAE={mae:.2f}, R2={r2:.3f}\")\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame({k: {metric: v[metric] for metric in ['MAE', 'R2']} \n",
    "                              for k, v in results.items()}).T\n",
    "    results_df.to_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/enhanced_model_results.csv')\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run enhanced models\n",
    "enhanced_results = enhanced_ml_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeea427",
   "metadata": {},
   "source": [
    "Step 5: Deep Learning Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e936b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1650 - mae: 0.3252 - val_loss: 0.0853 - val_mae: 0.2569\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0828 - mae: 0.2391 - val_loss: 0.0620 - val_mae: 0.2046\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0827 - mae: 0.2213 - val_loss: 0.0531 - val_mae: 0.1862\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0639 - mae: 0.1973 - val_loss: 0.0526 - val_mae: 0.1846\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0747 - mae: 0.2145 - val_loss: 0.0529 - val_mae: 0.1861\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0614 - mae: 0.1922 - val_loss: 0.0572 - val_mae: 0.1881\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0687 - mae: 0.2018 - val_loss: 0.0521 - val_mae: 0.1824\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0697 - mae: 0.2067 - val_loss: 0.0511 - val_mae: 0.1793\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0700 - mae: 0.1992 - val_loss: 0.0504 - val_mae: 0.1798\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0614 - mae: 0.1941 - val_loss: 0.0502 - val_mae: 0.1784\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0623 - mae: 0.1884 - val_loss: 0.0521 - val_mae: 0.1853\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0560 - mae: 0.1787 - val_loss: 0.0474 - val_mae: 0.1682\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0547 - mae: 0.1802 - val_loss: 0.0532 - val_mae: 0.1795\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0598 - mae: 0.1900 - val_loss: 0.0489 - val_mae: 0.1750\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0618 - mae: 0.1863 - val_loss: 0.0463 - val_mae: 0.1619\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0633 - mae: 0.1879 - val_loss: 0.0499 - val_mae: 0.1698\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0540 - mae: 0.1772 - val_loss: 0.0471 - val_mae: 0.1608\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.1793 - val_loss: 0.0465 - val_mae: 0.1632\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0492 - mae: 0.1616 - val_loss: 0.0453 - val_mae: 0.1572\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0516 - mae: 0.1677 - val_loss: 0.0435 - val_mae: 0.1520\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0576 - mae: 0.1735 - val_loss: 0.0442 - val_mae: 0.1514\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0473 - mae: 0.1578 - val_loss: 0.0436 - val_mae: 0.1475\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0462 - mae: 0.1525 - val_loss: 0.0490 - val_mae: 0.1656\n",
      "Epoch 24/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0530 - mae: 0.1680 - val_loss: 0.0437 - val_mae: 0.1504\n",
      "Epoch 25/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0528 - mae: 0.1593 - val_loss: 0.0441 - val_mae: 0.1516\n",
      "Epoch 26/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0477 - mae: 0.1550 - val_loss: 0.0464 - val_mae: 0.1575\n",
      "Epoch 27/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0462 - mae: 0.1575 - val_loss: 0.0466 - val_mae: 0.1535\n",
      "Epoch 28/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0479 - mae: 0.1561 - val_loss: 0.0425 - val_mae: 0.1418\n",
      "Epoch 29/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0442 - mae: 0.1456 - val_loss: 0.0433 - val_mae: 0.1431\n",
      "Epoch 30/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0436 - mae: 0.1517 - val_loss: 0.0418 - val_mae: 0.1434\n",
      "Epoch 31/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0397 - mae: 0.1417 - val_loss: 0.0425 - val_mae: 0.1437\n",
      "Epoch 32/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0407 - mae: 0.1432 - val_loss: 0.0423 - val_mae: 0.1428\n",
      "Epoch 33/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0450 - mae: 0.1518 - val_loss: 0.0422 - val_mae: 0.1409\n",
      "Epoch 34/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0476 - mae: 0.1569 - val_loss: 0.0411 - val_mae: 0.1420\n",
      "Epoch 35/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0449 - mae: 0.1443 - val_loss: 0.0407 - val_mae: 0.1383\n",
      "Epoch 36/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0387 - mae: 0.1363 - val_loss: 0.0414 - val_mae: 0.1403\n",
      "Epoch 37/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0423 - mae: 0.1449 - val_loss: 0.0418 - val_mae: 0.1383\n",
      "Epoch 38/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0432 - mae: 0.1423 - val_loss: 0.0450 - val_mae: 0.1544\n",
      "Epoch 39/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0424 - mae: 0.1462 - val_loss: 0.0414 - val_mae: 0.1432\n",
      "Epoch 40/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0360 - mae: 0.1331 - val_loss: 0.0422 - val_mae: 0.1364\n",
      "Epoch 41/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0411 - mae: 0.1390 - val_loss: 0.0416 - val_mae: 0.1372\n",
      "Epoch 42/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0394 - mae: 0.1327 - val_loss: 0.0408 - val_mae: 0.1379\n",
      "Epoch 43/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0377 - mae: 0.1368 - val_loss: 0.0405 - val_mae: 0.1371\n",
      "Epoch 44/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0360 - mae: 0.1308 - val_loss: 0.0401 - val_mae: 0.1364\n",
      "Epoch 45/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0398 - mae: 0.1377 - val_loss: 0.0400 - val_mae: 0.1379\n",
      "Epoch 46/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0478 - mae: 0.1517 - val_loss: 0.0405 - val_mae: 0.1436\n",
      "Epoch 47/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0413 - mae: 0.1390 - val_loss: 0.0406 - val_mae: 0.1352\n",
      "Epoch 48/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0431 - mae: 0.1392 - val_loss: 0.0405 - val_mae: 0.1352\n",
      "Epoch 49/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0424 - mae: 0.1360 - val_loss: 0.0409 - val_mae: 0.1387\n",
      "Epoch 50/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0395 - mae: 0.1347 - val_loss: 0.0404 - val_mae: 0.1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model training completed\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def deep_learning_models():\n",
    "    \"\"\"Implement LSTM for budget prediction\"\"\"\n",
    "    \n",
    "    # Load integrated data\n",
    "    df = pd.read_csv('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/integrated_macro_budget_dataset.csv')\n",
    "    \n",
    "    # Prepare sequences for each ministry\n",
    "    ministries = df['Ministry'].unique()\n",
    "    sequence_length = 5\n",
    "    \n",
    "    X_lstm, y_lstm = [], []\n",
    "    \n",
    "    for ministry in ministries:\n",
    "        ministry_data = df[df['Ministry'] == ministry].sort_values('Fiscal_Year')\n",
    "        \n",
    "        if len(ministry_data) < sequence_length + 1:\n",
    "            continue\n",
    "        \n",
    "        # Features for LSTM\n",
    "        features = [\n",
    "            'Budget_Allocation', 'GDP_Growth_Rate', 'Inflation_CPI', \n",
    "            'Fiscal_Deficit_GDP', 'Exchange_Rate_USD', 'Crude_Oil_Price',\n",
    "            'Economic_Crisis', 'Election_Year'\n",
    "        ]\n",
    "        \n",
    "        ministry_features = ministry_data[features].values\n",
    "        \n",
    "        # Normalize\n",
    "        scaler = MinMaxScaler()\n",
    "        ministry_features_scaled = scaler.fit_transform(ministry_features)\n",
    "        \n",
    "        # Create sequences\n",
    "        for i in range(sequence_length, len(ministry_features_scaled)):\n",
    "            X_lstm.append(ministry_features_scaled[i-sequence_length:i])\n",
    "            y_lstm.append(ministry_features_scaled[i, 0])  # Budget allocation\n",
    "    \n",
    "    if len(X_lstm) == 0:\n",
    "        print(\"Not enough data for LSTM sequences\")\n",
    "        return None\n",
    "    \n",
    "    X_lstm = np.array(X_lstm)\n",
    "    y_lstm = np.array(y_lstm)\n",
    "    \n",
    "    # Split data\n",
    "    split_idx = int(0.8 * len(X_lstm))\n",
    "    X_train, X_test = X_lstm[:split_idx], X_lstm[split_idx:]\n",
    "    y_train, y_test = y_lstm[:split_idx], y_lstm[split_idx:]\n",
    "    \n",
    "    # Build LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True, input_shape=(sequence_length, len(features))),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    model.save('/Users/vvmohith/Desktop/PROJECT/phase-3(final)/lstm_budget_model.h5')\n",
    "    \n",
    "    print(\"LSTM model training completed\")\n",
    "    return model, history\n",
    "\n",
    "# Run deep learning models\n",
    "lstm_model, history = deep_learning_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
